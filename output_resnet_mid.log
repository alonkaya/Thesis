nohup: ignoring input
/home/alonkay/conda/alon/lib/python3.9/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/home/alonkay/conda/alon/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/alonkay/Thesis/FMatrixRegressor.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(model_path, map_location='cpu')
no model for plots/Stereo/Winners/SED_0.5__L2_1__huber_1__lr_0.0001__conv__Resnet__use_reconstruction_True/BS_8__ratio_0.004__mid__frozen_0
no model for plots/Stereo/Winners/SED_0.5__L2_1__huber_1__lr_0.0001__conv__Resnet__use_reconstruction_True/BS_8__ratio_0.008__mid__frozen_0
no model for plots/Stereo/Winners/SED_0.5__L2_1__huber_1__lr_0.0001__conv__Resnet__use_reconstruction_True/BS_8__ratio_0.1__mid__frozen_0
no model for plots/Stereo/Winners/SED_0.5__L2_1__huber_1__lr_0.0001__conv__Resnet__use_reconstruction_True/BS_8__ratio_0.2__mid__frozen_0
Model plots/Stereo/Winners/SED_0.5__L2_1__huber_1__lr_0.0001__conv__Resnet__use_reconstruction_True/BS_8__ratio_0.004__mid__frozen_0__seed_300 already trained
no model for plots/Stereo/Winners/SED_0.5__L2_1__huber_1__lr_0.0001__conv__Resnet__use_reconstruction_True/BS_8__ratio_0.008__mid__frozen_0__seed_300

###########################################################################################################################################################

 learning rate: 0.0001, mlp_hidden_sizes: [1024, 512], jump_frames: 6, use_reconstruction_layer: True
batch_size: 8, norm: True, train_seqeunces: [0, 2, 3, 5], val_sequences: [6, 7, 8], RL_TEST_NAMES: ['fe2fadf89a84e92a', 'f01e8b6f8e10fdd9', 'f1ee9dc6135e5307', 'a41df4fa06fd391b', 'bc0ebb7482f14795', '9bdd34e784c04e3a', '98ebee1c36ecec55'], dataset: Stereo,
average embeddings: False, model: microsoft/resnet-152, augmentation: True, random crop: True, part: mid, get_old_path: False, computer: 1,
RE1 coeff: 0 SED coeff: 0.5, ALG_COEFF: 0, L2_coeff: 1, huber_coeff: 1, frozen layers: 0, trained vit: None,
crop: 224 resize: 256, use conv: True pretrained: None, train_size: 0.1, norm_mean: tensor([0.5000, 0.5000, 0.5000], device='cuda:0'), norm_std: tensor([0.5000, 0.5000, 0.5000], device='cuda:0'), sched: None seed: 300

train size: 1082, val size: 367, test size: 1064

##### CONTINUE TRAINING #####

Epoch 6791/7000: Training Loss: 0.12869805448195515		 Val Loss: 0.48935517020847485
             	Training MAE: 0.06205341964960098		 Val MAE: 0.05944783613085747
             	Algebraic dist: 0.2759724785299862		 Val Algebraic dist: 0.44312725896420685
             	RE1 dist: 0.07320662105784696		 Val RE1 dist: 0.28540080526600714
             	SED dist: 0.22370641371783087		 Val SED dist: 0.9456863403320312

### Not decreasing ###

Epoch 6792/7000: Training Loss: 0.12309673253227682		 Val Loss: 0.42824562736179517
             	Training MAE: 0.06247050687670708		 Val MAE: 0.07192549854516983
             	Algebraic dist: 0.2639176144319422		 Val Algebraic dist: 0.39241197834844177
             	RE1 dist: 0.06786578543045942		 Val RE1 dist: 0.22640642912491507
             	SED dist: 0.21225376690135284		 Val SED dist: 0.818566197934358

### Not decreasing ###

Epoch 6793/7000: Training Loss: 0.2502301721011891		 Val Loss: 0.6772300886071246
             	Training MAE: 0.06271083652973175		 Val MAE: 0.06919189542531967
             	Algebraic dist: 0.35954876507029815		 Val Algebraic dist: 0.6812363085539445
             	RE1 dist: 0.14989599059609807		 Val RE1 dist: 0.3858444794364598
             	SED dist: 0.46635784822351795		 Val SED dist: 1.318452254585598

### Not decreasing ###

Epoch 6794/7000: Training Loss: 0.23766610201667338		 Val Loss: 0.47541846399721893
             	Training MAE: 0.06366720795631409		 Val MAE: 0.06199122592806816
             	Algebraic dist: 0.393860284019919		 Val Algebraic dist: 0.5019043632175612
             	RE1 dist: 0.16005301475524902		 Val RE1 dist: 0.26541560629139777
             	SED dist: 0.4410349340999828		 Val SED dist: 0.9176367884096892

### Not decreasing ###

Epoch 6795/7000: Training Loss: 0.34407960667329673		 Val Loss: 0.5134750034498132
             	Training MAE: 0.06515185534954071		 Val MAE: 0.06387732177972794
             	Algebraic dist: 0.5017793879789465		 Val Algebraic dist: 0.4627544983573582
             	RE1 dist: 0.24338744668399587		 Val RE1 dist: 0.3192317589469578
             	SED dist: 0.6530182782341453		 Val SED dist: 0.9931921751602836

### Not decreasing ###

Epoch 6796/7000: Training Loss: 0.1265106481664321		 Val Loss: 0.4250984191894531
             	Training MAE: 0.06126587837934494		 Val MAE: 0.06293380260467529
             	Algebraic dist: 0.27637585471658144		 Val Algebraic dist: 0.41669003859810205
             	RE1 dist: 0.07561857560101677		 Val RE1 dist: 0.2572000959645147
             	SED dist: 0.21975893132826863		 Val SED dist: 0.8165205250615659

### Not decreasing ###

Epoch 6797/7000: Training Loss: 0.13205273011151483		 Val Loss: 0.3630265360293181
             	Training MAE: 0.06147642061114311		 Val MAE: 0.05905645340681076
             	Algebraic dist: 0.2794696022482479		 Val Algebraic dist: 0.3892391868259596
             	RE1 dist: 0.07662149737862979		 Val RE1 dist: 0.20410369790118674
             	SED dist: 0.23066537520464728		 Val SED dist: 0.6929325435472571

### Not decreasing ###

Epoch 6798/7000: Training Loss: 0.10921772788552676		 Val Loss: 0.42413102025571076
             	Training MAE: 0.061209727078676224		 Val MAE: 0.0702475905418396
             	Algebraic dist: 0.24515180026783662		 Val Algebraic dist: 0.4269130955571714
             	RE1 dist: 0.05861186279970057		 Val RE1 dist: 0.22660182869952658
             	SED dist: 0.18507857883677764		 Val SED dist: 0.81158563365107

### Not decreasing ###

Epoch 6799/7000: Training Loss: 0.10907546211691464		 Val Loss: 0.3607887599779212
             	Training MAE: 0.06162836030125618		 Val MAE: 0.06063103675842285
             	Algebraic dist: 0.24328958286958582		 Val Algebraic dist: 0.4020484012106191
             	RE1 dist: 0.056339081595925725		 Val RE1 dist: 0.18511440442956012
             	SED dist: 0.18457586625043085		 Val SED dist: 0.688205801922342

### Not decreasing ###

Epoch 6800/7000: Training Loss: 0.15142372075249166		 Val Loss: 0.30957833580348804
             	Training MAE: 0.06300430744886398		 Val MAE: 0.06473830342292786
             	Algebraic dist: 0.29038670483757467		 Val Algebraic dist: 0.35270180909529975
             	RE1 dist: 0.08445014673120835		 Val RE1 dist: 0.16278431726538617
             	SED dist: 0.2686014736399931		 Val SED dist: 0.584841894066852

### Not decreasing ###

Epoch 6801/7000: Training Loss: 0.1466542832991656		 Val Loss: 0.3436476251353388
             	Training MAE: 0.06201411411166191		 Val MAE: 0.0608835369348526
             	Algebraic dist: 0.2956453211167279		 Val Algebraic dist: 0.38338101428488025
             	RE1 dist: 0.08236282012041878		 Val RE1 dist: 0.17605827165686566
             	SED dist: 0.2596588695750517		 Val SED dist: 0.6538583092067553

### Not decreasing ###

Epoch 6802/7000: Training Loss: 0.19194682906655705		 Val Loss: 0.5277433810026749
             	Training MAE: 0.06494317203760147		 Val MAE: 0.0631251186132431
             	Algebraic dist: 0.3379647311042337		 Val Algebraic dist: 0.512030145396357
             	RE1 dist: 0.1112913594526403		 Val RE1 dist: 0.2858114242553711
             	SED dist: 0.3488396476296818		 Val SED dist: 1.02154308816661

### Not decreasing ###

Epoch 6803/7000: Training Loss: 0.11450717028449564		 Val Loss: 0.3834051463914954
             	Training MAE: 0.06127558648586273		 Val MAE: 0.06023919954895973
             	Algebraic dist: 0.25100935206693764		 Val Algebraic dist: 0.43220905635667883
             	RE1 dist: 0.0618052131989423		 Val RE1 dist: 0.18899098686549975
             	SED dist: 0.1955862045288086		 Val SED dist: 0.7333704906961193

### Not decreasing ###

Epoch 6804/7000: Training Loss: 0.28899276957792397		 Val Loss: 0.43399350539497705
             	Training MAE: 0.062472566962242126		 Val MAE: 0.06601057201623917
             	Algebraic dist: 0.4155912118799546		 Val Algebraic dist: 0.43545731254245923
             	RE1 dist: 0.18557349373312557		 Val RE1 dist: 0.25527195308519446
             	SED dist: 0.5442700105554917		 Val SED dist: 0.8329397284466288

### Not decreasing ###

Epoch 6805/7000: Training Loss: 0.1366122049443862		 Val Loss: 0.3640179841414742
             	Training MAE: 0.06305751949548721		 Val MAE: 0.05912930890917778
             	Algebraic dist: 0.2825180222006405		 Val Algebraic dist: 0.37964277682097064
             	RE1 dist: 0.07800622547374052		 Val RE1 dist: 0.20326691088469132
             	SED dist: 0.2391188845914953		 Val SED dist: 0.6948636096456776

### Not decreasing ###

Epoch 6806/7000: Training Loss: 0.18882266212912166		 Val Loss: 45.845023777173914
             	Training MAE: 0.06398867815732956		 Val MAE: 0.06845371425151825
             	Algebraic dist: 0.3451194763183594		 Val Algebraic dist: 1.060937549756921
             	RE1 dist: 0.11339157469132367		 Val RE1 dist: 11.495269775390625
             	SED dist: 0.3431066905750948		 Val SED dist: 91.6536281419837

### Not decreasing ###

Epoch 6807/7000: Training Loss: 0.1626121016109691		 Val Loss: 22.250916854194973
             	Training MAE: 0.06298736482858658		 Val MAE: 0.060124341398477554
             	Algebraic dist: 0.31671717587639303		 Val Algebraic dist: 0.7291669430940048
             	RE1 dist: 0.09411484353682574		 Val RE1 dist: 8.018272068189537
             	SED dist: 0.2911255219403435		 Val SED dist: 44.46835990574049

### Not decreasing ###

Epoch 6808/7000: Training Loss: 0.19114568654228659		 Val Loss: 36.42012886379076
             	Training MAE: 0.06203986331820488		 Val MAE: 0.06062932685017586
             	Algebraic dist: 0.3443496648003073		 Val Algebraic dist: 1.1195170361062754
             	RE1 dist: 0.11620641455930822		 Val RE1 dist: 12.90705274498981
             	SED dist: 0.34861118653241324		 Val SED dist: 72.8064548658288

### Not decreasing ###

Epoch 6809/7000: Training Loss: 0.1821910072775448		 Val Loss: 0.43017180069633154
             	Training MAE: 0.0627916231751442		 Val MAE: 0.06275513768196106
             	Algebraic dist: 0.3355265505173627		 Val Algebraic dist: 0.46446335834005603
             	RE1 dist: 0.10887106727151309		 Val RE1 dist: 0.23971870671147885
             	SED dist: 0.33032408882589903		 Val SED dist: 0.8265675254490065

### Not decreasing ###

Epoch 6810/7000: Training Loss: 0.17735441993264592		 Val Loss: 0.3815613207609757
             	Training MAE: 0.06222953647375107		 Val MAE: 0.059783969074487686
             	Algebraic dist: 0.3298191182753619		 Val Algebraic dist: 0.3992281789365022
             	RE1 dist: 0.10681606040281408		 Val RE1 dist: 0.2096140073693317
             	SED dist: 0.32100649440989776		 Val SED dist: 0.7297500942064368

### Not decreasing ###

Epoch 6811/7000: Training Loss: 0.16614709180944107		 Val Loss: 0.34030549422554346
             	Training MAE: 0.061505068093538284		 Val MAE: 0.059392284601926804
             	Algebraic dist: 0.3215775209314683		 Val Algebraic dist: 0.4023676747861116
             	RE1 dist: 0.09766518368440516		 Val RE1 dist: 0.18026175706282907
             	SED dist: 0.29882534812478456		 Val SED dist: 0.6474510275799296

### Not decreasing ###

Epoch 6812/7000: Training Loss: 0.16071170919081745		 Val Loss: 0.4681667659593665
             	Training MAE: 0.06337684392929077		 Val MAE: 0.05809235945343971
             	Algebraic dist: 0.30910570481244254		 Val Algebraic dist: 0.5412265114162279
             	RE1 dist: 0.09211655925301944		 Val RE1 dist: 0.24637976936672046
             	SED dist: 0.28713428272920494		 Val SED dist: 0.9035976244055707

### Not decreasing ###

Epoch 6813/7000: Training Loss: 0.26966319364659924		 Val Loss: 0.6436181690381921
             	Training MAE: 0.06253816187381744		 Val MAE: 0.058929212391376495
             	Algebraic dist: 0.4131470848532284		 Val Algebraic dist: 0.4778031473574431
             	RE1 dist: 0.17734325633329504		 Val RE1 dist: 0.35305487591287366
             	SED dist: 0.5055810142965877		 Val SED dist: 1.2541040337604026

### Not decreasing ###

Epoch 6814/7000: Training Loss: 0.18564113448647893		 Val Loss: 0.624079704284668
             	Training MAE: 0.06237011030316353		 Val MAE: 0.06072341278195381
             	Algebraic dist: 0.3368430698619169		 Val Algebraic dist: 0.53338564997134
             	RE1 dist: 0.1178425480337704		 Val RE1 dist: 0.38438730654509173
             	SED dist: 0.33759105906767006		 Val SED dist: 1.215004133141559

### Not decreasing ###

Epoch 6815/7000: Training Loss: 0.14899795195635626		 Val Loss: 0.39126470814580505
             	Training MAE: 0.06238950043916702		 Val MAE: 0.06434091925621033
             	Algebraic dist: 0.3000555879929486		 Val Algebraic dist: 0.38533322707466455
             	RE1 dist: 0.08755061205695658		 Val RE1 dist: 0.21901713246884552
             	SED dist: 0.2642469125635484		 Val SED dist: 0.7484674868376359

### Not decreasing ###

Epoch 6816/7000: Training Loss: 0.13318605983958526		 Val Loss: 0.49710725701373554
             	Training MAE: 0.061569638550281525		 Val MAE: 0.06884756684303284
             	Algebraic dist: 0.27758514179902916		 Val Algebraic dist: 0.5699392816294795
             	RE1 dist: 0.07402613583733053		 Val RE1 dist: 0.24625284775443698
             	SED dist: 0.2328769599690157		 Val SED dist: 0.9581461367399796

### Not decreasing ###

Epoch 6817/7000: Training Loss: 0.16982527340159698		 Val Loss: 0.3444609849349312
             	Training MAE: 0.06322191655635834		 Val MAE: 0.059281423687934875
             	Algebraic dist: 0.32390529969159293		 Val Algebraic dist: 0.37993995003078296
             	RE1 dist: 0.09915304183959961		 Val RE1 dist: 0.19484546910161557
             	SED dist: 0.30547377642463236		 Val SED dist: 0.65554780545442

### Not decreasing ###

Epoch 6818/7000: Training Loss: 0.17888864348916447		 Val Loss: 0.41031207209048065
             	Training MAE: 0.06210285425186157		 Val MAE: 0.06594806909561157
             	Algebraic dist: 0.32204703723683076		 Val Algebraic dist: 0.40053380053976306
             	RE1 dist: 0.10491657958311193		 Val RE1 dist: 0.22692504136458688
             	SED dist: 0.32407640008365407		 Val SED dist: 0.7855904620626698

### Not decreasing ###

Epoch 6819/7000: Training Loss: 0.17467570304870605		 Val Loss: 0.35306549072265625
             	Training MAE: 0.06404747068881989		 Val MAE: 0.05970633774995804
             	Algebraic dist: 0.31976497874540444		 Val Algebraic dist: 0.4076360619586447
             	RE1 dist: 0.10456078192766975		 Val RE1 dist: 0.18424562785936438
             	SED dist: 0.314876023460837		 Val SED dist: 0.6730109919672427

### Not decreasing ###

Epoch 6820/7000: Training Loss: 0.1217507194070255		 Val Loss: 0.3692314728446629
             	Training MAE: 0.062357097864151		 Val MAE: 0.05904440954327583
             	Algebraic dist: 0.263885778539321		 Val Algebraic dist: 0.396935628808063
             	RE1 dist: 0.06612772801343132		 Val RE1 dist: 0.1981922025265901
             	SED dist: 0.20973296726451202		 Val SED dist: 0.7052380105723506

### Not decreasing ###

Epoch 6821/7000: Training Loss: 0.16100753054899328		 Val Loss: 0.32132190206776495
             	Training MAE: 0.06331323087215424		 Val MAE: 0.0664064809679985
             	Algebraic dist: 0.3085530224968405		 Val Algebraic dist: 0.3629107267960258
             	RE1 dist: 0.09248344337238985		 Val RE1 dist: 0.1684204288150953
             	SED dist: 0.28771162033081055		 Val SED dist: 0.6077586878900942

### Not decreasing ###

Epoch 6822/7000: Training Loss: 0.12079930305480957		 Val Loss: 0.4389255357825238
             	Training MAE: 0.06156061962246895		 Val MAE: 0.05961933732032776
             	Algebraic dist: 0.25667358847225413		 Val Algebraic dist: 0.4015733470087466
             	RE1 dist: 0.06649697528165929		 Val RE1 dist: 0.25420628423276154
             	SED dist: 0.2080682726467357		 Val SED dist: 0.8445052271303923

### Not decreasing ###

Epoch 6823/7000: Training Loss: 0.1665208900676054		 Val Loss: 0.2964230620342752
             	Training MAE: 0.0635557621717453		 Val MAE: 0.05894076079130173
             	Algebraic dist: 0.31063211665434		 Val Algebraic dist: 0.35282603554103686
             	RE1 dist: 0.09464500932132497		 Val RE1 dist: 0.1519103257552437
             	SED dist: 0.29874582851634307		 Val SED dist: 0.5597238955290421

### Not decreasing ###

Epoch 1/10: Test SED dist: 0.3690819417623649
Epoch 2/10: Test SED dist: 0.37864475680473153
Epoch 3/10: Test SED dist: 0.3640043215644091
Epoch 4/10: Test SED dist: 0.35487575100776847
Epoch 5/10: Test SED dist: 0.3577492792803542
Epoch 6/10: Test SED dist: 0.35714317264413475
Epoch 7/10: Test SED dist: 0.365318843296596
Epoch 8/10: Test SED dist: 0.367363348939365
Epoch 9/10: Test SED dist: 0.3476101868134692
Epoch 10/10: Test SED dist: 0.36224095624192315


## TEST RESULTS: ##
Test Loss: 0.19771870060970909		 Test MAE: 0.058507348969578744
Test Algebraic dist: 0.3298083054391961
Test SED dist: 0.36240325583551164
Test RE1 dist: 0.11568397651041362

Test Algebraic dist truth: 0.017686137579437485
Test SED dist truth: 0.0017203104899341899
Test RE1 dist truth: 0.00021503868519811702


plots/Stereo/Winners/SED_0.5__L2_1__huber_1__lr_0.0001__conv__Resnet__use_reconstruction_True/BS_8__ratio_0.1__mid__frozen_0__seed_300 no backup to delete after job done

no model for plots/Stereo/Winners/SED_0.5__L2_1__huber_1__lr_0.0001__conv__Resnet__use_reconstruction_True/BS_8__ratio_0.2__mid__frozen_0__seed_300
no model for plots/Stereo/Winners/SED_0.5__L2_1__huber_1__lr_0.0001__conv__Resnet__use_reconstruction_True/BS_8__ratio_0.004__mid__frozen_0__seed_500
no model for plots/Stereo/Winners/SED_0.5__L2_1__huber_1__lr_0.0001__conv__Resnet__use_reconstruction_True/BS_8__ratio_0.008__mid__frozen_0__seed_500
no model for plots/Stereo/Winners/SED_0.5__L2_1__huber_1__lr_0.0001__conv__Resnet__use_reconstruction_True/BS_8__ratio_0.1__mid__frozen_0__seed_500

###########################################################################################################################################################

 learning rate: 0.0001, mlp_hidden_sizes: [1024, 512], jump_frames: 6, use_reconstruction_layer: True
batch_size: 8, norm: True, train_seqeunces: [0, 2, 3, 5], val_sequences: [6, 7, 8], RL_TEST_NAMES: ['fe2fadf89a84e92a', 'f01e8b6f8e10fdd9', 'f1ee9dc6135e5307', 'a41df4fa06fd391b', 'bc0ebb7482f14795', '9bdd34e784c04e3a', '98ebee1c36ecec55'], dataset: Stereo,
average embeddings: False, model: microsoft/resnet-152, augmentation: True, random crop: True, part: mid, get_old_path: False, computer: 1,
RE1 coeff: 0 SED coeff: 0.5, ALG_COEFF: 0, L2_coeff: 1, huber_coeff: 1, frozen layers: 0, trained vit: None,
crop: 224 resize: 256, use conv: True pretrained: None, train_size: 0.2, norm_mean: tensor([0.5000, 0.5000, 0.5000], device='cuda:0'), norm_std: tensor([0.5000, 0.5000, 0.5000], device='cuda:0'), sched: None seed: 500

train size: 2166, val size: 736, test size: 1064

##### CONTINUE TRAINING #####

Epoch 3025/4500: Training Loss: 0.6827718586939288		 Val Loss: 1.074856136156165
             	Training MAE: 0.3564589023590088		 Val MAE: 0.3653043210506439
             	Algebraic dist: 0.0870704228587696		 Val Algebraic dist: 0.12933769433394723
             	RE1 dist: 0.00702014312532995		 Val RE1 dist: 0.019181557323621666
             	SED dist: 0.3549370572135897		 Val SED dist: 1.0923245471456777

Epoch 3026/4500: Training Loss: 0.7522954061022544		 Val Loss: 1.1595033562701682
             	Training MAE: 0.3548811078071594		 Val MAE: 0.3653504252433777
             	Algebraic dist: 0.09795564742985687		 Val Algebraic dist: 0.1380143061928127
             	RE1 dist: 0.009557437192909832		 Val RE1 dist: 0.021958356318266495
             	SED dist: 0.49924651986998386		 Val SED dist: 1.2622016409169072

Epoch 3027/4500: Training Loss: 0.760565726079624		 Val Loss: 1.3092292288075322
             	Training MAE: 0.3556511104106903		 Val MAE: 0.36449745297431946
             	Algebraic dist: 0.10089018424058753		 Val Algebraic dist: 0.169907051583995
             	RE1 dist: 0.009778059716594175		 Val RE1 dist: 0.027644667936408
             	SED dist: 0.513599916577779		 Val SED dist: 1.5681633327318274

Epoch 3028/4500: Training Loss: 0.656318242259571		 Val Loss: 1.2205231708029043
             	Training MAE: 0.3551666736602783		 Val MAE: 0.36637625098228455
             	Algebraic dist: 0.0798803519498818		 Val Algebraic dist: 0.13581936255745267
             	RE1 dist: 0.00600610228042321		 Val RE1 dist: 0.022182379079901653
             	SED dist: 0.3076543209737517		 Val SED dist: 1.3783769192902937

Epoch 3029/4500: Training Loss: 0.9229841056345134		 Val Loss: 1.53802722433339
             	Training MAE: 0.35543057322502136		 Val MAE: 0.3640633821487427
             	Algebraic dist: 0.13058875671611941		 Val Algebraic dist: 0.20041961255280868
             	RE1 dist: 0.015975408448504345		 Val RE1 dist: 0.03445432237956835
             	SED dist: 0.8388265349328298		 Val SED dist: 2.028287141219429

Epoch 3030/4500: Training Loss: 0.6990060841465349		 Val Loss: 1.4474618331245754
             	Training MAE: 0.3558468222618103		 Val MAE: 0.3634257912635803
             	Algebraic dist: 0.09064406222522918		 Val Algebraic dist: 0.16612084015556003
             	RE1 dist: 0.0075881489968387845		 Val RE1 dist: 0.027992567290430485
             	SED dist: 0.38971850968814864		 Val SED dist: 1.851046023161515

Epoch 3031/4500: Training Loss: 0.8746066498140568		 Val Loss: 1.0998221687648608
             	Training MAE: 0.3549412190914154		 Val MAE: 0.3657563328742981
             	Algebraic dist: 0.11671613151296918		 Val Algebraic dist: 0.1345051786173945
             	RE1 dist: 0.01339553642976768		 Val RE1 dist: 0.019247033025907433
             	SED dist: 0.7447427559602744		 Val SED dist: 1.1404843537703804

Epoch 3032/4500: Training Loss: 0.7818640677251499		 Val Loss: 1.2495847784954568
             	Training MAE: 0.35610806941986084		 Val MAE: 0.36901187896728516
             	Algebraic dist: 0.10614495083854647		 Val Algebraic dist: 0.14136343416960342
             	RE1 dist: 0.010886829277686087		 Val RE1 dist: 0.026514390240544857
             	SED dist: 0.5529808804557772		 Val SED dist: 1.41430547963018

