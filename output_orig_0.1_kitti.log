/home/alonkay/conda/alon/lib/python3.9/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/home/alonkay/conda/alon/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/alonkay/conda/alon/lib/python3.9/site-packages/transformers/modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location=map_location)
/home/alonkay/Thesis/FMatrixRegressor.py:331: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(model_path, map_location='cpu')
###########################################################################################################################################################

 learning rate: 0.0001, mlp_hidden_sizes: [1024, 512], jump_frames: 6, use_reconstruction_layer: True
batch_size: 8, norm: True, train_seqeunces: [0, 2, 3, 5], val_sequences: [6, 7, 8], RL_TEST_NAMES: ['fe2fadf89a84e92a', 'f01e8b6f8e10fdd9', 'f1ee9dc6135e5307', 'a41df4fa06fd391b', 'bc0ebb7482f14795', '9bdd34e784c04e3a', '98ebee1c36ecec55'], dataset: Stereo,
average embeddings: False, model: openai/clip-vit-base-patch32, augmentation: True, random crop: True, part: head, get_old_path: False,
RE1 coeff: 0 SED coeff: 0.5, ALG_COEFF: 0, L2_coeff: 1, huber_coeff: 1, frozen layers: 0, trained vit: None,
crop: 224 resize: 256, use conv: True pretrained: None, train_size: 0.1, norm_mean: tensor([0.4815, 0.4578, 0.4082], device='cuda:0'), norm_std: tensor([0.2686, 0.2613, 0.2758], device='cuda:0'), sched: None seed: 42, 

train size: 1082, val size: 367, test size: 1064

##### CONTINUE TRAINING #####

Epoch 4015/7000: Training Loss: 0.2830341283012839		 Val Loss: 0.37807680212933087
             	Training MAE: 0.06665059179067612		 Val MAE: 0.06528133898973465
             	Algebraic dist: 0.4244694429285386		 Val Algebraic dist: 0.522302710491678
             	RE1 dist: 0.18090323840870576		 Val RE1 dist: 0.28168313399605127
             	SED dist: 0.5289555156932157		 Val SED dist: 0.7201093590777853

Epoch 4016/7000: Training Loss: 0.2999305725097656		 Val Loss: 0.6110151539678159
             	Training MAE: 0.06666749715805054		 Val MAE: 0.06349685043096542
             	Algebraic dist: 0.4330764658310834		 Val Algebraic dist: 0.6981895280920941
             	RE1 dist: 0.185576831593233		 Val RE1 dist: 0.43193091516909393
             	SED dist: 0.5627484602086684		 Val SED dist: 1.1861771293308423

Epoch 4017/7000: Training Loss: 0.47993772170122934		 Val Loss: 0.4463157653808594
             	Training MAE: 0.06802154332399368		 Val MAE: 0.06639868021011353
             	Algebraic dist: 0.5819944493910846		 Val Algebraic dist: 0.565112943234651
             	RE1 dist: 0.3298662690555348		 Val RE1 dist: 0.3902877724688986
             	SED dist: 0.9221881978652057		 Val SED dist: 0.8559178891389266

Epoch 4018/7000: Training Loss: 0.2307273079367245		 Val Loss: 0.7003255097762399
             	Training MAE: 0.06579290330410004		 Val MAE: 0.06356503069400787
             	Algebraic dist: 0.37325376622817097		 Val Algebraic dist: 0.7932857015858525
             	RE1 dist: 0.14218654352075913		 Val RE1 dist: 0.5315186873726223
             	SED dist: 0.42470017601461973		 Val SED dist: 1.3652968199356743

Epoch 4019/7000: Training Loss: 0.3337380745831658		 Val Loss: 0.40683738045070483
             	Training MAE: 0.06807053089141846		 Val MAE: 0.06545249372720718
             	Algebraic dist: 0.4658665657043457		 Val Algebraic dist: 0.5414828010227369
             	RE1 dist: 0.21419872957117417		 Val RE1 dist: 0.2970325428506602
             	SED dist: 0.6296600453993854		 Val SED dist: 0.7772458947223165

Epoch 4020/7000: Training Loss: 0.7144963320563821		 Val Loss: 0.4923057556152344
             	Training MAE: 0.06839732080698013		 Val MAE: 0.06519731879234314
             	Algebraic dist: 0.697548417484059		 Val Algebraic dist: 0.6142454976620881
             	RE1 dist: 0.5281825907090131		 Val RE1 dist: 0.4404154653134553
             	SED dist: 1.3910310408648323		 Val SED dist: 0.9483356475830078

Epoch 4021/7000: Training Loss: 0.3281557139228372		 Val Loss: 0.9878229887589164
             	Training MAE: 0.06667743623256683		 Val MAE: 0.06949132680892944
             	Algebraic dist: 0.4695316482992733		 Val Algebraic dist: 0.9392069940981658
             	RE1 dist: 0.23583002651438995		 Val RE1 dist: 0.7872759777566661
             	SED dist: 0.6193127912633559		 Val SED dist: 1.9372923477836277

