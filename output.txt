learning rate vit: 2e-05, learning rate mlp: 0.0005, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.0005, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.0005, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.0005, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.0005, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.0005, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.0005, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.0005, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.0005, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.0005, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.0005, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

Epoch 1/50, Training Loss: 0.38016197085380554 Val Loss: 0.21133659780025482 
            Training MAE: 0.3323436975479126 Val mae: 0.3277329206466675 
            Train epipolar error pred unormalized: 8347.8330078125 Val epipolar error pred unormalized: 6521.51318359375
            Train epipolar error pred: 5903.28759765625 Val epipolar error pred: 2326.609619140625 
            penalty: 0.6738805770874023
Epoch 2/50, Training Loss: 0.3138315677642822 Val Loss: 0.2143578827381134 
            Training MAE: 0.2926165759563446 Val mae: 0.316490113735199 
            Train epipolar error pred unormalized: 6159.4287109375 Val epipolar error pred unormalized: 4563.9248046875
            Train epipolar error pred: 4463.75341796875 Val epipolar error pred: 2196.03173828125 
            penalty: 0.2420274317264557
Epoch 3/50, Training Loss: 0.1937028467655182 Val Loss: 0.22276100516319275 
            Training MAE: 0.22122728824615479 Val mae: 0.31731748580932617 
            Train epipolar error pred unormalized: 3500.007568359375 Val epipolar error pred unormalized: 1702.20458984375
            Train epipolar error pred: 2364.529052734375 Val epipolar error pred: 1234.447265625 
            penalty: 0.04522988572716713
Epoch 4/50, Training Loss: 0.09381825476884842 Val Loss: 0.22008539736270905 
            Training MAE: 0.15112818777561188 Val mae: 0.25201746821403503 
            Train epipolar error pred unormalized: 2228.778564453125 Val epipolar error pred unormalized: 539.9700927734375
            Train epipolar error pred: 1191.3082275390625 Val epipolar error pred: 757.91845703125 
            penalty: 0.003608057042583823
Epoch 5/50, Training Loss: 0.0626128539443016 Val Loss: 0.22212129831314087 
            Training MAE: 0.11794646084308624 Val mae: 0.24594751000404358 
            Train epipolar error pred unormalized: 2009.33154296875 Val epipolar error pred unormalized: 642.2022094726562
            Train epipolar error pred: 857.7001342773438 Val epipolar error pred: 704.0037231445312 
            penalty: 0.011274999007582664
Epoch 6/50, Training Loss: 0.049182500690221786 Val Loss: 0.20494137704372406 
            Training MAE: 0.09910301119089127 Val mae: 0.23002000153064728 
            Train epipolar error pred unormalized: 1745.228759765625 Val epipolar error pred unormalized: 566.7247924804688
            Train epipolar error pred: 686.84130859375 Val epipolar error pred: 486.5850830078125 
            penalty: 0.00821597594767809
Epoch 7/50, Training Loss: 0.04225115850567818 Val Loss: 0.19300693273544312 
            Training MAE: 0.09011514484882355 Val mae: 0.21874482929706573 
            Train epipolar error pred unormalized: 1721.3482666015625 Val epipolar error pred unormalized: 548.0064086914062
            Train epipolar error pred: 597.9786987304688 Val epipolar error pred: 580.093505859375 
            penalty: 0.003914289176464081
Epoch 8/50, Training Loss: 0.03535182774066925 Val Loss: 0.18159855902194977 
            Training MAE: 0.08022460341453552 Val mae: 0.2144429087638855 
            Train epipolar error pred unormalized: 1779.7720947265625 Val epipolar error pred unormalized: 482.0503234863281
            Train epipolar error pred: 558.6460571289062 Val epipolar error pred: 467.9169616699219 
            penalty: 0.005444312002509832
Epoch 9/50, Training Loss: 0.03225622698664665 Val Loss: 0.21189606189727783 
            Training MAE: 0.074466273188591 Val mae: 0.2204320877790451 
            Train epipolar error pred unormalized: 1666.853759765625 Val epipolar error pred unormalized: 565.6890869140625
            Train epipolar error pred: 531.9330444335938 Val epipolar error pred: 598.2431030273438 
            penalty: 0.0040476578287780285
Epoch 10/50, Training Loss: 0.03012242168188095 Val Loss: 0.19351370632648468 
            Training MAE: 0.06881140172481537 Val mae: 0.21528244018554688 
            Train epipolar error pred unormalized: 1538.667724609375 Val epipolar error pred unormalized: 571.7974853515625
            Train epipolar error pred: 483.1930847167969 Val epipolar error pred: 724.171875 
            penalty: 0.0035960618406534195
Epoch 11/50, Training Loss: 0.02713090553879738 Val Loss: 0.19452321529388428 
            Training MAE: 0.06586015969514847 Val mae: 0.22298337519168854 
            Train epipolar error pred unormalized: 1531.239013671875 Val epipolar error pred unormalized: 679.1334228515625
            Train epipolar error pred: 478.6860046386719 Val epipolar error pred: 642.1646118164062 
            penalty: 0.005872620269656181
Epoch 12/50, Training Loss: 0.026404570788145065 Val Loss: 0.18293291330337524 
            Training MAE: 0.06381069868803024 Val mae: 0.2070169448852539 
            Train epipolar error pred unormalized: 1643.303955078125 Val epipolar error pred unormalized: 642.1265869140625
            Train epipolar error pred: 505.8869934082031 Val epipolar error pred: 757.7674560546875 
            penalty: 0.0027898200787603855
Epoch 13/50, Training Loss: 0.028028957545757294 Val Loss: 0.19973017275333405 
            Training MAE: 0.06756561994552612 Val mae: 0.22776758670806885 
            Train epipolar error pred unormalized: 1836.3509521484375 Val epipolar error pred unormalized: 953.0612182617188
            Train epipolar error pred: 557.3119506835938 Val epipolar error pred: 551.876953125 
            penalty: 0.006156695540994406
Epoch 14/50, Training Loss: 0.03172868490219116 Val Loss: 0.20922881364822388 
            Training MAE: 0.0702984407544136 Val mae: 0.21514827013015747 
            Train epipolar error pred unormalized: 1754.832763671875 Val epipolar error pred unormalized: 812.1795654296875
            Train epipolar error pred: 534.9986572265625 Val epipolar error pred: 588.9640502929688 
            penalty: 0.004645372275263071
###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.0005, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

Epoch 1/50, Training Loss: 0.34750834107398987 Val Loss: 0.21431739628314972 
            Training MAE: 0.31955355405807495 Val mae: 0.32622426748275757 
            Train epipolar error pred unormalized: 7239.16064453125 Val epipolar error pred unormalized: 806.2711181640625
            Train epipolar error pred: 5535.68310546875 Val epipolar error pred: 1467.636962890625 
            penalty: 0.01531913224607706
Epoch 2/50, Training Loss: 0.266834557056427 Val Loss: 0.21088364720344543 
            Training MAE: 0.2852342128753662 Val mae: 0.3145596385002136 
            Train epipolar error pred unormalized: 4093.53125 Val epipolar error pred unormalized: 650.529052734375
            Train epipolar error pred: 3084.6953125 Val epipolar error pred: 919.2887573242188 
            penalty: 0.018116330727934837
Epoch 3/50, Training Loss: 0.2335837483406067 Val Loss: 0.2089727222919464 
            Training MAE: 0.2804953157901764 Val mae: 0.3062199354171753 
            Train epipolar error pred unormalized: 2882.757080078125 Val epipolar error pred unormalized: 300.3699645996094
            Train epipolar error pred: 1859.1241455078125 Val epipolar error pred: 355.05279541015625 
            penalty: 0.006444375496357679
Epoch 4/50, Training Loss: 0.20876142382621765 Val Loss: 0.2081717699766159 
            Training MAE: 0.26613807678222656 Val mae: 0.2902362048625946 
            Train epipolar error pred unormalized: 2280.727294921875 Val epipolar error pred unormalized: 126.20245361328125
            Train epipolar error pred: 1137.833251953125 Val epipolar error pred: 133.96505737304688 
            penalty: 0.0055958786979317665
Epoch 5/50, Training Loss: 0.2049647867679596 Val Loss: 0.20713964104652405 
            Training MAE: 0.25935500860214233 Val mae: 0.2867330312728882 
            Train epipolar error pred unormalized: 1974.0230712890625 Val epipolar error pred unormalized: 170.46168518066406
            Train epipolar error pred: 1011.2122802734375 Val epipolar error pred: 155.7245330810547 
            penalty: 0.002323163440451026
Epoch 6/50, Training Loss: 0.19816789031028748 Val Loss: 0.20585545897483826 
            Training MAE: 0.2547471821308136 Val mae: 0.2858297526836395 
            Train epipolar error pred unormalized: 1777.363525390625 Val epipolar error pred unormalized: 154.89002990722656
            Train epipolar error pred: 864.1852416992188 Val epipolar error pred: 145.08111572265625 
            penalty: 0.0028603053651750088
Epoch 7/50, Training Loss: 0.1502974033355713 Val Loss: 0.1915266364812851 
            Training MAE: 0.20259860157966614 Val mae: 0.24852560460567474 
            Train epipolar error pred unormalized: 2338.310546875 Val epipolar error pred unormalized: 379.5093994140625
            Train epipolar error pred: 1174.0885009765625 Val epipolar error pred: 439.89947509765625 
            penalty: 0.0032720596063882113
Epoch 8/50, Training Loss: 0.09598520398139954 Val Loss: 0.2029244750738144 
            Training MAE: 0.1357753723859787 Val mae: 0.2578301727771759 
            Train epipolar error pred unormalized: 2208.327880859375 Val epipolar error pred unormalized: 438.6640319824219
            Train epipolar error pred: 1017.5875244140625 Val epipolar error pred: 397.2531433105469 
            penalty: 0.002824682742357254
Epoch 9/50, Training Loss: 0.06255567073822021 Val Loss: 0.18684592843055725 
            Training MAE: 0.1037868782877922 Val mae: 0.22396261990070343 
            Train epipolar error pred unormalized: 2259.04833984375 Val epipolar error pred unormalized: 542.2013549804688
            Train epipolar error pred: 809.4086303710938 Val epipolar error pred: 603.9414672851562 
            penalty: 0.0018337125657126307
###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.0005, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.0005, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.0005, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.0005, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.0005, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

Epoch 1/50, Training Loss: 0.3250913918018341 Val Loss: 0.2027134895324707 
            Training MAE: 0.3076833188533783 Val mae: 0.32500457763671875 
            Train epipolar error pred unormalized: 7343.9091796875 Val epipolar error pred unormalized: 11397.09375
            Train epipolar error pred: 5340.0703125 Val epipolar error pred: 6373.1337890625 
            penalty: 0.04552339017391205
Epoch 2/50, Training Loss: 0.2286580204963684 Val Loss: 0.18697959184646606 
            Training MAE: 0.2552408277988434 Val mae: 0.2500532269477844 
            Train epipolar error pred unormalized: 4210.46240234375 Val epipolar error pred unormalized: 368.6398620605469
            Train epipolar error pred: 2600.29052734375 Val epipolar error pred: 263.1768493652344 
            penalty: 0.008759194985032082
Epoch 3/50, Training Loss: 0.18468958139419556 Val Loss: 0.18775779008865356 
            Training MAE: 0.23031075298786163 Val mae: 0.2509475350379944 
            Train epipolar error pred unormalized: 3001.3017578125 Val epipolar error pred unormalized: 165.31790161132812
            Train epipolar error pred: 1406.9066162109375 Val epipolar error pred: 132.27268981933594 
            penalty: 0.002903595333918929
Epoch 4/50, Training Loss: 0.17082877457141876 Val Loss: 0.18726569414138794 
            Training MAE: 0.2209017425775528 Val mae: 0.2501925826072693 
            Train epipolar error pred unormalized: 2186.78369140625 Val epipolar error pred unormalized: 593.5945434570312
            Train epipolar error pred: 992.0440063476562 Val epipolar error pred: 364.141357421875 
            penalty: 0.01617184281349182
Epoch 5/50, Training Loss: 0.1630396693944931 Val Loss: 0.18657052516937256 
            Training MAE: 0.21496185660362244 Val mae: 0.25251930952072144 
            Train epipolar error pred unormalized: 2246.59228515625 Val epipolar error pred unormalized: 870.411376953125
            Train epipolar error pred: 1075.1607666015625 Val epipolar error pred: 518.044677734375 
            penalty: 0.009679087437689304
Epoch 6/50, Training Loss: 0.11955231428146362 Val Loss: 0.18767273426055908 
            Training MAE: 0.17175844311714172 Val mae: 0.2916449308395386 
            Train epipolar error pred unormalized: 2460.17626953125 Val epipolar error pred unormalized: 3698.200927734375
            Train epipolar error pred: 1073.0203857421875 Val epipolar error pred: 1803.82177734375 
            penalty: 0.03750604763627052
Epoch 7/50, Training Loss: 0.07843761146068573 Val Loss: 0.17540499567985535 
            Training MAE: 0.13227741420269012 Val mae: 0.24424181878566742 
            Train epipolar error pred unormalized: 2540.16455078125 Val epipolar error pred unormalized: 1391.174072265625
            Train epipolar error pred: 1025.2513427734375 Val epipolar error pred: 1079.73828125 
            penalty: 0.004937284626066685
Epoch 8/50, Training Loss: 0.05069299042224884 Val Loss: 0.17008262872695923 
            Training MAE: 0.10283364355564117 Val mae: 0.22444401681423187 
            Train epipolar error pred unormalized: 2376.671630859375 Val epipolar error pred unormalized: 556.5859985351562
            Train epipolar error pred: 907.8991088867188 Val epipolar error pred: 393.570556640625 
            penalty: 0.004678630270063877
Epoch 9/50, Training Loss: 0.04143029823899269 Val Loss: 0.18176506459712982 
            Training MAE: 0.08964518457651138 Val mae: 0.22495639324188232 
            Train epipolar error pred unormalized: 2181.036376953125 Val epipolar error pred unormalized: 916.760986328125
            Train epipolar error pred: 758.7172241210938 Val epipolar error pred: 568.5490112304688 
            penalty: 0.01177555974572897
Epoch 10/50, Training Loss: 0.036893103271722794 Val Loss: 0.16289889812469482 
            Training MAE: 0.08236584812402725 Val mae: 0.2124529778957367 
            Train epipolar error pred unormalized: 2088.655029296875 Val epipolar error pred unormalized: 710.2963256835938
            Train epipolar error pred: 676.5216674804688 Val epipolar error pred: 713.257568359375 
            penalty: 0.003740728599950671
Epoch 11/50, Training Loss: 0.032539382576942444 Val Loss: 0.16610783338546753 
            Training MAE: 0.07813718914985657 Val mae: 0.2133978009223938 
            Train epipolar error pred unormalized: 1989.010498046875 Val epipolar error pred unormalized: 557.835205078125
            Train epipolar error pred: 660.1227416992188 Val epipolar error pred: 477.9122314453125 
            penalty: 0.005398550070822239
Epoch 12/50, Training Loss: 0.030998656526207924 Val Loss: 0.16997459530830383 
            Training MAE: 0.07487896829843521 Val mae: 0.2155952900648117 
            Train epipolar error pred unormalized: 2056.16162109375 Val epipolar error pred unormalized: 640.0801391601562
            Train epipolar error pred: 635.3856811523438 Val epipolar error pred: 722.85302734375 
            penalty: 0.0014802897348999977
Epoch 13/50, Training Loss: 0.02852407842874527 Val Loss: 0.1704808473587036 
            Training MAE: 0.07083138078451157 Val mae: 0.224747896194458 
            Train epipolar error pred unormalized: 1843.156982421875 Val epipolar error pred unormalized: 274.795166015625
            Train epipolar error pred: 576.2006225585938 Val epipolar error pred: 537.4271240234375 
            penalty: 0.0037392338272184134
Epoch 14/50, Training Loss: 0.027508538216352463 Val Loss: 0.15807437896728516 
            Training MAE: 0.0697464793920517 Val mae: 0.2060007005929947 
            Train epipolar error pred unormalized: 1790.2100830078125 Val epipolar error pred unormalized: 333.86102294921875
            Train epipolar error pred: 542.025634765625 Val epipolar error pred: 405.80731201171875 
            penalty: 0.0029264322947710752
Epoch 15/50, Training Loss: 0.025419175624847412 Val Loss: 0.15962490439414978 
            Training MAE: 0.06659164279699326 Val mae: 0.21252033114433289 
            Train epipolar error pred unormalized: 1658.137939453125 Val epipolar error pred unormalized: 149.13290405273438
            Train epipolar error pred: 520.78076171875 Val epipolar error pred: 202.6670379638672 
            penalty: 0.0018087783828377724
Epoch 16/50, Training Loss: 0.027457844465970993 Val Loss: 0.17106130719184875 
            Training MAE: 0.0711563304066658 Val mae: 0.21940158307552338 
            Train epipolar error pred unormalized: 1627.8387451171875 Val epipolar error pred unormalized: 310.81378173828125
            Train epipolar error pred: 494.49127197265625 Val epipolar error pred: 254.00390625 
            penalty: 0.0033102547749876976
Epoch 17/50, Training Loss: 0.0241180919110775 Val Loss: 0.18075953423976898 
            Training MAE: 0.06395985186100006 Val mae: 0.22511813044548035 
            Train epipolar error pred unormalized: 1510.3780517578125 Val epipolar error pred unormalized: 249.35379028320312
            Train epipolar error pred: 465.0630798339844 Val epipolar error pred: 430.22210693359375 
            penalty: 0.0036765055265277624
Epoch 18/50, Training Loss: 0.02307765930891037 Val Loss: 0.17995713651180267 
            Training MAE: 0.06270057708024979 Val mae: 0.21675434708595276 
            Train epipolar error pred unormalized: 1378.61279296875 Val epipolar error pred unormalized: 229.74749755859375
            Train epipolar error pred: 418.8050231933594 Val epipolar error pred: 460.3840026855469 
            penalty: 0.003417583182454109
Epoch 19/50, Training Loss: 0.021343577653169632 Val Loss: 0.17326506972312927 
            Training MAE: 0.060231540352106094 Val mae: 0.22551991045475006 
            Train epipolar error pred unormalized: 1317.7930908203125 Val epipolar error pred unormalized: 206.8663330078125
            Train epipolar error pred: 424.4957275390625 Val epipolar error pred: 277.565185546875 
            penalty: 0.001383003662340343
Epoch 20/50, Training Loss: 0.02154814824461937 Val Loss: 0.1748734712600708 
            Training MAE: 0.05847573280334473 Val mae: 0.22035139799118042 
            Train epipolar error pred unormalized: 1244.03515625 Val epipolar error pred unormalized: 214.88926696777344
            Train epipolar error pred: 375.6794128417969 Val epipolar error pred: 430.5079040527344 
            penalty: 0.0022935494780540466
Epoch 21/50, Training Loss: 0.020385276526212692 Val Loss: 0.1687365621328354 
            Training MAE: 0.05825033783912659 Val mae: 0.21425700187683105 
            Train epipolar error pred unormalized: 1112.3848876953125 Val epipolar error pred unormalized: 159.63482666015625
            Train epipolar error pred: 354.4993896484375 Val epipolar error pred: 597.1458740234375 
            penalty: 0.0015011815121397376
Epoch 22/50, Training Loss: 0.02047341875731945 Val Loss: 0.18075554072856903 
            Training MAE: 0.05537807196378708 Val mae: 0.2550226151943207 
            Train epipolar error pred unormalized: 1121.2750244140625 Val epipolar error pred unormalized: 99.02465057373047
            Train epipolar error pred: 321.4919738769531 Val epipolar error pred: 885.9659423828125 
            penalty: 0.0021142512559890747
Epoch 23/50, Training Loss: 0.01863696426153183 Val Loss: 0.1526586413383484 
            Training MAE: 0.05292290449142456 Val mae: 0.2041328400373459 
            Train epipolar error pred unormalized: 1091.5716552734375 Val epipolar error pred unormalized: 50.80902099609375
            Train epipolar error pred: 286.7394714355469 Val epipolar error pred: 153.43942260742188 
            penalty: 0.0022938952315598726
Epoch 24/50, Training Loss: 0.018267424777150154 Val Loss: 0.1663677990436554 
            Training MAE: 0.0526251383125782 Val mae: 0.21016088128089905 
            Train epipolar error pred unormalized: 958.1126098632812 Val epipolar error pred unormalized: 90.44131469726562
            Train epipolar error pred: 259.7264404296875 Val epipolar error pred: 181.72628784179688 
            penalty: 0.0026282244361937046
Epoch 25/50, Training Loss: 0.017238624393939972 Val Loss: 0.1784699559211731 
            Training MAE: 0.05141935497522354 Val mae: 0.2360285520553589 
            Train epipolar error pred unormalized: 919.4613037109375 Val epipolar error pred unormalized: 135.41119384765625
            Train epipolar error pred: 252.9923553466797 Val epipolar error pred: 123.89662170410156 
            penalty: 0.0031673803459852934
Epoch 26/50, Training Loss: 0.018317757174372673 Val Loss: 0.16848817467689514 
            Training MAE: 0.052848607301712036 Val mae: 0.21604928374290466 
            Train epipolar error pred unormalized: 872.4968872070312 Val epipolar error pred unormalized: 75.58746337890625
            Train epipolar error pred: 240.58941650390625 Val epipolar error pred: 92.89225769042969 
            penalty: 0.0006523855845443904
Epoch 27/50, Training Loss: 0.021968785673379898 Val Loss: 0.20282065868377686 
            Training MAE: 0.057679805904626846 Val mae: 0.25825124979019165 
            Train epipolar error pred unormalized: 933.1295166015625 Val epipolar error pred unormalized: 170.34353637695312
            Train epipolar error pred: 248.81045532226562 Val epipolar error pred: 380.26239013671875 
            penalty: 0.0017195534892380238
Epoch 28/50, Training Loss: 0.019230548292398453 Val Loss: 0.18826374411582947 
            Training MAE: 0.05442288890480995 Val mae: 0.2437301129102707 
            Train epipolar error pred unormalized: 833.9743041992188 Val epipolar error pred unormalized: 1197.4288330078125
            Train epipolar error pred: 228.53298950195312 Val epipolar error pred: 1225.071533203125 
            penalty: 0.006473245099186897
###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.005, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: False

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.005, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: False

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.005, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: False

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.005, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: False

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 0.005, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: False

Epoch 1/50, Training Loss: 0.21292948722839355 Val Loss: 0.20718269050121307 
            Training MAE: 0.23516032099723816 Val mae: 0.2631676197052002 
            Train epipolar error pred unormalized: 2663.683837890625 Val epipolar error pred unormalized: 46.38941955566406
            Train epipolar error pred: 209.02268981933594 Val epipolar error pred: 67.17815399169922 
            penalty: 0.0007942126248963177
###########################################################################################################

learning rate vit: 8e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: False

Epoch 1/50, Training Loss: 0.19446095824241638 Val Loss: 0.21380320191383362 
            Training MAE: 0.24967075884342194 Val mae: 0.2590303122997284 
            Train epipolar error pred unormalized: 5729.19921875 Val epipolar error pred unormalized: 971.694580078125
            Train epipolar error pred: 2194.583740234375 Val epipolar error pred: 748.2493896484375 
            penalty: 0.023295914754271507
Epoch 2/50, Training Loss: 0.10684996843338013 Val Loss: 0.19019101560115814 
            Training MAE: 0.1439543217420578 Val mae: 0.24169312417507172 
            Train epipolar error pred unormalized: 2244.841064453125 Val epipolar error pred unormalized: 1284.3739013671875
            Train epipolar error pred: 1154.1290283203125 Val epipolar error pred: 1307.5648193359375 
            penalty: 0.014127669855952263
Epoch 3/50, Training Loss: 0.043865006417036057 Val Loss: 0.1914350986480713 
            Training MAE: 0.093010313808918 Val mae: 0.2157174050807953 
            Train epipolar error pred unormalized: 1021.3328247070312 Val epipolar error pred unormalized: 695.9801635742188
            Train epipolar error pred: 801.8573608398438 Val epipolar error pred: 699.1663208007812 
            penalty: 0.009471219964325428
Epoch 4/50, Training Loss: 0.03854554891586304 Val Loss: 0.18277162313461304 
            Training MAE: 0.07900148630142212 Val mae: 0.21926553547382355 
            Train epipolar error pred unormalized: 1102.973876953125 Val epipolar error pred unormalized: 934.3637084960938
            Train epipolar error pred: 726.2821655273438 Val epipolar error pred: 1050.218505859375 
            penalty: 0.012454189360141754
Epoch 5/50, Training Loss: 0.02402278408408165 Val Loss: 0.16807033121585846 
            Training MAE: 0.0640975683927536 Val mae: 0.21518650650978088 
            Train epipolar error pred unormalized: 700.7631225585938 Val epipolar error pred unormalized: 395.8437805175781
            Train epipolar error pred: 528.3131103515625 Val epipolar error pred: 602.182373046875 
            penalty: 0.007822878658771515
Epoch 6/50, Training Loss: 0.02385040931403637 Val Loss: 0.17944923043251038 
            Training MAE: 0.06147600710391998 Val mae: 0.20859889686107635 
            Train epipolar error pred unormalized: 649.3406982421875 Val epipolar error pred unormalized: 685.2991943359375
            Train epipolar error pred: 457.5203552246094 Val epipolar error pred: 777.578125 
            penalty: 0.005319198593497276
Epoch 7/50, Training Loss: 0.01632842980325222 Val Loss: 0.1762586086988449 
            Training MAE: 0.05245883762836456 Val mae: 0.20927485823631287 
            Train epipolar error pred unormalized: 509.341064453125 Val epipolar error pred unormalized: 432.2957763671875
            Train epipolar error pred: 403.1533203125 Val epipolar error pred: 571.4461669921875 
            penalty: 0.007489407435059547
Epoch 8/50, Training Loss: 0.015761230140924454 Val Loss: 0.18106897175312042 
            Training MAE: 0.0494694709777832 Val mae: 0.2214534878730774 
            Train epipolar error pred unormalized: 470.4402770996094 Val epipolar error pred unormalized: 495.56768798828125
            Train epipolar error pred: 356.9796447753906 Val epipolar error pred: 817.3410034179688 
            penalty: 0.004241619259119034
Epoch 9/50, Training Loss: 0.01311204768717289 Val Loss: 0.18852347135543823 
            Training MAE: 0.04611414298415184 Val mae: 0.21203453838825226 
            Train epipolar error pred unormalized: 392.19622802734375 Val epipolar error pred unormalized: 297.9064636230469
            Train epipolar error pred: 325.9708557128906 Val epipolar error pred: 511.5910339355469 
            penalty: 0.006307408679276705
Epoch 10/50, Training Loss: 0.013424194417893887 Val Loss: 0.17533235251903534 
            Training MAE: 0.04431731253862381 Val mae: 0.20907124876976013 
            Train epipolar error pred unormalized: 416.19219970703125 Val epipolar error pred unormalized: 448.1462097167969
            Train epipolar error pred: 329.2115173339844 Val epipolar error pred: 543.5614013671875 
            penalty: 0.0038730583619326353
###########################################################################################################

learning rate vit: 4e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: False

Epoch 1/50, Training Loss: 0.11794200539588928 Val Loss: 0.09086596965789795 
            Training MAE: 0.1901499330997467 Val mae: 0.1566230058670044 
            Train epipolar error pred unormalized: 964.9974365234375 Val epipolar error pred unormalized: 581.18310546875
            Train epipolar error pred: 1229.7220458984375 Val epipolar error pred: 1087.2440185546875 
            penalty: 0.011991874314844608
Epoch 2/50, Training Loss: 0.037075310945510864 Val Loss: 0.08152623474597931 
            Training MAE: 0.08795146644115448 Val mae: 0.13346274197101593 
            Train epipolar error pred unormalized: 504.6354675292969 Val epipolar error pred unormalized: 420.42730712890625
            Train epipolar error pred: 705.0798950195312 Val epipolar error pred: 721.9286499023438 
            penalty: 0.01128353737294674
Epoch 3/50, Training Loss: 0.023014983162283897 Val Loss: 0.07893592119216919 
            Training MAE: 0.06507480144500732 Val mae: 0.11914399266242981 
            Train epipolar error pred unormalized: 420.13885498046875 Val epipolar error pred unormalized: 289.3466491699219
            Train epipolar error pred: 529.0050659179688 Val epipolar error pred: 411.46575927734375 
            penalty: 0.00689743785187602
Epoch 4/50, Training Loss: 0.016084011644124985 Val Loss: 0.07116517424583435 
            Training MAE: 0.05354960262775421 Val mae: 0.11796096712350845 
            Train epipolar error pred unormalized: 312.4581298828125 Val epipolar error pred unormalized: 317.78704833984375
            Train epipolar error pred: 403.7524719238281 Val epipolar error pred: 576.1959838867188 
            penalty: 0.005782587919384241
Epoch 5/50, Training Loss: 0.0157137680798769 Val Loss: 0.06290584057569504 
            Training MAE: 0.04928261786699295 Val mae: 0.11265832185745239 
            Train epipolar error pred unormalized: 340.4488525390625 Val epipolar error pred unormalized: 172.07717895507812
            Train epipolar error pred: 388.22308349609375 Val epipolar error pred: 307.0729675292969 
            penalty: 0.0044259969145059586
Epoch 6/50, Training Loss: 0.012571609579026699 Val Loss: 0.07496409863233566 
            Training MAE: 0.045373767614364624 Val mae: 0.10658124834299088 
            Train epipolar error pred unormalized: 262.8270568847656 Val epipolar error pred unormalized: 108.72588348388672
            Train epipolar error pred: 331.0751037597656 Val epipolar error pred: 244.9437255859375 
            penalty: 0.002966193947941065
Epoch 7/50, Training Loss: 0.0109689487144351 Val Loss: 0.07569624483585358 
            Training MAE: 0.04148058965802193 Val mae: 0.11075036227703094 
            Train epipolar error pred unormalized: 235.57403564453125 Val epipolar error pred unormalized: 291.07843017578125
            Train epipolar error pred: 284.1794738769531 Val epipolar error pred: 409.5572204589844 
            penalty: 0.004393407609313726
Epoch 8/50, Training Loss: 0.009159657172858715 Val Loss: 0.07218078523874283 
            Training MAE: 0.0380907878279686 Val mae: 0.10894610732793808 
            Train epipolar error pred unormalized: 216.0359344482422 Val epipolar error pred unormalized: 242.97218322753906
            Train epipolar error pred: 265.2456970214844 Val epipolar error pred: 384.70458984375 
            penalty: 0.0043634083122015
Epoch 9/50, Training Loss: 0.008581225760281086 Val Loss: 0.07528123259544373 
            Training MAE: 0.03688894584774971 Val mae: 0.1082719936966896 
            Train epipolar error pred unormalized: 210.49102783203125 Val epipolar error pred unormalized: 164.7721405029297
            Train epipolar error pred: 259.2198181152344 Val epipolar error pred: 320.0026550292969 
            penalty: 0.002500019036233425
Epoch 10/50, Training Loss: 0.007263019680976868 Val Loss: 0.07999379187822342 
            Training MAE: 0.034469254314899445 Val mae: 0.11225759238004684 
            Train epipolar error pred unormalized: 174.1161651611328 Val epipolar error pred unormalized: 145.15000915527344
            Train epipolar error pred: 242.84567260742188 Val epipolar error pred: 288.97772216796875 
            penalty: 0.0028400311712175608
Epoch 11/50, Training Loss: 0.007734193466603756 Val Loss: 0.08440226316452026 
            Training MAE: 0.03300273045897484 Val mae: 0.11066077649593353 
            Train epipolar error pred unormalized: 196.11764526367188 Val epipolar error pred unormalized: 144.69891357421875
            Train epipolar error pred: 230.13890075683594 Val epipolar error pred: 387.9187927246094 
            penalty: 0.0023343905340880156
Epoch 12/50, Training Loss: 0.006637924816459417 Val Loss: 0.07090631872415543 
            Training MAE: 0.03224288299679756 Val mae: 0.10254935920238495 
            Train epipolar error pred unormalized: 165.9505157470703 Val epipolar error pred unormalized: 132.5675811767578
            Train epipolar error pred: 227.70689392089844 Val epipolar error pred: 335.766357421875 
            penalty: 0.0029197537805885077
Epoch 13/50, Training Loss: 0.005820928141474724 Val Loss: 0.06013565883040428 
            Training MAE: 0.02992052584886551 Val mae: 0.0990443155169487 
            Train epipolar error pred unormalized: 145.57070922851562 Val epipolar error pred unormalized: 141.07272338867188
            Train epipolar error pred: 217.26165771484375 Val epipolar error pred: 324.75506591796875 
            penalty: 0.003040311625227332
Epoch 14/50, Training Loss: 0.005542147904634476 Val Loss: 0.070610411465168 
            Training MAE: 0.029244503006339073 Val mae: 0.10252473503351212 
            Train epipolar error pred unormalized: 143.29364013671875 Val epipolar error pred unormalized: 129.18312072753906
            Train epipolar error pred: 207.38987731933594 Val epipolar error pred: 318.5694885253906 
            penalty: 0.0021210117265582085
Epoch 15/50, Training Loss: 0.005246112123131752 Val Loss: 0.07249008119106293 
            Training MAE: 0.02846347726881504 Val mae: 0.10060910135507584 
            Train epipolar error pred unormalized: 135.57040405273438 Val epipolar error pred unormalized: 166.6522216796875
            Train epipolar error pred: 201.28465270996094 Val epipolar error pred: 369.08819580078125 
            penalty: 0.0024558266159147024
Epoch 16/50, Training Loss: 0.004730393644422293 Val Loss: 0.07769132405519485 
            Training MAE: 0.02660694345831871 Val mae: 0.10452199727296829 
            Train epipolar error pred unormalized: 130.08999633789062 Val epipolar error pred unormalized: 139.75880432128906
            Train epipolar error pred: 193.8870086669922 Val epipolar error pred: 373.2899169921875 
            penalty: 0.002224025782197714
Epoch 17/50, Training Loss: 0.004222343675792217 Val Loss: 0.07198508083820343 
            Training MAE: 0.025211220607161522 Val mae: 0.09907299280166626 
            Train epipolar error pred unormalized: 115.49856567382812 Val epipolar error pred unormalized: 90.58300018310547
            Train epipolar error pred: 183.07559204101562 Val epipolar error pred: 228.76870727539062 
            penalty: 0.0016025457298383117
Epoch 18/50, Training Loss: 0.004795146640390158 Val Loss: 0.07431212067604065 
            Training MAE: 0.0260973758995533 Val mae: 0.1016184613108635 
            Train epipolar error pred unormalized: 119.1283187866211 Val epipolar error pred unormalized: 67.32389068603516
            Train epipolar error pred: 181.2581787109375 Val epipolar error pred: 245.0941925048828 
            penalty: 0.0012203851947560906
Epoch 19/50, Training Loss: 0.0038044173270463943 Val Loss: 0.0739632174372673 
            Training MAE: 0.024570709094405174 Val mae: 0.09692458808422089 
            Train epipolar error pred unormalized: 99.7254409790039 Val epipolar error pred unormalized: 93.53811645507812
            Train epipolar error pred: 169.53720092773438 Val epipolar error pred: 302.2265930175781 
            penalty: 0.0013912030262872577
Epoch 20/50, Training Loss: 0.003938020206987858 Val Loss: 0.07029455900192261 
            Training MAE: 0.024692362174391747 Val mae: 0.09608788788318634 
            Train epipolar error pred unormalized: 103.56671905517578 Val epipolar error pred unormalized: 83.95887756347656
            Train epipolar error pred: 166.47579956054688 Val epipolar error pred: 194.77325439453125 
            penalty: 0.001662207767367363
Epoch 21/50, Training Loss: 0.0041534146293997765 Val Loss: 0.06975651532411575 
            Training MAE: 0.023927364498376846 Val mae: 0.09709999710321426 
            Train epipolar error pred unormalized: 108.2242202758789 Val epipolar error pred unormalized: 80.19754791259766
            Train epipolar error pred: 166.90887451171875 Val epipolar error pred: 237.2330322265625 
            penalty: 0.001438606414012611
Epoch 22/50, Training Loss: 0.0034530027769505978 Val Loss: 0.07540249079465866 
            Training MAE: 0.022860880941152573 Val mae: 0.10140210390090942 
            Train epipolar error pred unormalized: 87.98269653320312 Val epipolar error pred unormalized: 90.96650695800781
            Train epipolar error pred: 156.35983276367188 Val epipolar error pred: 376.54583740234375 
            penalty: 0.0017417200142517686
Epoch 23/50, Training Loss: 0.0036973583046346903 Val Loss: 0.06890992820262909 
            Training MAE: 0.022799519822001457 Val mae: 0.09568632394075394 
            Train epipolar error pred unormalized: 99.60255432128906 Val epipolar error pred unormalized: 69.44073486328125
            Train epipolar error pred: 158.83953857421875 Val epipolar error pred: 208.46311950683594 
            penalty: 0.0011769609991461039
Epoch 24/50, Training Loss: 0.003185431007295847 Val Loss: 0.06805771589279175 
            Training MAE: 0.022506888955831528 Val mae: 0.09313401579856873 
            Train epipolar error pred unormalized: 76.16363525390625 Val epipolar error pred unormalized: 49.27574157714844
            Train epipolar error pred: 145.436767578125 Val epipolar error pred: 216.5572967529297 
            penalty: 0.001024992554448545
Epoch 25/50, Training Loss: 0.003130401484668255 Val Loss: 0.07367897778749466 
            Training MAE: 0.02175965905189514 Val mae: 0.09588591009378433 
            Train epipolar error pred unormalized: 78.10186767578125 Val epipolar error pred unormalized: 51.377471923828125
            Train epipolar error pred: 145.4232940673828 Val epipolar error pred: 206.31103515625 
            penalty: 0.0011876665521413088
Epoch 26/50, Training Loss: 0.0034680457320064306 Val Loss: 0.07409228384494781 
            Training MAE: 0.022379813715815544 Val mae: 0.09819716215133667 
            Train epipolar error pred unormalized: 91.06993865966797 Val epipolar error pred unormalized: 84.64402770996094
            Train epipolar error pred: 154.82937622070312 Val epipolar error pred: 208.124755859375 
            penalty: 0.0013140406226739287
Epoch 27/50, Training Loss: 0.0027315663173794746 Val Loss: 0.07275864481925964 
            Training MAE: 0.02070811577141285 Val mae: 0.0963013619184494 
            Train epipolar error pred unormalized: 72.7607421875 Val epipolar error pred unormalized: 68.71858978271484
            Train epipolar error pred: 139.79026794433594 Val epipolar error pred: 268.0389709472656 
            penalty: 0.0014245962956920266
Epoch 28/50, Training Loss: 0.002761790994554758 Val Loss: 0.07011393457651138 
            Training MAE: 0.020316222682595253 Val mae: 0.09700405597686768 
            Train epipolar error pred unormalized: 73.90343475341797 Val epipolar error pred unormalized: 70.11408233642578
            Train epipolar error pred: 137.13482666015625 Val epipolar error pred: 265.68182373046875 
            penalty: 0.0013451490085572004
Epoch 29/50, Training Loss: 0.002815062878653407 Val Loss: 0.066941998898983 
            Training MAE: 0.020181449130177498 Val mae: 0.09459277987480164 
            Train epipolar error pred unormalized: 70.76580047607422 Val epipolar error pred unormalized: 50.79185485839844
            Train epipolar error pred: 129.99757385253906 Val epipolar error pred: 238.52780151367188 
            penalty: 0.0007007983513176441
Epoch 30/50, Training Loss: 0.0043107978999614716 Val Loss: 0.06592091917991638 
            Training MAE: 0.022437136620283127 Val mae: 0.08981010317802429 
            Train epipolar error pred unormalized: 98.94475555419922 Val epipolar error pred unormalized: 53.62974548339844
            Train epipolar error pred: 145.8470458984375 Val epipolar error pred: 171.72311401367188 
            penalty: 0.001311574480496347
Epoch 31/50, Training Loss: 0.003354440676048398 Val Loss: 0.06849642843008041 
            Training MAE: 0.0208599790930748 Val mae: 0.0905352309346199 
            Train epipolar error pred unormalized: 93.56966400146484 Val epipolar error pred unormalized: 60.77951431274414
            Train epipolar error pred: 138.41690063476562 Val epipolar error pred: 151.90744018554688 
            penalty: 0.000907272391486913
Epoch 32/50, Training Loss: 0.004661728627979755 Val Loss: 0.06574715673923492 
            Training MAE: 0.021662598475813866 Val mae: 0.090853750705719 
            Train epipolar error pred unormalized: 112.33010864257812 Val epipolar error pred unormalized: 75.59429168701172
            Train epipolar error pred: 143.5241241455078 Val epipolar error pred: 244.6355438232422 
            penalty: 0.001154511352069676
Epoch 33/50, Training Loss: 0.004620898049324751 Val Loss: 0.11792708188295364 
            Training MAE: 0.02219969965517521 Val mae: 0.13634531199932098 
            Train epipolar error pred unormalized: 131.08998107910156 Val epipolar error pred unormalized: 168.91424560546875
            Train epipolar error pred: 146.6136474609375 Val epipolar error pred: 258.5920715332031 
            penalty: 0.004182098433375359
Epoch 34/50, Training Loss: 0.0030402608681470156 Val Loss: 0.06657196581363678 
            Training MAE: 0.02005022019147873 Val mae: 0.0901017040014267 
            Train epipolar error pred unormalized: 97.81560516357422 Val epipolar error pred unormalized: 70.97447967529297
            Train epipolar error pred: 132.5549774169922 Val epipolar error pred: 197.5513916015625 
            penalty: 0.0013569365255534649
Epoch 35/50, Training Loss: 0.002875911071896553 Val Loss: 0.07500141859054565 
            Training MAE: 0.01974603347480297 Val mae: 0.09577624499797821 
            Train epipolar error pred unormalized: 84.9560317993164 Val epipolar error pred unormalized: 82.63400268554688
            Train epipolar error pred: 125.40062713623047 Val epipolar error pred: 223.7073211669922 
            penalty: 0.0012463510502129793
Epoch 36/50, Training Loss: 0.0030200465116649866 Val Loss: 0.0706280767917633 
            Training MAE: 0.020377136766910553 Val mae: 0.09207779169082642 
            Train epipolar error pred unormalized: 88.03996276855469 Val epipolar error pred unormalized: 57.52389907836914
            Train epipolar error pred: 131.80442810058594 Val epipolar error pred: 204.39608764648438 
            penalty: 0.0008319918415509164
Epoch 37/50, Training Loss: 0.0033161526080220938 Val Loss: 0.06894716620445251 
            Training MAE: 0.020703228190541267 Val mae: 0.08956320583820343 
            Train epipolar error pred unormalized: 96.0758056640625 Val epipolar error pred unormalized: 88.55078125
            Train epipolar error pred: 132.61813354492188 Val epipolar error pred: 207.96588134765625 
            penalty: 0.0017101663397625089
Epoch 38/50, Training Loss: 0.0023644177708774805 Val Loss: 0.06837250292301178 
            Training MAE: 0.018454963341355324 Val mae: 0.09100926667451859 
            Train epipolar error pred unormalized: 69.55410766601562 Val epipolar error pred unormalized: 52.5983772277832
            Train epipolar error pred: 119.49278259277344 Val epipolar error pred: 208.60279846191406 
            penalty: 0.0010733201634138823
Epoch 39/50, Training Loss: 0.005161580629646778 Val Loss: 0.0679142102599144 
            Training MAE: 0.023892022669315338 Val mae: 0.0886850357055664 
            Train epipolar error pred unormalized: 119.61127471923828 Val epipolar error pred unormalized: 67.48990631103516
            Train epipolar error pred: 133.50677490234375 Val epipolar error pred: 217.08016967773438 
            penalty: 0.0014972516801208258
Epoch 40/50, Training Loss: 0.002415660535916686 Val Loss: 0.07261677086353302 
            Training MAE: 0.017950836569070816 Val mae: 0.09425268322229385 
            Train epipolar error pred unormalized: 73.5112533569336 Val epipolar error pred unormalized: 68.03703308105469
            Train epipolar error pred: 115.79691314697266 Val epipolar error pred: 253.86146545410156 
            penalty: 0.0008299167384393513
Epoch 41/50, Training Loss: 0.003456525504589081 Val Loss: 0.07199431210756302 
            Training MAE: 0.020281299948692322 Val mae: 0.09434279799461365 
            Train epipolar error pred unormalized: 93.7514877319336 Val epipolar error pred unormalized: 50.54214859008789
            Train epipolar error pred: 129.35873413085938 Val epipolar error pred: 164.8364715576172 
            penalty: 0.0012517294380813837
Epoch 42/50, Training Loss: 0.002241003094241023 Val Loss: 0.07273200899362564 
            Training MAE: 0.018241291865706444 Val mae: 0.09055642038583755 
            Train epipolar error pred unormalized: 67.36241912841797 Val epipolar error pred unormalized: 40.56182098388672
            Train epipolar error pred: 115.52581787109375 Val epipolar error pred: 197.84498596191406 
            penalty: 0.0005630003288388252
Epoch 43/50, Training Loss: 0.00213575828820467 Val Loss: 0.07997659593820572 
            Training MAE: 0.018089959397912025 Val mae: 0.10576363652944565 
            Train epipolar error pred unormalized: 56.36682891845703 Val epipolar error pred unormalized: 81.76775360107422
            Train epipolar error pred: 107.6051025390625 Val epipolar error pred: 262.865478515625 
            penalty: 0.002153164939954877
Epoch 44/50, Training Loss: 0.0022303115110844374 Val Loss: 0.0726848766207695 
            Training MAE: 0.01805991865694523 Val mae: 0.09555411338806152 
            Train epipolar error pred unormalized: 57.821781158447266 Val epipolar error pred unormalized: 42.208045959472656
            Train epipolar error pred: 112.08721160888672 Val epipolar error pred: 198.33642578125 
            penalty: 0.0008831122540868819
Epoch 45/50, Training Loss: 0.0030192723497748375 Val Loss: 0.08299635350704193 
            Training MAE: 0.01855185255408287 Val mae: 0.09951485693454742 
            Train epipolar error pred unormalized: 71.24691772460938 Val epipolar error pred unormalized: 73.62787628173828
            Train epipolar error pred: 114.28230285644531 Val epipolar error pred: 192.53179931640625 
            penalty: 0.001337836030870676
Epoch 46/50, Training Loss: 0.0022786471527069807 Val Loss: 0.07734119147062302 
            Training MAE: 0.017139581963419914 Val mae: 0.09550751000642776 
            Train epipolar error pred unormalized: 61.26624298095703 Val epipolar error pred unormalized: 43.91506576538086
            Train epipolar error pred: 107.48490905761719 Val epipolar error pred: 216.31216430664062 
            penalty: 0.000628907757345587
Epoch 47/50, Training Loss: 0.002053511328995228 Val Loss: 0.07470189034938812 
            Training MAE: 0.017133451998233795 Val mae: 0.09236668050289154 
            Train epipolar error pred unormalized: 61.36624526977539 Val epipolar error pred unormalized: 55.58998489379883
            Train epipolar error pred: 109.865966796875 Val epipolar error pred: 194.41966247558594 
            penalty: 0.0006163379293866456
Epoch 48/50, Training Loss: 0.0018786962609738111 Val Loss: 0.07170234620571136 
            Training MAE: 0.0165527556091547 Val mae: 0.09143971651792526 
            Train epipolar error pred unormalized: 53.38945388793945 Val epipolar error pred unormalized: 63.049373626708984
            Train epipolar error pred: 103.83383178710938 Val epipolar error pred: 172.95375061035156 
            penalty: 0.0007658753311261535
Epoch 49/50, Training Loss: 0.0019750904757529497 Val Loss: 0.07549536973237991 
            Training MAE: 0.017073990777134895 Val mae: 0.0920419842004776 
            Train epipolar error pred unormalized: 53.95402526855469 Val epipolar error pred unormalized: 43.12057876586914
            Train epipolar error pred: 109.32737731933594 Val epipolar error pred: 193.26467895507812 
            penalty: 0.0007963155512697995
Epoch 50/50, Training Loss: 0.0016953422455117106 Val Loss: 0.07824894785881042 
            Training MAE: 0.01600729301571846 Val mae: 0.09645441174507141 
            Train epipolar error pred unormalized: 44.36003112792969 Val epipolar error pred unormalized: 35.112396240234375
            Train epipolar error pred: 101.61502075195312 Val epipolar error pred: 201.40135192871094 
            penalty: 0.0007794706616550684
Train unormalized ground truth error: 0.0010376219567842782 val unormalized ground truth error: 0.0007065878598950803
=======
###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: False

Epoch 1/3, Training Loss: 0.2933640778064728 Val Loss: 0.1449078768491745 
            Training MAE: 0.3023155629634857 Val mae: 0.23050442337989807 
            Train epipolar error pred unormalized: 623.0881958007812 Val epipolar error pred unormalized: 1040.597900390625
            Train epipolar error pred: 3259.069091796875 Val epipolar error pred: 1381.06494140625 
            penalty: 0.06985466927289963
Epoch 2/3, Training Loss: 0.299543172121048 Val Loss: 0.14221324026584625 
            Training MAE: 0.25819408893585205 Val mae: 0.224522665143013 
            Train epipolar error pred unormalized: 1452.2186279296875 Val epipolar error pred unormalized: 1937.7835693359375
            Train epipolar error pred: 1853.0699462890625 Val epipolar error pred: 2489.714599609375 
            penalty: 0.14936016499996185
Epoch 3/3, Training Loss: 0.2763051688671112 Val Loss: 0.15907220542430878 
            Training MAE: 0.22447197139263153 Val mae: 0.23310816287994385 
            Train epipolar error pred unormalized: 2519.497802734375 Val epipolar error pred unormalized: 4203.84228515625
            Train epipolar error pred: 3216.007080078125 Val epipolar error pred: 5260.56884765625 
            penalty: 0.101748526096344
Train unormalized ground truth error: 0.00012660736683756113 val unormalized ground truth error: 0.00012660736683756113


###########################################################################################################

###########################################################################################################

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: False

Epoch 1/12, Training Loss: 0.3108733594417572 Val Loss: 0.16730976104736328 
            Training MAE: 0.39735546708106995 Val mae: 0.3309977054595947 
            Train epipolar error pred unormalized: 3060.099853515625 Val epipolar error pred unormalized: 5016.75244140625
            Train epipolar error pred: 10760.9453125 Val epipolar error pred: 8449.6181640625 
            penalty: 0.133424773812294
Epoch 2/12, Training Loss: 0.30308735370635986 Val Loss: 0.1947183609008789 
            Training MAE: 0.3541819155216217 Val mae: 0.36004239320755005 
            Train epipolar error pred unormalized: 5446.41357421875 Val epipolar error pred unormalized: 5215.87060546875
            Train epipolar error pred: 8655.8427734375 Val epipolar error pred: 8918.5859375 
            penalty: 0.19647885859012604
Epoch 3/12, Training Loss: 0.32648494839668274 Val Loss: 0.2051672786474228 
            Training MAE: 0.38429057598114014 Val mae: 0.36947327852249146 
            Train epipolar error pred unormalized: 3470.880126953125 Val epipolar error pred unormalized: 922.482421875
            Train epipolar error pred: 6204.779296875 Val epipolar error pred: 1511.4039306640625 
            penalty: 0.18994687497615814
Epoch 4/12, Training Loss: 0.3689647912979126 Val Loss: 0.18341533839702606 
            Training MAE: 0.38287150859832764 Val mae: 0.36956027150154114 
            Train epipolar error pred unormalized: 908.2820434570312 Val epipolar error pred unormalized: 2030.5308837890625
            Train epipolar error pred: 1557.8052978515625 Val epipolar error pred: 3817.697998046875 
            penalty: 0.06715447455644608
Epoch 5/12, Training Loss: 0.28084373474121094 Val Loss: 0.15842051804065704 
            Training MAE: 0.38428664207458496 Val mae: 0.3444201648235321 
            Train epipolar error pred unormalized: 3275.848388671875 Val epipolar error pred unormalized: 5104.24169921875
            Train epipolar error pred: 6300.79931640625 Val epipolar error pred: 8714.6064453125 
            penalty: 0.13131140172481537
Epoch 6/12, Training Loss: 0.2890610992908478 Val Loss: 0.1512400060892105 
            Training MAE: 0.3217153251171112 Val mae: 0.30732232332229614 
            Train epipolar error pred unormalized: 4004.8359375 Val epipolar error pred unormalized: 1677.5123291015625
            Train epipolar error pred: 6695.216796875 Val epipolar error pred: 3267.208251953125 
            penalty: 0.09532814472913742
Epoch 7/12, Training Loss: 0.2546672821044922 Val Loss: 0.1714382916688919 
            Training MAE: 0.3135356903076172 Val mae: 0.33280739188194275 
            Train epipolar error pred unormalized: 2448.25927734375 Val epipolar error pred unormalized: 3611.833740234375
            Train epipolar error pred: 4914.74365234375 Val epipolar error pred: 7596.037109375 
            penalty: 0.09169726818799973
Epoch 8/12, Training Loss: 0.2681712806224823 Val Loss: 0.13728052377700806 
            Training MAE: 0.3344951570034027 Val mae: 0.29524141550064087 
            Train epipolar error pred unormalized: 2243.668701171875 Val epipolar error pred unormalized: 868.2623901367188
            Train epipolar error pred: 5042.66943359375 Val epipolar error pred: 2029.697265625 
            penalty: 0.026088116690516472
Epoch 9/12, Training Loss: 0.16398680210113525 Val Loss: 0.09091705083847046 
            Training MAE: 0.3189847469329834 Val mae: 0.26142242550849915 
            Train epipolar error pred unormalized: 841.4619750976562 Val epipolar error pred unormalized: 1032.7113037109375
            Train epipolar error pred: 2293.786376953125 Val epipolar error pred: 2632.646240234375 
            penalty: 0.09267259389162064
Epoch 10/12, Training Loss: 0.20047910511493683 Val Loss: 0.05199761688709259 
            Training MAE: 0.2759087085723877 Val mae: 0.16917505860328674 
            Train epipolar error pred unormalized: 1319.511962890625 Val epipolar error pred unormalized: 1555.05859375
            Train epipolar error pred: 3603.197509765625 Val epipolar error pred: 4533.1376953125 
            penalty: 0.042587827891111374
Epoch 11/12, Training Loss: 0.11192956566810608 Val Loss: 0.03311247006058693 
            Training MAE: 0.18024571239948273 Val mae: 0.15269029140472412 
            Train epipolar error pred unormalized: 1434.6168212890625 Val epipolar error pred unormalized: 1055.3934326171875
            Train epipolar error pred: 4517.37060546875 Val epipolar error pred: 3795.700927734375 
            penalty: 0.030226662755012512
Epoch 12/12, Training Loss: 0.057422515004873276 Val Loss: 0.03522401675581932 
            Training MAE: 0.15771350264549255 Val mae: 0.15466216206550598 
            Train epipolar error pred unormalized: 804.244384765625 Val epipolar error pred unormalized: 1500.8853759765625
            Train epipolar error pred: 2903.867431640625 Val epipolar error pred: 5192.53955078125 
            penalty: 0.04869530722498894
Train unormalized ground truth error: 0.00012660736683756113 val unormalized ground truth error: 0.00012660736683756113


###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: False

Epoch 1/2, Training Loss: 0.29122278094291687 Val Loss: 0.19045375287532806 
            Training MAE: 0.35098978877067566 Val mae: 0.34793752431869507 
            Train epipolar error pred unormalized: 3441.546875 Val epipolar error pred unormalized: 5189.85400390625
            Train epipolar error pred: 6545.93017578125 Val epipolar error pred: 6929.17236328125 
            penalty: 0.19233769178390503
Epoch 2/2, Training Loss: 0.32319143414497375 Val Loss: 0.1618441492319107 
            Training MAE: 0.3252789080142975 Val mae: 0.28953081369400024 
            Train epipolar error pred unormalized: 5911.70947265625 Val epipolar error pred unormalized: 5828.95458984375
            Train epipolar error pred: 7943.10400390625 Val epipolar error pred: 8661.1083984375 
            penalty: 0.13338787853717804
Train unormalized ground truth error: 0.00012660736683756113 val unormalized ground truth error: 0.00012660736683756113


###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: False

Epoch 1/2, Training Loss: 0.3559516668319702 Val Loss: 0.2067410945892334 
            Training MAE: 0.4267454147338867 Val mae: 0.34863904118537903 
            Train epipolar error pred unormalized: 3208.873046875 Val epipolar error pred unormalized: 7483.96337890625
            Train epipolar error pred: 8071.31494140625 Val epipolar error pred: 8484.009765625 
            penalty: 0.15764372050762177
Epoch 2/2, Training Loss: 0.338525652885437 Val Loss: 0.1873374730348587 
            Training MAE: 0.3643489181995392 Val mae: 0.3732762038707733 
            Train epipolar error pred unormalized: 7892.04248046875 Val epipolar error pred unormalized: 6895.46337890625
            Train epipolar error pred: 8289.5673828125 Val epipolar error pred: 6598.00927734375 
            penalty: 0.3432297706604004
Train unormalized ground truth error: 0.00012660736683756113 val unormalized ground truth error: 0.00012660736683756113


###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: False

Epoch 1/2, Training Loss: 0.36788806319236755 Val Loss: 0.2016056329011917 
            Training MAE: 0.4127899706363678 Val mae: 0.3498282730579376 
            Train epipolar error pred unormalized: 3693.410400390625 Val epipolar error pred unormalized: 7263.54345703125
            Train epipolar error pred: 12363.515625 Val epipolar error pred: 11852.3271484375 
            penalty: 0.12476718425750732
Epoch 2/2, Training Loss: 0.35991084575653076 Val Loss: 0.18144220113754272 
            Training MAE: 0.3590430021286011 Val mae: 0.32749825716018677 
            Train epipolar error pred unormalized: 7661.02490234375 Val epipolar error pred unormalized: 6698.55615234375
            Train epipolar error pred: 12489.53515625 Val epipolar error pred: 8938.0 
            penalty: 0.1346837282180786
Train unormalized ground truth error: 0.00012660736683756113 val unormalized ground truth error: 0.00012660736683756113


learning rate vit: 2e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: False

Epoch 1/2, Training Loss: 0.17914944887161255 Val Loss: 0.11576812714338303 
            Training MAE: 0.2598998546600342 Val mae: 0.22895674407482147 
            Train epipolar error pred unormalized: 693.3423461914062 Val epipolar error pred unormalized: 1245.8082275390625
            Train epipolar error pred: 2001.7867431640625 Val epipolar error pred: 1471.3538818359375 
            penalty: 0.08741501718759537
Epoch 2/2, Training Loss: 0.25102198123931885 Val Loss: 0.13291403651237488 
            Training MAE: 0.26425182819366455 Val mae: 0.27492573857307434 
            Train epipolar error pred unormalized: 4201.32177734375 Val epipolar error pred unormalized: 958.8648681640625
            Train epipolar error pred: 4042.53125 Val epipolar error pred: 1018.919921875 
            penalty: 0.23926137387752533
Train unormalized ground truth error: 0.0005193096585571766 val unormalized ground truth error: 0.0005365349934436381


###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: False

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: False

Epoch 1/50, Training Loss: 0.10100015252828598 Val Loss: 0.02762346714735031
            Training MAE: 0.1658552885055542 Val mae: 0.0945136696100235 
            Train epipolar error pred unormalized: 795.7977294921875 Val epipolar error pred unormalized: 403.88812255859375
            Train epipolar error pred: 1358.13525390625 Val epipolar error pred: 697.1650390625 
            penalty: 0.016087602823972702
Epoch 2/50, Training Loss: 0.028341764584183693 Val Loss: 0.01044163852930069 
            Training MAE: 0.07284675538539886 Val mae: 0.05702323094010353 
            Train epipolar error pred unormalized: 366.2518310546875 Val epipolar error pred unormalized: 222.7277069091797
            Train epipolar error pred: 656.1468505859375 Val epipolar error pred: 366.246826171875 
            penalty: 0.01130632497370243
Epoch 3/50, Training Loss: 0.017520157620310783 Val Loss: 0.007157071493566036 
            Training MAE: 0.05466115102171898 Val mae: 0.04660956561565399 
            Train epipolar error pred unormalized: 253.2088623046875 Val epipolar error pred unormalized: 199.69798278808594
            Train epipolar error pred: 441.07568359375 Val epipolar error pred: 351.1922302246094 
            penalty: 0.0066855535842478275
Epoch 4/50, Training Loss: 0.012700431048870087 Val Loss: 0.007472819183021784 
            Training MAE: 0.04619750380516052 Val mae: 0.043781328946352005 
            Train epipolar error pred unormalized: 193.73121643066406 Val epipolar error pred unormalized: 133.14767456054688
            Train epipolar error pred: 354.8248291015625 Val epipolar error pred: 260.5107116699219 
            penalty: 0.003941394854336977
Epoch 5/50, Training Loss: 0.010305597446858883 Val Loss: 0.0057420311495661736 
            Training MAE: 0.04058919847011566 Val mae: 0.0408368855714798 
            Train epipolar error pred unormalized: 150.63272094726562 Val epipolar error pred unormalized: 96.71234893798828
            Train epipolar error pred: 286.38385009765625 Val epipolar error pred: 175.28038024902344 
            penalty: 0.002611033385619521
Epoch 6/50, Training Loss: 0.008732588030397892 Val Loss: 0.004687928594648838 
            Training MAE: 0.036754805594682693 Val mae: 0.03846348449587822 
            Train epipolar error pred unormalized: 140.70364379882812 Val epipolar error pred unormalized: 108.25762939453125
            Train epipolar error pred: 255.47808837890625 Val epipolar error pred: 218.55967712402344 
            penalty: 0.003697590436786413
Epoch 7/50, Training Loss: 0.007019691169261932 Val Loss: 0.003447365015745163 
            Training MAE: 0.03374399244785309 Val mae: 0.03388763219118118 
            Train epipolar error pred unormalized: 113.835693359375 Val epipolar error pred unormalized: 167.28814697265625
            Train epipolar error pred: 230.6724395751953 Val epipolar error pred: 333.97857666015625 
            penalty: 0.0032888210844248533
Epoch 8/50, Training Loss: 0.005698028020560741 Val Loss: 0.004881454166024923 
            Training MAE: 0.030746113508939743 Val mae: 0.03525424748659134 
            Train epipolar error pred unormalized: 104.09236145019531 Val epipolar error pred unormalized: 146.8708953857422
            Train epipolar error pred: 219.54531860351562 Val epipolar error pred: 242.712646484375 
            penalty: 0.003617501351982355
Epoch 9/50, Training Loss: 0.005745179485529661 Val Loss: 0.0024830440524965525 
            Training MAE: 0.0301582682877779 Val mae: 0.030025847256183624 
            Train epipolar error pred unormalized: 99.63423919677734 Val epipolar error pred unormalized: 103.25393676757812
            Train epipolar error pred: 204.56895446777344 Val epipolar error pred: 178.0123748779297 
            penalty: 0.0029751439578831196
Epoch 10/50, Training Loss: 0.004966775421053171 Val Loss: 0.004094922915101051 
            Training MAE: 0.02814950793981552 Val mae: 0.03541901707649231 
            Train epipolar error pred unormalized: 93.55432891845703 Val epipolar error pred unormalized: 166.20018005371094
            Train epipolar error pred: 197.488525390625 Val epipolar error pred: 378.6466064453125 
            penalty: 0.0037785868626087904
Epoch 11/50, Training Loss: 0.005224181339144707 Val Loss: 0.0022498629987239838 
            Training MAE: 0.028430895879864693 Val mae: 0.027323352172970772 
            Train epipolar error pred unormalized: 106.58673858642578 Val epipolar error pred unormalized: 94.40406036376953
            Train epipolar error pred: 209.99082946777344 Val epipolar error pred: 217.87110900878906 
            penalty: 0.0024440607521682978
Epoch 12/50, Training Loss: 0.004131763242185116 Val Loss: 0.0025986316613852978 
            Training MAE: 0.026033174246549606 Val mae: 0.0262665506452322 
            Train epipolar error pred unormalized: 83.36363220214844 Val epipolar error pred unormalized: 100.89042663574219
            Train epipolar error pred: 186.75033569335938 Val epipolar error pred: 198.67381286621094 
            penalty: 0.0023613683879375458
Epoch 13/50, Training Loss: 0.003696833737194538 Val Loss: 0.001990571850910783 
            Training MAE: 0.023906487971544266 Val mae: 0.02371739037334919 
            Train epipolar error pred unormalized: 70.98436737060547 Val epipolar error pred unormalized: 66.08524322509766
            Train epipolar error pred: 168.8402862548828 Val epipolar error pred: 173.2865447998047 
            penalty: 0.0011657900176942348
###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: False

Epoch 1/50, Training Loss: 0.10922657698392868 Val Loss: 0.027291569858789444 
            Training MAE: 0.18275319039821625 Val mae: 0.09591963142156601 
            Train epipolar error pred unormalized: 1140.65576171875 Val epipolar error pred unormalized: 511.12689208984375
            Train epipolar error pred: 2017.6295166015625 Val epipolar error pred: 1153.7144775390625 
            penalty: 0.01484776008874178
Epoch 2/50, Training Loss: 0.03049200400710106 Val Loss: 0.016410578042268753 
            Training MAE: 0.08199456334114075 Val mae: 0.07489504665136337 
            Train epipolar error pred unormalized: 405.5845031738281 Val epipolar error pred unormalized: 415.5594787597656
            Train epipolar error pred: 879.6685180664062 Val epipolar error pred: 847.4464111328125 
            penalty: 0.011523480527102947
Epoch 3/50, Training Loss: 0.0224769227206707 Val Loss: 0.01050721574574709 
            Training MAE: 0.06642086058855057 Val mae: 0.056330010294914246 
            Train epipolar error pred unormalized: 365.1227111816406 Val epipolar error pred unormalized: 442.4737854003906
            Train epipolar error pred: 660.0643310546875 Val epipolar error pred: 734.8494873046875 
            penalty: 0.007365198340266943
Epoch 4/50, Training Loss: 0.01717470772564411 Val Loss: 0.007454792037606239 
            Training MAE: 0.055116306990385056 Val mae: 0.046371955424547195 
            Train epipolar error pred unormalized: 311.4229431152344 Val epipolar error pred unormalized: 220.40089416503906
            Train epipolar error pred: 536.199951171875 Val epipolar error pred: 402.3436584472656 
            penalty: 0.004479382187128067
Epoch 5/50, Training Loss: 0.012913018465042114 Val Loss: 0.006161849945783615 
            Training MAE: 0.0478425994515419 Val mae: 0.04274218901991844 
            Train epipolar error pred unormalized: 232.79873657226562 Val epipolar error pred unormalized: 195.97499084472656
            Train epipolar error pred: 439.3043212890625 Val epipolar error pred: 321.4923400878906 
            penalty: 0.005283792968839407
Epoch 6/50, Training Loss: 0.011077514849603176 Val Loss: 0.005425549112260342 
            Training MAE: 0.04367102310061455 Val mae: 0.040469568222761154 
            Train epipolar error pred unormalized: 209.17916870117188 Val epipolar error pred unormalized: 213.79290771484375
            Train epipolar error pred: 386.6138610839844 Val epipolar error pred: 349.4812927246094 
            penalty: 0.0034375812392681837
Epoch 7/50, Training Loss: 0.009479295462369919 Val Loss: 0.005213203839957714 
            Training MAE: 0.03979627415537834 Val mae: 0.03706125169992447 
            Train epipolar error pred unormalized: 192.8422393798828 Val epipolar error pred unormalized: 171.1382293701172
            Train epipolar error pred: 368.3885803222656 Val epipolar error pred: 316.6381530761719 
            penalty: 0.00425751693546772
Epoch 8/50, Training Loss: 0.007867773994803429 Val Loss: 0.004548297263681889 
            Training MAE: 0.037047095596790314 Val mae: 0.035918448120355606 
            Train epipolar error pred unormalized: 177.33062744140625 Val epipolar error pred unormalized: 124.50861358642578
            Train epipolar error pred: 345.24517822265625 Val epipolar error pred: 289.13665771484375 
            penalty: 0.0029295156709849834
Epoch 9/50, Training Loss: 0.00751281064003706 Val Loss: 0.0031320916023105383 
            Training MAE: 0.03506810963153839 Val mae: 0.029515529051423073 
            Train epipolar error pred unormalized: 166.44883728027344 Val epipolar error pred unormalized: 143.14581298828125
            Train epipolar error pred: 313.1835021972656 Val epipolar error pred: 319.4180603027344 
            penalty: 0.0026829615235328674
Epoch 10/50, Training Loss: 0.007914415560662746 Val Loss: 0.003295663045719266 
            Training MAE: 0.03535962104797363 Val mae: 0.03040853515267372 
            Train epipolar error pred unormalized: 176.06253051757812 Val epipolar error pred unormalized: 202.5478515625
            Train epipolar error pred: 324.7934265136719 Val epipolar error pred: 311.19317626953125 
            penalty: 0.005810871720314026
Epoch 11/50, Training Loss: 0.005952825769782066 Val Loss: 0.004155704751610756 
            Training MAE: 0.03111950494349003 Val mae: 0.03183078393340111 
            Train epipolar error pred unormalized: 136.25408935546875 Val epipolar error pred unormalized: 135.8310546875
            Train epipolar error pred: 268.6977844238281 Val epipolar error pred: 289.2872619628906 
            penalty: 0.0029047897551208735
Epoch 12/50, Training Loss: 0.006457122508436441 Val Loss: 0.00517602264881134 
            Training MAE: 0.031227700412273407 Val mae: 0.03572653606534004 
            Train epipolar error pred unormalized: 145.37771606445312 Val epipolar error pred unormalized: 194.06898498535156
            Train epipolar error pred: 267.8941345214844 Val epipolar error pred: 328.6513366699219 
            penalty: 0.005421441979706287
Epoch 13/50, Training Loss: 0.005277945660054684 Val Loss: 0.0031435166019946337 
            Training MAE: 0.02866246923804283 Val mae: 0.028412962332367897 
            Train epipolar error pred unormalized: 132.00064086914062 Val epipolar error pred unormalized: 106.52781677246094
            Train epipolar error pred: 244.88690185546875 Val epipolar error pred: 215.92880249023438 
            penalty: 0.0019694401416927576
Epoch 14/50, Training Loss: 0.0050129941664636135 Val Loss: 0.0032071052119135857 
            Training MAE: 0.028430558741092682 Val mae: 0.029052628204226494 
            Train epipolar error pred unormalized: 115.56690979003906 Val epipolar error pred unormalized: 105.228759765625
            Train epipolar error pred: 241.92037963867188 Val epipolar error pred: 250.91323852539062 
            penalty: 0.0019344114698469639
Epoch 15/50, Training Loss: 0.005045635160058737 Val Loss: 0.002910235431045294 
            Training MAE: 0.0283769890666008 Val mae: 0.026997823268175125 
            Train epipolar error pred unormalized: 117.96055603027344 Val epipolar error pred unormalized: 124.3416748046875
            Train epipolar error pred: 249.45883178710938 Val epipolar error pred: 260.4337463378906 
            penalty: 0.00212110485881567
Epoch 16/50, Training Loss: 0.004175148904323578 Val Loss: 0.002596429083496332 
            Training MAE: 0.025907550007104874 Val mae: 0.025102343410253525 
            Train epipolar error pred unormalized: 89.61222839355469 Val epipolar error pred unormalized: 73.03216552734375
            Train epipolar error pred: 209.43572998046875 Val epipolar error pred: 158.72511291503906 
            penalty: 0.001595978857949376
Epoch 17/50, Training Loss: 0.006313493940979242 Val Loss: 0.0023893227335065603 
            Training MAE: 0.028378143906593323 Val mae: 0.02566816657781601 
            Train epipolar error pred unormalized: 150.6282958984375 Val epipolar error pred unormalized: 116.31846618652344
            Train epipolar error pred: 249.84043884277344 Val epipolar error pred: 226.93084716796875 
            penalty: 0.0017134679947048426
Epoch 18/50, Training Loss: 0.0041794744320213795 Val Loss: 0.002232540398836136 
            Training MAE: 0.02447175234556198 Val mae: 0.022395743057131767 
            Train epipolar error pred unormalized: 106.94794464111328 Val epipolar error pred unormalized: 69.86553955078125
            Train epipolar error pred: 206.52810668945312 Val epipolar error pred: 162.9088592529297 
            penalty: 0.0016090135322883725
Epoch 19/50, Training Loss: 0.003633128246292472 Val Loss: 0.002795999404042959 
            Training MAE: 0.023559389635920525 Val mae: 0.0257866270840168 
            Train epipolar error pred unormalized: 85.94641876220703 Val epipolar error pred unormalized: 73.64729309082031
            Train epipolar error pred: 196.67990112304688 Val epipolar error pred: 187.93301391601562 
            penalty: 0.0011832562740892172
Epoch 20/50, Training Loss: 0.003572269110009074 Val Loss: 0.002495436230674386 
            Training MAE: 0.024421799927949905 Val mae: 0.025690050795674324 
            Train epipolar error pred unormalized: 85.47112274169922 Val epipolar error pred unormalized: 89.17583465576172
            Train epipolar error pred: 200.6885986328125 Val epipolar error pred: 207.88052368164062 
            penalty: 0.0016220740508288145
Epoch 21/50, Training Loss: 0.003290379885584116 Val Loss: 0.0024071899242699146 
            Training MAE: 0.023538554087281227 Val mae: 0.02463301457464695 
            Train epipolar error pred unormalized: 81.0796127319336 Val epipolar error pred unormalized: 111.0223159790039
            Train epipolar error pred: 192.3763885498047 Val epipolar error pred: 246.236572265625 
            penalty: 0.0016295666573569179
Train unormalized ground truth error: 0.0010218295335237468 val unormalized ground truth error: 0.0010053319856524467


learning rate vit: 2e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: False

Epoch 1/50, Training Loss: 0.09048722684383392 Val Loss: 0.020896177738904953 
            Training MAE: 0.15591426193714142 Val mae: 0.0778857097029686 
            Train epipolar error pred unormalized: 652.7277221679688 Val epipolar error pred unormalized: 375.6242370605469
            Train epipolar error pred: 1288.9532470703125 Val epipolar error pred: 697.5457153320312 
            penalty: 0.009811521507799625
Epoch 2/50, Training Loss: 0.028496621176600456 Val Loss: 0.010763789527118206 
            Training MAE: 0.07290324568748474 Val mae: 0.054918136447668076 
            Train epipolar error pred unormalized: 379.1650695800781 Val epipolar error pred unormalized: 209.55538940429688
            Train epipolar error pred: 656.9176635742188 Val epipolar error pred: 374.1922607421875 
            penalty: 0.005658609792590141
Epoch 3/50, Training Loss: 0.01744038611650467 Val Loss: 0.008205978199839592 
            Training MAE: 0.05457458272576332 Val mae: 0.05091101676225662 
            Train epipolar error pred unormalized: 278.5520324707031 Val epipolar error pred unormalized: 325.3012390136719
            Train epipolar error pred: 501.7152404785156 Val epipolar error pred: 582.6881103515625 
            penalty: 0.00816886406391859
Epoch 4/50, Training Loss: 0.01691594533622265 Val Loss: 0.0072778742760419846 
            Training MAE: 0.049701422452926636 Val mae: 0.045188724994659424 
            Train epipolar error pred unormalized: 295.02667236328125 Val epipolar error pred unormalized: 219.10415649414062
            Train epipolar error pred: 450.123291015625 Val epipolar error pred: 378.4447937011719 
            penalty: 0.004846398252993822
Epoch 5/50, Training Loss: 0.01167421042919159 Val Loss: 0.004843748174607754 
            Training MAE: 0.0428270623087883 Val mae: 0.040312569588422775 
            Train epipolar error pred unormalized: 225.01405334472656 Val epipolar error pred unormalized: 180.51231384277344
            Train epipolar error pred: 383.777099609375 Val epipolar error pred: 274.0130615234375 
            penalty: 0.00500471843406558
Epoch 6/50, Training Loss: 0.00891425833106041 Val Loss: 0.0036819209344685078 
            Training MAE: 0.0374651737511158 Val mae: 0.03409803658723831 
            Train epipolar error pred unormalized: 191.67640686035156 Val epipolar error pred unormalized: 150.11013793945312
            Train epipolar error pred: 348.107666015625 Val epipolar error pred: 247.1439971923828 
            penalty: 0.004465199541300535
Epoch 7/50, Training Loss: 0.007799271959811449 Val Loss: 0.004767125938087702 
            Training MAE: 0.03521743789315224 Val mae: 0.03231344744563103 
            Train epipolar error pred unormalized: 157.00572204589844 Val epipolar error pred unormalized: 120.9783706665039
            Train epipolar error pred: 302.93634033203125 Val epipolar error pred: 218.83477783203125 
            penalty: 0.002867802744731307
Epoch 8/50, Training Loss: 0.007132814731448889 Val Loss: 0.004683263599872589 
            Training MAE: 0.0321822427213192 Val mae: 0.03659810125827789 
            Train epipolar error pred unormalized: 172.65403747558594 Val epipolar error pred unormalized: 184.2611541748047
            Train epipolar error pred: 285.3351135253906 Val epipolar error pred: 309.36785888671875 
            penalty: 0.003926074132323265
Epoch 9/50, Training Loss: 0.00627649761736393 Val Loss: 0.0031017435248941183 
            Training MAE: 0.03112739510834217 Val mae: 0.0292753204703331 
            Train epipolar error pred unormalized: 141.54087829589844 Val epipolar error pred unormalized: 125.8751220703125
            Train epipolar error pred: 255.94778442382812 Val epipolar error pred: 227.3009490966797 
            penalty: 0.002487678313627839
Epoch 10/50, Training Loss: 0.005351333878934383 Val Loss: 0.0034964035730808973 
            Training MAE: 0.028856465592980385 Val mae: 0.02889200672507286 
            Train epipolar error pred unormalized: 121.81848907470703 Val epipolar error pred unormalized: 220.78244018554688
            Train epipolar error pred: 242.33041381835938 Val epipolar error pred: 359.7962646484375 
            penalty: 0.0031758788973093033
Epoch 11/50, Training Loss: 0.004852276761084795 Val Loss: 0.002777524758130312 
            Training MAE: 0.026957521215081215 Val mae: 0.026538437232375145 
            Train epipolar error pred unormalized: 110.97775268554688 Val epipolar error pred unormalized: 104.386962890625
            Train epipolar error pred: 222.2299041748047 Val epipolar error pred: 188.31561279296875 
            penalty: 0.0024837555829435587
Epoch 12/50, Training Loss: 0.004495634231716394 Val Loss: 0.002220767317339778 
            Training MAE: 0.026491675525903702 Val mae: 0.024472156539559364 
            Train epipolar error pred unormalized: 101.61204528808594 Val epipolar error pred unormalized: 106.67070007324219
            Train epipolar error pred: 209.8246307373047 Val epipolar error pred: 195.80186462402344 
            penalty: 0.002102777361869812
Epoch 13/50, Training Loss: 0.00399414636194706 Val Loss: 0.002071134280413389 
            Training MAE: 0.02514328993856907 Val mae: 0.023540373891592026 
            Train epipolar error pred unormalized: 91.50247192382812 Val epipolar error pred unormalized: 88.92330932617188
            Train epipolar error pred: 199.71798706054688 Val epipolar error pred: 203.82188415527344 
            penalty: 0.0013110400177538395
Epoch 14/50, Training Loss: 0.003607884980738163 Val Loss: 0.0017218803986907005 
            Training MAE: 0.023746194317936897 Val mae: 0.022972693666815758 
            Train epipolar error pred unormalized: 88.10025024414062 Val epipolar error pred unormalized: 98.06110382080078
            Train epipolar error pred: 197.5567626953125 Val epipolar error pred: 192.78924560546875 
            penalty: 0.002855094149708748
Epoch 15/50, Training Loss: 0.0042627304792404175 Val Loss: 0.001687356038019061 
            Training MAE: 0.024337051436305046 Val mae: 0.023683110252022743 
            Train epipolar error pred unormalized: 114.18205261230469 Val epipolar error pred unormalized: 114.73979949951172
            Train epipolar error pred: 214.31649780273438 Val epipolar error pred: 243.9214324951172 
            penalty: 0.0015679491916671395
Train unormalized ground truth error: 0.0010376219792912404 val unormalized ground truth error: 0.0007276546093635261


###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True, batchnorm & dropout: False, 
average embeddings: True, customdataset type: CustomDataset_first_two_thirds_train model: google/vit-base-patch16-224-in21k

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True, batchnorm & dropout: False, 
average embeddings: True, customdataset type: CustomDataset_first_two_thirds_train model: google/vit-base-patch16-224-in21k

###########################################################################################################

learning rate vit: 2e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True, batchnorm & dropout: False, 
average embeddings: True, customdataset type: CustomDataset_first_two_thirds_train model: google/vit-base-patch32-224-in21k

