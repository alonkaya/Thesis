###########################################################################################################

learning rate vit: 1e-05, learning rate mlp: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
        batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 1e-05, learning rate mlp: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
        batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 1e-05, learning rate mlp: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
        batch_size: 2, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 1e-05, learning rate mlp: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
        batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 1e-05, learning rate mlp: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
        batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 1e-05, learning rate mlp: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
        batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

Epoch 1/40, Training Loss: 0.2374819964170456 Val Loss: 0.15380623936653137 
            Training MAE: 0.3720412850379944 Val mae: 0.3379040062427521 
            Train epipolar error pred unormalized: 433.4247741699219 Val epipolar error pred unormalized: 1253.71044921875
            Train epipolar error pred: 6326.43017578125 Val epipolar error pred: 5050.46923828125 
            penalty: 0.033964257687330246
###########################################################################################################

learning rate vit: 1e-05, learning rate mlp: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

Epoch 1/1, Training Loss: 0.25986936688423157 Val Loss: 0.2282983362674713 
            Training MAE: 0.39419665932655334 Val mae: 0.376930296421051 
            Train epipolar error pred unormalized: 641.0435180664062 Val epipolar error pred unormalized: 1575.7325439453125
            Train epipolar error pred: 5565.35888671875 Val epipolar error pred: 3518.11962890625 
            penalty: 0.05777774751186371
Train ground truth error: 2.7535852495930158e-06 val ground truth error: 6.913584456924582e-06


learning rate vit: 1e-05, learning rate mlp: 0.005, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 1e-05, learning rate mlp: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

Epoch 1/1, Training Loss: 0.23097820580005646 Val Loss: 0.18827955424785614 
            Training MAE: 0.3773946762084961 Val mae: 0.3730801045894623 
            Train epipolar error pred unormalized: 225.2227020263672 Val epipolar error pred unormalized: 3775.10009765625
            Train epipolar error pred: 2381.701904296875 Val epipolar error pred: 8087.16064453125 
            penalty: 0.15474948287010193
Train ground truth error: 2.7535852495930158e-06 val ground truth error: 6.913584456924582e-06


learning rate vit: 1e-05, learning rate mlp: 0.005, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 1e-05, learning rate mlp: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

Epoch 1/1, Training Loss: 0.23859967291355133 Val Loss: 0.17731977999210358 
            Training MAE: 0.3319799602031708 Val mae: 0.32179006934165955 
            Train epipolar error pred unormalized: 195.3543243408203 Val epipolar error pred unormalized: 1183.678466796875
            Train epipolar error pred: 1981.4273681640625 Val epipolar error pred: 3635.128662109375 
            penalty: 0.02589336410164833
Train ground truth error: 2.7535852495930158e-06 val ground truth error: 6.913584456924582e-06


learning rate vit: 1e-05, learning rate mlp: 0.005, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 1e-05, learning rate mlp: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

Epoch 1/1, Training Loss: 0.20389771461486816 Val Loss: 0.2104635238647461 
            Training MAE: 0.382844477891922 Val mae: 0.40108203887939453 
            Train epipolar error pred unormalized: 842.5286254882812 Val epipolar error pred unormalized: 4687.43505859375
            Train epipolar error pred: 6719.88134765625 Val epipolar error pred: 14577.1845703125 
            penalty: 0.021313289180397987
Train ground truth error: 2.7535852495930158e-06 val ground truth error: 6.913584456924582e-06


learning rate vit: 1e-05, learning rate mlp: 0.005, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 1e-05, learning rate mlp: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

Epoch 1/1, Training Loss: 0.21773739159107208 Val Loss: 0.1777719110250473 
            Training MAE: 0.39004138112068176 Val mae: 0.33640170097351074 
            Train epipolar error pred unormalized: 173.3126983642578 Val epipolar error pred unormalized: 4442.38232421875
            Train epipolar error pred: 1449.4085693359375 Val epipolar error pred: 10226.8037109375 
            penalty: 0.058479178696870804
Train ground truth error: 2.7535852495930158e-06 val ground truth error: 6.913584456924582e-06


###########################################################################################################

learning rate vit: 1e-05, learning rate mlp: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

Epoch 1/1, Training Loss: 0.2634015381336212 Val Loss: 0.23114386200904846 
            Training MAE: 0.4010378122329712 Val mae: 0.35571348667144775 
            Train epipolar error pred unormalized: 606.8565063476562 Val epipolar error pred unormalized: 3545.05224609375
            Train epipolar error pred: 4318.396484375 Val epipolar error pred: 7957.73388671875 
            penalty: 0.03839794173836708
Train ground truth error: 2.7535852495930158e-06 val ground truth error: 6.913584456924582e-06


learning rate vit: 1e-05, learning rate mlp: 0.005, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

Epoch 1/1, Training Loss: 0.2355741262435913 Val Loss: 0.22345367074012756 
            Training MAE: 0.3762623071670532 Val mae: 0.3977113366127014 
            Train epipolar error pred unormalized: 999.8820190429688 Val epipolar error pred unormalized: 6550.59521484375
            Train epipolar error pred: 7761.64599609375 Val epipolar error pred: 12453.76171875 
            penalty: 0.031182697042822838
Train ground truth error: 2.7535852495930158e-06 val ground truth error: 6.913584456924582e-06


learning rate vit: 4e-05, learning rate mlp: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 1e-05, learning rate mlp: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

###########################################################################################################

learning rate vit: 1e-05, learning rate mlp: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False, RealEstate: True batchnorm & dropout: True

Epoch 1/1, Training Loss: 0.23994393646717072 Val Loss: 0.3660926818847656 
            Training MAE: 0.4063026010990143 Val mae: 0.4629376232624054 
            Train epipolar error pred unormalized: 480.0155029296875 Val epipolar error pred unormalized: 1916.0157470703125
            Train epipolar error pred: 4593.7421875 Val epipolar error pred: 3594.60107421875 
            penalty: 0.06135311350226402
Train ground truth error: 2.7535852495930158e-06 val ground truth error: 6.913584456924582e-06


