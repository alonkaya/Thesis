learning_rate: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False, batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: True

Epoch 1/15,  Training Loss: 0.08491024374961853 Val Loss: 0.05325155705213547 
            Training MAE: 0.15929295122623444 Val mae: 0.11393962055444717 
            Train epipolar error pred unormalized: 5680.8671875 Val epipolar error pred unormalized: 29325.4453125
            Train epipolar error pred: 29.352550506591797 Val epipolar error pred:  29.934736251831055
            penalty_coeff: 1, batch_size: 1 penalty: 0.0004799935268238187
Epoch 2/15,  Training Loss: 0.08274635672569275 Val Loss: 0.05276435613632202 
            Training MAE: 0.15796145796775818 Val mae: 0.11222688108682632 
            Train epipolar error pred unormalized: 43357.92578125 Val epipolar error pred unormalized: 33634.43359375
            Train epipolar error pred: 7.472936153411865 Val epipolar error pred:  1.4117070436477661
            penalty_coeff: 1, batch_size: 1 penalty: 0.0011246781796216965
Epoch 3/15,  Training Loss: 0.08252398669719696 Val Loss: 0.05276478826999664 
            Training MAE: 0.15783092379570007 Val mae: 0.11235680431127548 
            Train epipolar error pred unormalized: 430169.9375 Val epipolar error pred unormalized: 547805.6875
            Train epipolar error pred: 5.8357720375061035 Val epipolar error pred:  5.330773830413818
            penalty_coeff: 1, batch_size: 1 penalty: 0.00037588996929116547
Epoch 4/15,  Training Loss: 0.0824512168765068 Val Loss: 0.052761830389499664 
            Training MAE: 0.15780198574066162 Val mae: 0.11217760294675827 
            Train epipolar error pred unormalized: 832344.9375 Val epipolar error pred unormalized: 497033.75
            Train epipolar error pred: 5.863039970397949 Val epipolar error pred:  2.033372163772583
            penalty_coeff: 1, batch_size: 1 penalty: 4.888986222795211e-05
Epoch 5/15,  Training Loss: 0.08240889757871628 Val Loss: 0.05280902981758118 
            Training MAE: 0.15790283679962158 Val mae: 0.11259616166353226 
            Train epipolar error pred unormalized: 2104266.5 Val epipolar error pred unormalized: 2585683.25
            Train epipolar error pred: 8.073450088500977 Val epipolar error pred:  8.526501655578613
            penalty_coeff: 1, batch_size: 1 penalty: 0.0004233013023622334
Epoch 6/15,  Training Loss: 0.08239548653364182 Val Loss: 0.052793703973293304 
            Training MAE: 0.1578715592622757 Val mae: 0.1123989000916481 
            Train epipolar error pred unormalized: 3050324.5 Val epipolar error pred unormalized: 781536.1875
            Train epipolar error pred: 6.304945945739746 Val epipolar error pred:  3.624878406524658
            penalty_coeff: 1, batch_size: 1 penalty: 5.767853508586995e-05
Epoch 7/15,  Training Loss: 0.08235057443380356 Val Loss: 0.0529477559030056 
            Training MAE: 0.15782374143600464 Val mae: 0.1129009798169136 
            Train epipolar error pred unormalized: 8667853.0 Val epipolar error pred unormalized: 12806844.0
            Train epipolar error pred: 7.52834939956665 Val epipolar error pred:  10.351762771606445
            penalty_coeff: 1, batch_size: 1 penalty: 0.0005252821138128638
Epoch 8/15,  Training Loss: 0.082359679043293 Val Loss: 0.05275161564350128 
            Training MAE: 0.15789732336997986 Val mae: 0.11230668425559998 
            Train epipolar error pred unormalized: 9159732.0 Val epipolar error pred unormalized: 27994994.0
            Train epipolar error pred: 6.882755279541016 Val epipolar error pred:  6.885440826416016
            penalty_coeff: 1, batch_size: 1 penalty: 0.0003285094571765512
Epoch 9/15,  Training Loss: 0.08238139003515244 Val Loss: 0.05277518182992935 
            Training MAE: 0.15795525908470154 Val mae: 0.11230847239494324 
            Train epipolar error pred unormalized: 7968182.0 Val epipolar error pred unormalized: 3305885.0
            Train epipolar error pred: 6.807007312774658 Val epipolar error pred:  2.6456573009490967
            penalty_coeff: 1, batch_size: 1 penalty: 0.00010906236275332049
Epoch 10/15,  Training Loss: 0.08234833925962448 Val Loss: 0.05269062519073486 
            Training MAE: 0.15778791904449463 Val mae: 0.1123463585972786 
            Train epipolar error pred unormalized: 11455540.0 Val epipolar error pred unormalized: 9944894.0
            Train epipolar error pred: 4.192772388458252 Val epipolar error pred:  6.048641204833984
            penalty_coeff: 1, batch_size: 1 penalty: 6.27374611212872e-05
Epoch 11/15,  Training Loss: 0.08235865086317062 Val Loss: 0.05278189107775688 
            Training MAE: 0.15784622728824615 Val mae: 0.1123189777135849 
            Train epipolar error pred unormalized: 16093460.0 Val epipolar error pred unormalized: 7820787.0
            Train epipolar error pred: 5.151581764221191 Val epipolar error pred:  1.9287993907928467
            penalty_coeff: 1, batch_size: 1 penalty: 7.906632527010515e-05
Epoch 12/15,  Training Loss: 0.08231459558010101 Val Loss: 0.05285819619894028 
            Training MAE: 0.1579418033361435 Val mae: 0.11277362704277039 
            Train epipolar error pred unormalized: 32043538.0 Val epipolar error pred unormalized: 18221774.0
            Train epipolar error pred: 9.731588363647461 Val epipolar error pred:  10.489760398864746
            penalty_coeff: 1, batch_size: 1 penalty: 5.4534306400455534e-05
Epoch 13/15,  Training Loss: 0.08222471922636032 Val Loss: 0.05291157588362694 
            Training MAE: 0.15792247653007507 Val mae: 0.11312226951122284 
            Train epipolar error pred unormalized: 67740872.0 Val epipolar error pred unormalized: 63713900.0
            Train epipolar error pred: 10.590910911560059 Val epipolar error pred:  19.849111557006836
            penalty_coeff: 1, batch_size: 1 penalty: 0.00016096954641398042
Epoch 14/15,  Training Loss: 0.08149005472660065 Val Loss: 0.05194239318370819 
            Training MAE: 0.15669415891170502 Val mae: 0.1114460825920105 
            Train epipolar error pred unormalized: 51400748.0 Val epipolar error pred unormalized: 17445884.0
            Train epipolar error pred: 15.465967178344727 Val epipolar error pred:  16.95941925048828
            penalty_coeff: 1, batch_size: 1 penalty: 0.0005988060729578137
Epoch 15/15,  Training Loss: 0.08026130497455597 Val Loss: 0.054434094578027725 
            Training MAE: 0.1542988419532776 Val mae: 0.11285454034805298 
            Train epipolar error pred unormalized: 29941008.0 Val epipolar error pred unormalized: 44997160.0
            Train epipolar error pred: 12.576988220214844 Val epipolar error pred:  1.7261102199554443
            penalty_coeff: 1, batch_size: 1 penalty: 0.0001994268095586449
Train ground truth error: 0.0024112658575177193 val ground truth error: 0.0021737790666520596


learning_rate: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False, batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False

Epoch 1/15,  Training Loss: 0.664023220539093 Val Loss: 0.07840383797883987 
            Training MAE: 0.2516214847564697 Val mae: 0.18437246978282928 
            Train epipolar error pred unormalized: 138938.046875 Val epipolar error pred unormalized: 35622.98046875
            Train epipolar error pred: 4400.43505859375 Val epipolar error pred:  3322.330322265625
            penalty_coeff: 1, batch_size: 1 penalty: 0.05503112077713013
Epoch 2/15,  Training Loss: 0.8906481862068176 Val Loss: 0.05282250791788101 
            Training MAE: 0.18923313915729523 Val mae: 0.1125689446926117 
            Train epipolar error pred unormalized: 65477.01171875 Val epipolar error pred unormalized: 0.5024081468582153
            Train epipolar error pred: 1008.986083984375 Val epipolar error pred:  3.588355779647827
            penalty_coeff: 1, batch_size: 1 penalty: 3.125518196611665e-05
Epoch 3/15,  Training Loss: 0.08242174983024597 Val Loss: 0.052906718105077744 
            Training MAE: 0.15763460099697113 Val mae: 0.11250860244035721 
            Train epipolar error pred unormalized: 0.4344978332519531 Val epipolar error pred unormalized: 0.16033093631267548
            Train epipolar error pred: 2.7537906169891357 Val epipolar error pred:  0.8576771020889282
            penalty_coeff: 1, batch_size: 1 penalty: 8.542698196833953e-05
learning_rate: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False, batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False

Epoch 1/15,  Training Loss: 0.5026735663414001 Val Loss: 0.05918382480740547 
            Training MAE: 0.23315298557281494 Val mae: 0.15487287938594818 
            Train epipolar error pred unormalized: 39532.12890625 Val epipolar error pred unormalized: 1924.7904052734375
            Train epipolar error pred: 1974.666259765625 Val epipolar error pred:  305.3941345214844
            penalty_coeff: 1, batch_size: 1 penalty: 0.00443644355982542
Epoch 2/15,  Training Loss: 0.2977215647697449 Val Loss: 0.055040143430233 
            Training MAE: 0.18329770863056183 Val mae: 0.13876155018806458 
            Train epipolar error pred unormalized: 8122.625 Val epipolar error pred unormalized: 4110.23486328125
            Train epipolar error pred: 301.17578125 Val epipolar error pred:  547.6005859375
            penalty_coeff: 1, batch_size: 1 penalty: 0.023485790938138962
Epoch 3/15,  Training Loss: 0.24497197568416595 Val Loss: 0.05340774729847908 
            Training MAE: 0.17943710088729858 Val mae: 0.12423171103000641 
            Train epipolar error pred unormalized: 7515.86376953125 Val epipolar error pred unormalized: 578.43408203125
            Train epipolar error pred: 286.2156982421875 Val epipolar error pred:  127.72528076171875
            penalty_coeff: 1, batch_size: 1 penalty: 0.0019343966851010919
Epoch 4/15,  Training Loss: 0.09176529943943024 Val Loss: 0.0533897764980793 
            Training MAE: 0.1614384949207306 Val mae: 0.11297737061977386 
            Train epipolar error pred unormalized: 397.29412841796875 Val epipolar error pred unormalized: 1.7037307024002075
            Train epipolar error pred: 50.869789123535156 Val epipolar error pred:  10.12321662902832
            penalty_coeff: 1, batch_size: 1 penalty: 4.29945757787209e-05
Epoch 5/15,  Training Loss: 0.08245168626308441 Val Loss: 0.052781861275434494 
            Training MAE: 0.15791967511177063 Val mae: 0.11224745213985443 
            Train epipolar error pred unormalized: 0.7715253233909607 Val epipolar error pred unormalized: 0.11897172033786774
            Train epipolar error pred: 4.0077948570251465 Val epipolar error pred:  0.5289914608001709
            penalty_coeff: 1, batch_size: 1 penalty: 4.329536750447005e-05
Epoch 6/15,  Training Loss: 0.08240673691034317 Val Loss: 0.05297283083200455 
            Training MAE: 0.1578342616558075 Val mae: 0.11257348954677582 
            Train epipolar error pred unormalized: 0.9873667359352112 Val epipolar error pred unormalized: 1.1857552528381348
            Train epipolar error pred: 3.7863950729370117 Val epipolar error pred:  4.0755815505981445
            penalty_coeff: 1, batch_size: 1 penalty: 0.00015661124780308455
Epoch 7/15,  Training Loss: 0.08235703408718109 Val Loss: 0.05275711044669151 
            Training MAE: 0.1578267514705658 Val mae: 0.11277728527784348 
            Train epipolar error pred unormalized: 1.3835235834121704 Val epipolar error pred unormalized: 2.652560234069824
            Train epipolar error pred: 4.475930213928223 Val epipolar error pred:  7.912471294403076
            penalty_coeff: 1, batch_size: 1 penalty: 4.6714634663658217e-05
Epoch 8/15,  Training Loss: 0.08231812715530396 Val Loss: 0.052792541682720184 
            Training MAE: 0.15782378613948822 Val mae: 0.11272426694631577 
            Train epipolar error pred unormalized: 2.0360605716705322 Val epipolar error pred unormalized: 2.670914888381958
            Train epipolar error pred: 5.884736061096191 Val epipolar error pred:  7.326465129852295
            penalty_coeff: 1, batch_size: 1 penalty: 5.86415444558952e-05
Epoch 9/15,  Training Loss: 0.08236298710107803 Val Loss: 0.052800148725509644 
            Training MAE: 0.15788660943508148 Val mae: 0.11234399676322937 
            Train epipolar error pred unormalized: 1.5441299676895142 Val epipolar error pred unormalized: 1.0095256567001343
            Train epipolar error pred: 4.062280178070068 Val epipolar error pred:  2.51743745803833
            penalty_coeff: 1, batch_size: 1 penalty: 4.79816080769524e-05
Epoch 10/15,  Training Loss: 0.0823453813791275 Val Loss: 0.05292140319943428 
            Training MAE: 0.15781554579734802 Val mae: 0.11262158304452896 
            Train epipolar error pred unormalized: 1.3395545482635498 Val epipolar error pred unormalized: 2.715695858001709
            Train epipolar error pred: 3.249877691268921 Val epipolar error pred:  6.380615234375
            penalty_coeff: 1, batch_size: 1 penalty: 0.00011502226698212326
Epoch 11/15,  Training Loss: 0.08236958831548691 Val Loss: 0.0528104305267334 
            Training MAE: 0.15786147117614746 Val mae: 0.11249669641256332 
            Train epipolar error pred unormalized: 1.3585257530212402 Val epipolar error pred unormalized: 1.2424558401107788
            Train epipolar error pred: 3.1115150451660156 Val epipolar error pred:  2.7549760341644287
            penalty_coeff: 1, batch_size: 1 penalty: 8.03964285296388e-05
Epoch 12/15,  Training Loss: nan Val Loss: nan 
            Training MAE: nan Val mae: nan 
            Train epipolar error pred unormalized: nan Val epipolar error pred unormalized: nan
            Train epipolar error pred: nan Val epipolar error pred:  nan
            penalty_coeff: 1, batch_size: 1 penalty: nan
Epoch 13/15,  Training Loss: nan Val Loss: nan 
            Training MAE: nan Val mae: nan 
            Train epipolar error pred unormalized: nan Val epipolar error pred unormalized: nan
            Train epipolar error pred: nan Val epipolar error pred:  nan
            penalty_coeff: 1, batch_size: 1 penalty: nan
Epoch 14/15,  Training Loss: nan Val Loss: nan 
            Training MAE: nan Val mae: nan 
            Train epipolar error pred unormalized: nan Val epipolar error pred unormalized: nan
            Train epipolar error pred: nan Val epipolar error pred:  nan
            penalty_coeff: 1, batch_size: 1 penalty: nan
Epoch 15/15,  Training Loss: nan Val Loss: nan 
            Training MAE: nan Val mae: nan 
            Train epipolar error pred unormalized: nan Val epipolar error pred unormalized: nan
            Train epipolar error pred: nan Val epipolar error pred:  nan
            penalty_coeff: 1, batch_size: 1 penalty: nan
Train ground truth error: 0.0024112658575177193 val ground truth error: 0.0021737790666520596


learning_rate: 5e-05, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False, batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False

Epoch 1/15,  Training Loss: 0.2215416133403778 Val Loss: 0.05425659194588661 
            Training MAE: 0.17488397657871246 Val mae: 0.13185589015483856 
            Train epipolar error pred unormalized: 3894.22509765625 Val epipolar error pred unormalized: 1342.3499755859375
            Train epipolar error pred: 269.9229736328125 Val epipolar error pred:  260.2190246582031
            penalty_coeff: 1, batch_size: 1 penalty: 0.041378602385520935
Epoch 2/15,  Training Loss: 0.11303739994764328 Val Loss: 0.053159184753894806 
            Training MAE: 0.1744719296693802 Val mae: 0.1238754615187645 
            Train epipolar error pred unormalized: 2017.3759765625 Val epipolar error pred unormalized: 124.6881332397461
            Train epipolar error pred: 245.239013671875 Val epipolar error pred:  25.43434715270996
            penalty_coeff: 1, batch_size: 1 penalty: 0.00220461911521852
Epoch 3/15,  Training Loss: 0.11116452515125275 Val Loss: 0.05585798993706703 
            Training MAE: 0.17109547555446625 Val mae: 0.12711597979068756 
            Train epipolar error pred unormalized: 1042.64599609375 Val epipolar error pred unormalized: 167.04029846191406
            Train epipolar error pred: 101.03184509277344 Val epipolar error pred:  77.61663055419922
            penalty_coeff: 1, batch_size: 1 penalty: 0.002562896814197302
Epoch 4/15,  Training Loss: 0.10309795290231705 Val Loss: 0.05314574018120766 
            Training MAE: 0.1657959371805191 Val mae: 0.1201561763882637 
            Train epipolar error pred unormalized: 641.07666015625 Val epipolar error pred unormalized: 113.25716400146484
            Train epipolar error pred: 89.36279296875 Val epipolar error pred:  35.36525344848633
            penalty_coeff: 1, batch_size: 1 penalty: 0.0017715540016070008
Epoch 5/15,  Training Loss: 0.09042724967002869 Val Loss: 0.05333680287003517 
            Training MAE: 0.16538003087043762 Val mae: 0.12475058436393738 
            Train epipolar error pred unormalized: 402.0325622558594 Val epipolar error pred unormalized: 577.4052734375
            Train epipolar error pred: 83.62566375732422 Val epipolar error pred:  119.51200103759766
            penalty_coeff: 1, batch_size: 1 penalty: 0.0020059607923030853
Epoch 6/15,  Training Loss: 0.08624758571386337 Val Loss: 0.05322054773569107 
            Training MAE: 0.165597066283226 Val mae: 0.12274203449487686 
            Train epipolar error pred unormalized: 249.66578674316406 Val epipolar error pred unormalized: 77.76335144042969
            Train epipolar error pred: 77.89752197265625 Val epipolar error pred:  103.08407592773438
            penalty_coeff: 1, batch_size: 1 penalty: 0.0006120086763985455
Epoch 7/15,  Training Loss: 0.08287495374679565 Val Loss: 0.05290110036730766 
            Training MAE: 0.16140884160995483 Val mae: 0.112481988966465 
            Train epipolar error pred unormalized: 11.628149032592773 Val epipolar error pred unormalized: 0.11296045035123825
            Train epipolar error pred: 25.273693084716797 Val epipolar error pred:  0.5333806276321411
            penalty_coeff: 1, batch_size: 1 penalty: 2.090632369800005e-05
Epoch 8/15,  Training Loss: 0.08234072476625443 Val Loss: 0.05278618633747101 
            Training MAE: 0.15776267647743225 Val mae: 0.11225292086601257 
            Train epipolar error pred unormalized: 0.17460620403289795 Val epipolar error pred unormalized: 0.08752895891666412
            Train epipolar error pred: 0.7856556177139282 Val epipolar error pred:  0.3680287301540375
            penalty_coeff: 1, batch_size: 1 penalty: 7.433661812683567e-05
Epoch 9/15,  Training Loss: 0.08235301077365875 Val Loss: 0.05280839651823044 
            Training MAE: 0.15777350962162018 Val mae: 0.11234026402235031 
            Train epipolar error pred unormalized: 0.17556637525558472 Val epipolar error pred unormalized: 0.2019035816192627
            Train epipolar error pred: 0.702549397945404 Val epipolar error pred:  0.7615576982498169
            penalty_coeff: 1, batch_size: 1 penalty: 0.00011874760093633085
Epoch 10/15,  Training Loss: 0.08229519426822662 Val Loss: 0.05281611531972885 
            Training MAE: 0.1577473133802414 Val mae: 0.11188669502735138 
            Train epipolar error pred unormalized: 0.23288339376449585 Val epipolar error pred unormalized: 0.28063297271728516
            Train epipolar error pred: 0.840768039226532 Val epipolar error pred:  1.0101161003112793
            penalty_coeff: 1, batch_size: 1 penalty: 7.981030648807064e-05
Epoch 11/15,  Training Loss: 0.08235198259353638 Val Loss: 0.05283436179161072 
            Training MAE: 0.1577061265707016 Val mae: 0.11241312325000763 
            Train epipolar error pred unormalized: 0.23846615850925446 Val epipolar error pred unormalized: 0.22863152623176575
            Train epipolar error pred: 0.8025960922241211 Val epipolar error pred:  0.7342703938484192
            penalty_coeff: 1, batch_size: 1 penalty: 3.0686216632602736e-05
Epoch 12/15,  Training Loss: 0.0823194682598114 Val Loss: 0.05278543010354042 
            Training MAE: 0.15773455798625946 Val mae: 0.11228959262371063 
            Train epipolar error pred unormalized: 0.3050086498260498 Val epipolar error pred unormalized: 0.1461847424507141
            Train epipolar error pred: 0.9579764604568481 Val epipolar error pred:  0.4440493583679199
            penalty_coeff: 1, batch_size: 1 penalty: 8.13904480310157e-05
Epoch 13/15,  Training Loss: 0.08231477439403534 Val Loss: 0.05298396199941635 
            Training MAE: 0.1576891392469406 Val mae: 0.11261570453643799 
            Train epipolar error pred unormalized: 0.3073715269565582 Val epipolar error pred unormalized: 0.40637344121932983
            Train epipolar error pred: 0.9110151529312134 Val epipolar error pred:  1.1621524095535278
            penalty_coeff: 1, batch_size: 1 penalty: 8.569547208026052e-05
Epoch 14/15,  Training Loss: 0.08233048021793365 Val Loss: 0.05278502032160759 
            Training MAE: 0.15776391327381134 Val mae: 0.1123371422290802 
            Train epipolar error pred unormalized: 0.26287034153938293 Val epipolar error pred unormalized: 0.2583414316177368
            Train epipolar error pred: 0.7354846596717834 Val epipolar error pred:  0.7076875567436218
            penalty_coeff: 1, batch_size: 1 penalty: 2.1323488908819854e-05
Epoch 15/15,  Training Loss: 0.08228936046361923 Val Loss: 0.05275816470384598 
            Training MAE: 0.15770256519317627 Val mae: 0.11213523894548416 
            Train epipolar error pred unormalized: 0.3572591245174408 Val epipolar error pred unormalized: 0.2273213118314743
            Train epipolar error pred: 0.9647423624992371 Val epipolar error pred:  0.6084485054016113
            penalty_coeff: 1, batch_size: 1 penalty: 3.451765587669797e-05
Train ground truth error: 0.002411260735243559 val ground truth error: 0.002173788147047162


learning_rate: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 2, use_reconstruction_layer: False, batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False

Epoch 1/15,  Training Loss: 1.0987988710403442 Val Loss: 0.10577546805143356 
            Training MAE: 0.2657080292701721 Val mae: 0.23680374026298523 
            Train epipolar error pred unormalized: 67687.828125 Val epipolar error pred unormalized: 61630.19921875
            Train epipolar error pred: 3222.483642578125 Val epipolar error pred:  2351.42724609375
            penalty_coeff: 2, batch_size: 1 penalty: 0.07781140506267548
Epoch 2/15,  Training Loss: 0.31132450699806213 Val Loss: 0.07834469527006149 
            Training MAE: 0.2412518709897995 Val mae: 0.1983979493379593 
            Train epipolar error pred unormalized: 53062.0 Val epipolar error pred unormalized: 11979.6787109375
            Train epipolar error pred: 3033.095947265625 Val epipolar error pred:  1988.17529296875
            penalty_coeff: 2, batch_size: 1 penalty: 0.004492732230573893
Epoch 3/15,  Training Loss: 0.3929332196712494 Val Loss: 0.05275708809494972 
            Training MAE: 0.19874632358551025 Val mae: 0.11311987042427063 
            Train epipolar error pred unormalized: 11952.513671875 Val epipolar error pred unormalized: 4.397551536560059
            Train epipolar error pred: 1372.244140625 Val epipolar error pred:  29.322145462036133
            penalty_coeff: 2, batch_size: 1 penalty: 0.0002116630639648065
Epoch 4/15,  Training Loss: 0.08255583792924881 Val Loss: 0.0528765507042408 
            Training MAE: 0.15799610316753387 Val mae: 0.11271069943904877 
            Train epipolar error pred unormalized: 1.9524099826812744 Val epipolar error pred unormalized: 0.8840405941009521
            Train epipolar error pred: 11.236693382263184 Val epipolar error pred:  4.132606506347656
            penalty_coeff: 2, batch_size: 1 penalty: 0.00021762347023468465
Epoch 5/15,  Training Loss: 0.08260117471218109 Val Loss: 0.052748437970876694 
            Training MAE: 0.15791937708854675 Val mae: 0.11217842996120453 
            Train epipolar error pred unormalized: 1.7956230640411377 Val epipolar error pred unormalized: 1.364797830581665
            Train epipolar error pred: 6.977553367614746 Val epipolar error pred:  4.386990547180176
            penalty_coeff: 2, batch_size: 1 penalty: 0.000273043115157634
Epoch 6/15,  Training Loss: 0.08247699588537216 Val Loss: 0.052941255271434784 
            Training MAE: 0.1576719582080841 Val mae: 0.11250338703393936 
            Train epipolar error pred unormalized: 2.4030258655548096 Val epipolar error pred unormalized: 0.822978138923645
            Train epipolar error pred: 7.083244800567627 Val epipolar error pred:  2.1387851238250732
            penalty_coeff: 2, batch_size: 1 penalty: 9.183612564811483e-05
Epoch 7/15,  Training Loss: 0.08254765719175339 Val Loss: 0.052800681442022324 
            Training MAE: 0.1578488051891327 Val mae: 0.11241894960403442 
            Train epipolar error pred unormalized: 2.382185935974121 Val epipolar error pred unormalized: 0.7359659671783447
            Train epipolar error pred: 5.771429538726807 Val epipolar error pred:  1.6555002927780151
            penalty_coeff: 2, batch_size: 1 penalty: 0.00014325909432955086
Epoch 8/15,  Training Loss: 0.08245605230331421 Val Loss: 0.05279581993818283 
            Training MAE: 0.15779083967208862 Val mae: 0.11247429996728897 
            Train epipolar error pred unormalized: 2.955570936203003 Val epipolar error pred unormalized: 2.9952478408813477
            Train epipolar error pred: 6.466498851776123 Val epipolar error pred:  6.153182029724121
            penalty_coeff: 2, batch_size: 1 penalty: 5.123992741573602e-05
Epoch 9/15,  Training Loss: 0.08252128958702087 Val Loss: 0.05278234928846359 
            Training MAE: 0.1577872782945633 Val mae: 0.11229363828897476 
            Train epipolar error pred unormalized: 2.022050619125366 Val epipolar error pred unormalized: 0.6909313201904297
            Train epipolar error pred: 4.026120662689209 Val epipolar error pred:  1.3214585781097412
            penalty_coeff: 2, batch_size: 1 penalty: 7.1747723268345e-05
Epoch 10/15,  Training Loss: 0.0823952928185463 Val Loss: 0.052843280136585236 
            Training MAE: 0.15777583420276642 Val mae: 0.11239273846149445 
            Train epipolar error pred unormalized: 2.0967636108398438 Val epipolar error pred unormalized: 0.39194488525390625
            Train epipolar error pred: 3.893094778060913 Val epipolar error pred:  0.7044403553009033
            penalty_coeff: 2, batch_size: 1 penalty: 1.7108486645156518e-05
Epoch 11/15,  Training Loss: 0.0824882760643959 Val Loss: 0.052816394716501236 
            Training MAE: 0.15779291093349457 Val mae: 0.11248482763767242 
            Train epipolar error pred unormalized: 2.0807878971099854 Val epipolar error pred unormalized: 0.8934563398361206
            Train epipolar error pred: 3.6538808345794678 Val epipolar error pred:  1.5311583280563354
            penalty_coeff: 2, batch_size: 1 penalty: 5.894888818147592e-05
Epoch 12/15,  Training Loss: 0.0824868381023407 Val Loss: 0.05276275798678398 
            Training MAE: 0.1578381061553955 Val mae: 0.11230963468551636 
            Train epipolar error pred unormalized: 2.4192748069763184 Val epipolar error pred unormalized: 2.7464098930358887
            Train epipolar error pred: 4.112348556518555 Val epipolar error pred:  4.5954365730285645
            penalty_coeff: 2, batch_size: 1 penalty: 0.00010666158777894452
Epoch 13/15,  Training Loss: 0.08245775103569031 Val Loss: 0.05276601016521454 
            Training MAE: 0.15780653059482574 Val mae: 0.11233888566493988 
            Train epipolar error pred unormalized: 2.2173259258270264 Val epipolar error pred unormalized: 1.7652950286865234
            Train epipolar error pred: 3.651334047317505 Val epipolar error pred:  2.870274543762207
            penalty_coeff: 2, batch_size: 1 penalty: 8.689059541211464e-06
Epoch 14/15,  Training Loss: 0.08245743811130524 Val Loss: 0.05277261137962341 
            Training MAE: 0.1578839272260666 Val mae: 0.11234431713819504 
            Train epipolar error pred unormalized: 2.489800214767456 Val epipolar error pred unormalized: 2.25221848487854
            Train epipolar error pred: 4.001598834991455 Val epipolar error pred:  3.5797317028045654
            penalty_coeff: 2, batch_size: 1 penalty: 6.715537892887369e-06
Epoch 15/15,  Training Loss: 0.08243708312511444 Val Loss: 0.053085483610630035 
            Training MAE: 0.15784676373004913 Val mae: 0.11328613013029099 
            Train epipolar error pred unormalized: 3.369525909423828 Val epipolar error pred unormalized: 9.124917984008789
            Train epipolar error pred: 5.359162330627441 Val epipolar error pred:  14.390107154846191
            penalty_coeff: 2, batch_size: 1 penalty: 4.526717748376541e-05
Train ground truth error: 0.0024112702812999487 val ground truth error: 0.0021737790666520596


learning_rate: 5e-05, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 2, use_reconstruction_layer: False, batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False

Epoch 1/15,  Training Loss: 0.15556666254997253 Val Loss: 0.05284583941102028 
            Training MAE: 0.17941051721572876 Val mae: 0.11630579829216003 
            Train epipolar error pred unormalized: 1779.519775390625 Val epipolar error pred unormalized: 60.2373046875
            Train epipolar error pred: 524.0313720703125 Val epipolar error pred:  45.563350677490234
            penalty_coeff: 2, batch_size: 1 penalty: 0.0010421130573377013
Epoch 2/15,  Training Loss: 0.1066686362028122 Val Loss: 0.05359755456447601 
            Training MAE: 0.1689131259918213 Val mae: 0.12324012070894241 
            Train epipolar error pred unormalized: 593.7023315429688 Val epipolar error pred unormalized: 311.9632873535156
            Train epipolar error pred: 140.48550415039062 Val epipolar error pred:  247.9894561767578
            penalty_coeff: 2, batch_size: 1 penalty: 0.0026785514783114195
Epoch 3/15,  Training Loss: 0.11035270988941193 Val Loss: 0.05499931424856186 
            Training MAE: 0.17003054916858673 Val mae: 0.13144029676914215 
            Train epipolar error pred unormalized: 661.3324584960938 Val epipolar error pred unormalized: 246.2655792236328
            Train epipolar error pred: 184.76593017578125 Val epipolar error pred:  183.22146606445312
            penalty_coeff: 2, batch_size: 1 penalty: 0.0024638117756694555
Epoch 4/15,  Training Loss: 0.09073343873023987 Val Loss: 0.05342212691903114 
            Training MAE: 0.17188680171966553 Val mae: 0.1255527287721634 
            Train epipolar error pred unormalized: 300.6260681152344 Val epipolar error pred unormalized: 87.22149658203125
            Train epipolar error pred: 206.79971313476562 Val epipolar error pred:  67.63016510009766
            penalty_coeff: 2, batch_size: 1 penalty: 0.0026013744063675404
Epoch 5/15,  Training Loss: 0.09108913689851761 Val Loss: 0.05279708281159401 
            Training MAE: 0.16585426032543182 Val mae: 0.11179503053426743 
            Train epipolar error pred unormalized: 141.19395446777344 Val epipolar error pred unormalized: 0.08791210502386093
            Train epipolar error pred: 148.2583770751953 Val epipolar error pred:  0.7491666078567505
            penalty_coeff: 2, batch_size: 1 penalty: 1.953875835170038e-05
Epoch 6/15,  Training Loss: 0.08238007128238678 Val Loss: 0.05286181718111038 
            Training MAE: 0.1576259732246399 Val mae: 0.1115894466638565 
            Train epipolar error pred unormalized: 0.09436512738466263 Val epipolar error pred unormalized: 0.20334739983081818
            Train epipolar error pred: 0.7077982425689697 Val epipolar error pred:  1.382567286491394
            penalty_coeff: 2, batch_size: 1 penalty: 3.4640590456547216e-05
Epoch 7/15,  Training Loss: 0.08242624998092651 Val Loss: 0.05285387113690376 
            Training MAE: 0.15768113732337952 Val mae: 0.11245949566364288 
            Train epipolar error pred unormalized: 0.1833823025226593 Val epipolar error pred unormalized: 0.28429681062698364
            Train epipolar error pred: 1.0957517623901367 Val epipolar error pred:  1.5153337717056274
            penalty_coeff: 2, batch_size: 1 penalty: 6.175191811053082e-05
Epoch 8/15,  Training Loss: 0.08236607909202576 Val Loss: 0.052827198058366776 
            Training MAE: 0.1577146351337433 Val mae: 0.11233380436897278 
            Train epipolar error pred unormalized: 0.26812177896499634 Val epipolar error pred unormalized: 0.2761829197406769
            Train epipolar error pred: 1.324774146080017 Val epipolar error pred:  1.3159202337265015
            penalty_coeff: 2, batch_size: 1 penalty: 5.6425324146403e-05
Epoch 9/15,  Training Loss: 0.08237730711698532 Val Loss: 0.052874885499477386 
            Training MAE: 0.15766555070877075 Val mae: 0.11243944615125656 
            Train epipolar error pred unormalized: 0.36521613597869873 Val epipolar error pred unormalized: 0.3008691072463989
            Train epipolar error pred: 1.6408439874649048 Val epipolar error pred:  1.266675591468811
            penalty_coeff: 2, batch_size: 1 penalty: 1.66860299941618e-05
Epoch 10/15,  Training Loss: 0.08235909044742584 Val Loss: 0.05303330346941948 
            Training MAE: 0.15767478942871094 Val mae: 0.11260964721441269 
            Train epipolar error pred unormalized: 0.3020346164703369 Val epipolar error pred unormalized: 0.6173516511917114
            Train epipolar error pred: 1.2255316972732544 Val epipolar error pred:  2.4122862815856934
            penalty_coeff: 2, batch_size: 1 penalty: 2.9176258976804093e-05
Epoch 11/15,  Training Loss: 0.08236299455165863 Val Loss: 0.052794769406318665 
            Training MAE: 0.15768343210220337 Val mae: 0.11235685646533966 
            Train epipolar error pred unormalized: 0.4064350426197052 Val epipolar error pred unormalized: 0.576319694519043
            Train epipolar error pred: 1.5265954732894897 Val epipolar error pred:  2.0985357761383057
            penalty_coeff: 2, batch_size: 1 penalty: 3.243590981583111e-05
Epoch 12/15,  Training Loss: 0.08232227712869644 Val Loss: 0.05311153084039688 
            Training MAE: 0.15761488676071167 Val mae: 0.11270829290151596 
            Train epipolar error pred unormalized: 0.4897936284542084 Val epipolar error pred unormalized: 1.1031172275543213
            Train epipolar error pred: 1.7321723699569702 Val epipolar error pred:  3.814349412918091
            penalty_coeff: 2, batch_size: 1 penalty: 5.648338992614299e-05
Epoch 13/15,  Training Loss: 0.08238306641578674 Val Loss: 0.052823882550001144 
            Training MAE: 0.15773436427116394 Val mae: 0.11236125230789185 
            Train epipolar error pred unormalized: 0.5265253782272339 Val epipolar error pred unormalized: 0.5936283469200134
            Train epipolar error pred: 1.778215765953064 Val epipolar error pred:  1.94209623336792
            penalty_coeff: 2, batch_size: 1 penalty: 6.213737651705742e-05
Epoch 14/15,  Training Loss: 0.08236145973205566 Val Loss: 0.05275022238492966 
            Training MAE: 0.1577523797750473 Val mae: 0.1123124361038208 
            Train epipolar error pred unormalized: 0.6896378397941589 Val epipolar error pred unormalized: 1.1856952905654907
            Train epipolar error pred: 2.2044930458068848 Val epipolar error pred:  3.74055552482605
            penalty_coeff: 2, batch_size: 1 penalty: 0.00010889661643886939
Epoch 15/15,  Training Loss: 0.08236350864171982 Val Loss: 0.05283340811729431 
            Training MAE: 0.1576681137084961 Val mae: 0.11232941597700119 
            Train epipolar error pred unormalized: 0.6673760414123535 Val epipolar error pred unormalized: 0.2153605967760086
            Train epipolar error pred: 2.0945160388946533 Val epipolar error pred:  0.6516237854957581
            penalty_coeff: 2, batch_size: 1 penalty: 4.426057785167359e-06
Train ground truth error: 0.0024112691171467304 val ground truth error: 0.0021737790666520596


learning_rate: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False, batch_size: 16, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False

Epoch 1/15,  Training Loss: 0.9678303003311157 Val Loss: 0.11078310012817383 
            Training MAE: 0.27421823143959045 Val mae: 0.25085413455963135 
            Train epipolar error pred unormalized: 64956.87890625 Val epipolar error pred unormalized: 301185.875
            Train epipolar error pred: 5156.89208984375 Val epipolar error pred:  3507.0908203125
            penalty_coeff: 1, batch_size: 16 penalty: 5.375349521636963
Epoch 2/15,  Training Loss: 2.4115452766418457 Val Loss: 0.10428746044635773 
            Training MAE: 0.29600754380226135 Val mae: 0.25675469636917114 
            Train epipolar error pred unormalized: 324468.6875 Val epipolar error pred unormalized: 47938.1953125
            Train epipolar error pred: 8972.9111328125 Val epipolar error pred:  5326.76171875
            penalty_coeff: 1, batch_size: 16 penalty: 0.000650355068501085
Epoch 3/15,  Training Loss: 0.17668738961219788 Val Loss: 0.09195742756128311 
            Training MAE: 0.26675108075141907 Val mae: 0.23774489760398865 
            Train epipolar error pred unormalized: 48269.0546875 Val epipolar error pred unormalized: 15932.3740234375
            Train epipolar error pred: 5752.90576171875 Val epipolar error pred:  3685.64208984375
            penalty_coeff: 1, batch_size: 16 penalty: 0.039644915610551834
Epoch 4/15,  Training Loss: 0.15444138646125793 Val Loss: 0.09019983559846878 
            Training MAE: 0.25292208790779114 Val mae: 0.22335107624530792 
            Train epipolar error pred unormalized: 25277.4609375 Val epipolar error pred unormalized: 18050.552734375
            Train epipolar error pred: 4621.41162109375 Val epipolar error pred:  3605.666748046875
            penalty_coeff: 1, batch_size: 16 penalty: 0.023022515699267387
Epoch 5/15,  Training Loss: 0.1365654021501541 Val Loss: 0.0698629841208458 
            Training MAE: 0.2401306927204132 Val mae: 0.19637291133403778 
            Train epipolar error pred unormalized: 15534.623046875 Val epipolar error pred unormalized: 3034.563720703125
            Train epipolar error pred: 3446.98193359375 Val epipolar error pred:  1294.4110107421875
            penalty_coeff: 1, batch_size: 16 penalty: 0.034829653799533844
Epoch 6/15,  Training Loss: 0.1316196471452713 Val Loss: 0.06749912351369858 
            Training MAE: 0.229769766330719 Val mae: 0.19168369472026825 
            Train epipolar error pred unormalized: 9368.6708984375 Val epipolar error pred unormalized: 3907.4814453125
            Train epipolar error pred: 2267.728515625 Val epipolar error pred:  1354.3876953125
            penalty_coeff: 1, batch_size: 16 penalty: 0.00537106953561306
Epoch 7/15,  Training Loss: 0.11221247166395187 Val Loss: 0.06051960214972496 
            Training MAE: 0.2152283787727356 Val mae: 0.1692257523536682 
            Train epipolar error pred unormalized: 3718.041259765625 Val epipolar error pred unormalized: 1440.481689453125
            Train epipolar error pred: 1339.9390869140625 Val epipolar error pred:  908.7742309570312
            penalty_coeff: 1, batch_size: 16 penalty: 0.0025628048460930586
Epoch 8/15,  Training Loss: 0.3709554970264435 Val Loss: 0.07651706039905548 
            Training MAE: 0.21881318092346191 Val mae: 0.20702169835567474 
            Train epipolar error pred unormalized: 33383.890625 Val epipolar error pred unormalized: 45296.0078125
            Train epipolar error pred: 1904.7449951171875 Val epipolar error pred:  2716.023681640625
            penalty_coeff: 1, batch_size: 16 penalty: 0.15987227857112885
Epoch 9/15,  Training Loss: 0.16073578596115112 Val Loss: 0.0667203739285469 
            Training MAE: 0.23424819111824036 Val mae: 0.18461723625659943 
            Train epipolar error pred unormalized: 31008.205078125 Val epipolar error pred unormalized: 9265.357421875
            Train epipolar error pred: 3142.85498046875 Val epipolar error pred:  1689.972900390625
            penalty_coeff: 1, batch_size: 16 penalty: 0.04311984032392502
Epoch 10/15,  Training Loss: 0.11060361564159393 Val Loss: 0.06366055458784103 
            Training MAE: 0.22188103199005127 Val mae: 0.18181930482387543 
            Train epipolar error pred unormalized: 9533.109375 Val epipolar error pred unormalized: 6011.7744140625
            Train epipolar error pred: 1795.666015625 Val epipolar error pred:  1340.5042724609375
            penalty_coeff: 1, batch_size: 16 penalty: 0.015189409255981445
Epoch 11/15,  Training Loss: 0.09827501326799393 Val Loss: 0.058654919266700745 
            Training MAE: 0.20179162919521332 Val mae: 0.15630210936069489 
            Train epipolar error pred unormalized: 3062.6474609375 Val epipolar error pred unormalized: 1308.6171875
            Train epipolar error pred: 1033.9482421875 Val epipolar error pred:  922.9808959960938
            penalty_coeff: 1, batch_size: 16 penalty: 0.0021224902011454105
Epoch 12/15,  Training Loss: 0.14611828327178955 Val Loss: 0.058563388884067535 
            Training MAE: 0.21969975531101227 Val mae: 0.165056049823761 
            Train epipolar error pred unormalized: 12377.8193359375 Val epipolar error pred unormalized: 1924.2176513671875
            Train epipolar error pred: 1537.593994140625 Val epipolar error pred:  639.1466674804688
            penalty_coeff: 1, batch_size: 16 penalty: 0.015435594134032726
Epoch 13/15,  Training Loss: 0.10704665631055832 Val Loss: 0.06225458160042763 
            Training MAE: 0.21292035281658173 Val mae: 0.1790858954191208 
            Train epipolar error pred unormalized: 5379.51416015625 Val epipolar error pred unormalized: 5351.48779296875
            Train epipolar error pred: 1129.2720947265625 Val epipolar error pred:  1143.0
            penalty_coeff: 1, batch_size: 16 penalty: 0.006476657465100288
Epoch 14/15,  Training Loss: 0.09907552599906921 Val Loss: 0.05475971847772598 
            Training MAE: 0.20231178402900696 Val mae: 0.14391353726387024 
            Train epipolar error pred unormalized: 3201.322021484375 Val epipolar error pred unormalized: 707.6782836914062
            Train epipolar error pred: 880.189208984375 Val epipolar error pred:  385.27764892578125
            penalty_coeff: 1, batch_size: 16 penalty: 0.0013044882798567414
Epoch 15/15,  Training Loss: 0.09735489636659622 Val Loss: 0.05417462810873985 
            Training MAE: 0.1924317181110382 Val mae: 0.13830304145812988 
            Train epipolar error pred unormalized: 1811.26123046875 Val epipolar error pred unormalized: 656.1513061523438
            Train epipolar error pred: 737.6776123046875 Val epipolar error pred:  422.22906494140625
            penalty_coeff: 1, batch_size: 16 penalty: 0.009914818219840527
Train ground truth error: 0.0024116283748298883 val ground truth error: 0.0021608450915664434


learning_rate: 5e-05, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False, batch_size: 16, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False

Epoch 1/15,  Training Loss: 0.1000455841422081 Val Loss: 0.05581972002983093 
            Training MAE: 0.17584878206253052 Val mae: 0.13476234674453735 
            Train epipolar error pred unormalized: 555.425537109375 Val epipolar error pred unormalized: 58.25066375732422
            Train epipolar error pred: 481.8831787109375 Val epipolar error pred:  295.7553405761719
            penalty_coeff: 1, batch_size: 16 penalty: 0.004844020586460829
Epoch 2/15,  Training Loss: 0.08172252774238586 Val Loss: 0.06310544162988663 
            Training MAE: 0.16108918190002441 Val mae: 0.13045626878738403 
            Train epipolar error pred unormalized: 44.028350830078125 Val epipolar error pred unormalized: 87.16567993164062
            Train epipolar error pred: 118.53236389160156 Val epipolar error pred:  293.3106994628906
            penalty_coeff: 1, batch_size: 16 penalty: 0.004914709832519293
Epoch 3/15,  Training Loss: 0.0699545368552208 Val Loss: 0.07150361686944962 
            Training MAE: 0.1439366638660431 Val mae: 0.12830425798892975 
            Train epipolar error pred unormalized: 49.87542724609375 Val epipolar error pred unormalized: 42.95224380493164
            Train epipolar error pred: 142.71372985839844 Val epipolar error pred:  121.37477111816406
            penalty_coeff: 1, batch_size: 16 penalty: 0.004000493325293064
Epoch 4/15,  Training Loss: 0.052843786776065826 Val Loss: 0.06488294154405594 
            Training MAE: 0.12100730836391449 Val mae: 0.12262321263551712 
            Train epipolar error pred unormalized: 59.76476287841797 Val epipolar error pred unormalized: 55.015384674072266
            Train epipolar error pred: 150.45156860351562 Val epipolar error pred:  131.69224548339844
            penalty_coeff: 1, batch_size: 16 penalty: 0.0027084187604486942
Epoch 5/15,  Training Loss: 0.033208999782800674 Val Loss: 0.07271475344896317 
            Training MAE: 0.09371601790189743 Val mae: 0.12907938659191132 
            Train epipolar error pred unormalized: 61.5198974609375 Val epipolar error pred unormalized: 56.84095764160156
            Train epipolar error pred: 135.6177978515625 Val epipolar error pred:  140.32070922851562
            penalty_coeff: 1, batch_size: 16 penalty: 0.0030292801093310118
Epoch 6/15,  Training Loss: 0.020090708509087563 Val Loss: 0.07619471102952957 
            Training MAE: 0.0729428231716156 Val mae: 0.12744717299938202 
            Train epipolar error pred unormalized: 58.80815505981445 Val epipolar error pred unormalized: 47.2218017578125
            Train epipolar error pred: 113.38829803466797 Val epipolar error pred:  115.66522216796875
            penalty_coeff: 1, batch_size: 16 penalty: 0.003213576041162014
Epoch 7/15,  Training Loss: 0.01362594123929739 Val Loss: 0.07598217576742172 
            Training MAE: 0.06011423096060753 Val mae: 0.1282459944486618 
            Train epipolar error pred unormalized: 54.21087646484375 Val epipolar error pred unormalized: 39.01005554199219
            Train epipolar error pred: 99.29280090332031 Val epipolar error pred:  113.5421371459961
            penalty_coeff: 1, batch_size: 16 penalty: 0.0011601714650169015
Epoch 8/15,  Training Loss: 0.009350038133561611 Val Loss: 0.0790453553199768 
            Training MAE: 0.04981130734086037 Val mae: 0.13420440256595612 
            Train epipolar error pred unormalized: 48.2266731262207 Val epipolar error pred unormalized: 41.777320861816406
            Train epipolar error pred: 86.97599029541016 Val epipolar error pred:  130.81707763671875
            penalty_coeff: 1, batch_size: 16 penalty: 0.001994050107896328
Epoch 9/15,  Training Loss: 0.007196588907390833 Val Loss: 0.0727577656507492 
            Training MAE: 0.04332907125353813 Val mae: 0.1256495863199234 
            Train epipolar error pred unormalized: 44.666595458984375 Val epipolar error pred unormalized: 38.41485595703125
            Train epipolar error pred: 79.852783203125 Val epipolar error pred:  104.09414672851562
            penalty_coeff: 1, batch_size: 16 penalty: 0.0012200080091133714
Epoch 10/15,  Training Loss: 0.006117936689406633 Val Loss: 0.06905632466077805 
            Training MAE: 0.03933514282107353 Val mae: 0.12769575417041779 
            Train epipolar error pred unormalized: 41.264923095703125 Val epipolar error pred unormalized: 48.49653244018555
            Train epipolar error pred: 76.04866027832031 Val epipolar error pred:  148.23733520507812
            penalty_coeff: 1, batch_size: 16 penalty: 0.0007228857139125466
Epoch 11/15,  Training Loss: 0.005863463971763849 Val Loss: 0.07387010008096695 
            Training MAE: 0.03804397955536842 Val mae: 0.12923398613929749 
            Train epipolar error pred unormalized: 37.789615631103516 Val epipolar error pred unormalized: 41.24811553955078
            Train epipolar error pred: 71.58675384521484 Val epipolar error pred:  123.33341979980469
            penalty_coeff: 1, batch_size: 16 penalty: 0.0028349740896373987
Epoch 12/15,  Training Loss: 0.006183564197272062 Val Loss: 0.0687972903251648 
            Training MAE: 0.03924665227532387 Val mae: 0.12131074070930481 
            Train epipolar error pred unormalized: 38.676361083984375 Val epipolar error pred unormalized: 26.571273803710938
            Train epipolar error pred: 66.10868835449219 Val epipolar error pred:  70.22185516357422
            penalty_coeff: 1, batch_size: 16 penalty: 0.0010393984848633409
Epoch 13/15,  Training Loss: 0.30792728066444397 Val Loss: 0.31330856680870056 
            Training MAE: 0.06858286261558533 Val mae: 0.4657250940799713 
            Train epipolar error pred unormalized: 20875.669921875 Val epipolar error pred unormalized: 424232.40625
            Train epipolar error pred: 468.25665283203125 Val epipolar error pred:  5791.36669921875
            penalty_coeff: 1, batch_size: 16 penalty: 1.1510030031204224
Epoch 14/15,  Training Loss: 1.4328159093856812 Val Loss: 0.307620108127594 
            Training MAE: 0.43961161375045776 Val mae: 0.4665476977825165 
            Train epipolar error pred unormalized: 282581.875 Val epipolar error pred unormalized: 603850.125
            Train epipolar error pred: 5883.6064453125 Val epipolar error pred:  5632.50732421875
            penalty_coeff: 1, batch_size: 16 penalty: 0.021412281319499016
Epoch 15/15,  Training Loss: 0.3714008331298828 Val Loss: 0.2610691785812378 
            Training MAE: 0.39819398522377014 Val mae: 0.41450703144073486 
            Train epipolar error pred unormalized: 128883.6484375 Val epipolar error pred unormalized: 100824.9375
            Train epipolar error pred: 5397.18505859375 Val epipolar error pred:  5361.7939453125
            penalty_coeff: 1, batch_size: 16 penalty: 0.031177103519439697
Train ground truth error: 0.0024118467699736357 val ground truth error: 0.0021608450915664434


learning_rate: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 2, use_reconstruction_layer: False, batch_size: 16, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False

Epoch 1/15,  Training Loss: 0.7010717988014221 Val Loss: 0.1526457965373993 
            Training MAE: 0.3588206171989441 Val mae: 0.3358146846294403 
            Train epipolar error pred unormalized: 42617.74609375 Val epipolar error pred unormalized: 22569.041015625
            Train epipolar error pred: 4943.3671875 Val epipolar error pred:  5897.0654296875
            penalty_coeff: 2, batch_size: 16 penalty: 0.0008785288082435727
Epoch 2/15,  Training Loss: 0.22608068585395813 Val Loss: 0.10873106122016907 
            Training MAE: 0.32626792788505554 Val mae: 0.26582062244415283 
            Train epipolar error pred unormalized: 16399.26171875 Val epipolar error pred unormalized: 1656.0771484375
            Train epipolar error pred: 4456.869140625 Val epipolar error pred:  1666.77783203125
            penalty_coeff: 2, batch_size: 16 penalty: 0.005460450891405344
Epoch 3/15,  Training Loss: 0.14964894950389862 Val Loss: 0.10499275475740433 
            Training MAE: 0.2819530963897705 Val mae: 0.25673678517341614 
            Train epipolar error pred unormalized: 3347.5576171875 Val epipolar error pred unormalized: 1106.7611083984375
            Train epipolar error pred: 2044.01806640625 Val epipolar error pred:  1195.376220703125
            penalty_coeff: 2, batch_size: 16 penalty: 0.0008612821693532169
Epoch 4/15,  Training Loss: 23.346553802490234 Val Loss: 0.3191513419151306 
            Training MAE: 0.3324340879917145 Val mae: 0.485321968793869 
            Train epipolar error pred unormalized: 614655.625 Val epipolar error pred unormalized: 728407.125
            Train epipolar error pred: 3012.512939453125 Val epipolar error pred:  3970.092529296875
            penalty_coeff: 2, batch_size: 16 penalty: 0.8708434104919434
Epoch 5/15,  Training Loss: 1.7178138494491577 Val Loss: 0.2935234606266022 
            Training MAE: 0.44214877486228943 Val mae: 0.4440871477127075 
            Train epipolar error pred unormalized: 314025.71875 Val epipolar error pred unormalized: 94561.7265625
            Train epipolar error pred: 3820.910400390625 Val epipolar error pred:  3319.900146484375
            penalty_coeff: 2, batch_size: 16 penalty: 0.11829637736082077
Epoch 6/15,  Training Loss: 0.6156412959098816 Val Loss: 0.2890340983867645 
            Training MAE: 0.42879927158355713 Val mae: 0.44829118251800537 
            Train epipolar error pred unormalized: 171161.6875 Val epipolar error pred unormalized: 149510.59375
            Train epipolar error pred: 4152.880859375 Val epipolar error pred:  4101.7060546875
            penalty_coeff: 2, batch_size: 16 penalty: 0.08849521726369858
Epoch 7/15,  Training Loss: 0.464812695980072 Val Loss: 0.24075718224048615 
            Training MAE: 0.3963184356689453 Val mae: 0.39861974120140076 
            Train epipolar error pred unormalized: 121967.0390625 Val epipolar error pred unormalized: 86912.0546875
            Train epipolar error pred: 4671.85595703125 Val epipolar error pred:  4792.97607421875
            penalty_coeff: 2, batch_size: 16 penalty: 0.07697119563817978
Epoch 8/15,  Training Loss: 0.4322732985019684 Val Loss: 0.2136811763048172 
            Training MAE: 0.36788734793663025 Val mae: 0.3624246120452881 
            Train epipolar error pred unormalized: 102200.9375 Val epipolar error pred unormalized: 56750.14453125
            Train epipolar error pred: 4776.7626953125 Val epipolar error pred:  4425.66796875
            penalty_coeff: 2, batch_size: 16 penalty: 0.007047547027468681
Epoch 9/15,  Training Loss: 1.2476160526275635 Val Loss: 0.2611013352870941 
            Training MAE: 0.3947218954563141 Val mae: 0.4143492579460144 
            Train epipolar error pred unormalized: 255378.90625 Val epipolar error pred unormalized: 133137.5
            Train epipolar error pred: 4321.48583984375 Val epipolar error pred:  3186.21533203125
            penalty_coeff: 2, batch_size: 16 penalty: 0.049486611038446426
Epoch 10/15,  Training Loss: 0.34492483735084534 Val Loss: 0.17727774381637573 
            Training MAE: 0.3487989008426666 Val mae: 0.3163875341415405 
            Train epipolar error pred unormalized: 89105.7265625 Val epipolar error pred unormalized: 38799.90625
            Train epipolar error pred: 4149.80322265625 Val epipolar error pred:  3523.233154296875
            penalty_coeff: 2, batch_size: 16 penalty: 0.044320378452539444
Epoch 11/15,  Training Loss: 0.29655104875564575 Val Loss: 0.14220568537712097 
            Training MAE: 0.31641510128974915 Val mae: 0.2915891408920288 
            Train epipolar error pred unormalized: 68857.5546875 Val epipolar error pred unormalized: 31565.9765625
            Train epipolar error pred: 4178.38720703125 Val epipolar error pred:  2815.633544921875
            penalty_coeff: 2, batch_size: 16 penalty: 0.03746791183948517
Epoch 12/15,  Training Loss: 0.25637713074684143 Val Loss: 0.20403657853603363 
            Training MAE: 0.2857227027416229 Val mae: 0.35646989941596985 
            Train epipolar error pred unormalized: 38399.4765625 Val epipolar error pred unormalized: 79343.4375
            Train epipolar error pred: 3320.717529296875 Val epipolar error pred:  4820.6572265625
            penalty_coeff: 2, batch_size: 16 penalty: 0.1417400985956192
Epoch 13/15,  Training Loss: 3.2023043632507324 Val Loss: 0.21984653174877167 
            Training MAE: 0.3740333020687103 Val mae: 0.3895857036113739 
            Train epipolar error pred unormalized: 414243.78125 Val epipolar error pred unormalized: 339919.3125
            Train epipolar error pred: 4450.4462890625 Val epipolar error pred:  3184.145751953125
            penalty_coeff: 2, batch_size: 16 penalty: 0.3807636797428131
Epoch 14/15,  Training Loss: 0.6212263703346252 Val Loss: 0.14188213646411896 
            Training MAE: 0.34816956520080566 Val mae: 0.28593751788139343 
            Train epipolar error pred unormalized: 153388.703125 Val epipolar error pred unormalized: 36955.8671875
            Train epipolar error pred: 3390.498291015625 Val epipolar error pred:  2290.90185546875
            penalty_coeff: 2, batch_size: 16 penalty: 0.04037462919950485
Epoch 15/15,  Training Loss: 0.37177789211273193 Val Loss: 0.14661777019500732 
            Training MAE: 0.3188176453113556 Val mae: 0.2823832035064697 
            Train epipolar error pred unormalized: 69572.6484375 Val epipolar error pred unormalized: 52028.25
            Train epipolar error pred: 2581.380126953125 Val epipolar error pred:  2112.28369140625
            penalty_coeff: 2, batch_size: 16 penalty: 0.06627579033374786
Train ground truth error: 0.0024115026462823153 val ground truth error: 0.0021608450915664434


learning_rate: 5e-05, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 2, use_reconstruction_layer: False, batch_size: 16, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False

Epoch 1/15,  Training Loss: 0.17099709808826447 Val Loss: 0.05471343919634819 
            Training MAE: 0.20393098890781403 Val mae: 0.13144567608833313 
            Train epipolar error pred unormalized: 2848.238525390625 Val epipolar error pred unormalized: 109.075439453125
            Train epipolar error pred: 1332.6553955078125 Val epipolar error pred:  373.4471740722656
            penalty_coeff: 2, batch_size: 16 penalty: 0.010541912168264389
Epoch 2/15,  Training Loss: 0.08918631076812744 Val Loss: 0.05326171964406967 
            Training MAE: 0.16550737619400024 Val mae: 0.12388207018375397 
            Train epipolar error pred unormalized: 44.81658172607422 Val epipolar error pred unormalized: 71.0536880493164
            Train epipolar error pred: 135.95875549316406 Val epipolar error pred:  189.89453125
            penalty_coeff: 2, batch_size: 16 penalty: 0.0022689083125442266
Epoch 3/15,  Training Loss: 0.0840579941868782 Val Loss: 0.057344626635313034 
            Training MAE: 0.16142845153808594 Val mae: 0.12064478546380997 
            Train epipolar error pred unormalized: 56.133060455322266 Val epipolar error pred unormalized: 44.43271255493164
            Train epipolar error pred: 188.09921264648438 Val epipolar error pred:  144.8218536376953
            penalty_coeff: 2, batch_size: 16 penalty: 0.0029153304640203714
Epoch 4/15,  Training Loss: 0.06960946321487427 Val Loss: 0.06559599936008453 
            Training MAE: 0.14403629302978516 Val mae: 0.12420853972434998 
            Train epipolar error pred unormalized: 48.80019760131836 Val epipolar error pred unormalized: 26.12137794494629
            Train epipolar error pred: 242.53378295898438 Val epipolar error pred:  146.76268005371094
            penalty_coeff: 2, batch_size: 16 penalty: 0.0016317671397700906
Epoch 5/15,  Training Loss: 0.050776734948158264 Val Loss: 0.06875482201576233 
            Training MAE: 0.11738447844982147 Val mae: 0.12401670217514038 
            Train epipolar error pred unormalized: 42.554603576660156 Val epipolar error pred unormalized: 29.749629974365234
            Train epipolar error pred: 217.01046752929688 Val epipolar error pred:  135.3589630126953
            penalty_coeff: 2, batch_size: 16 penalty: 0.002443365752696991
Epoch 6/15,  Training Loss: 0.0315791554749012 Val Loss: 0.07964019477367401 
            Training MAE: 0.09009205549955368 Val mae: 0.13532936573028564 
            Train epipolar error pred unormalized: 41.39945602416992 Val epipolar error pred unormalized: 38.186893463134766
            Train epipolar error pred: 180.32908630371094 Val epipolar error pred:  208.3934783935547
            penalty_coeff: 2, batch_size: 16 penalty: 0.0031116949394345284
Epoch 7/15,  Training Loss: 0.021199991926550865 Val Loss: 0.08193129301071167 
            Training MAE: 0.07257389277219772 Val mae: 0.1351040005683899 
            Train epipolar error pred unormalized: 41.949501037597656 Val epipolar error pred unormalized: 39.81154251098633
            Train epipolar error pred: 152.8119354248047 Val epipolar error pred:  196.63900756835938
            penalty_coeff: 2, batch_size: 16 penalty: 0.0013620373792946339
Epoch 8/15,  Training Loss: 0.015576423145830631 Val Loss: 0.07180439680814743 
            Training MAE: 0.06115062162280083 Val mae: 0.12526266276836395 
            Train epipolar error pred unormalized: 39.06889724731445 Val epipolar error pred unormalized: 31.697460174560547
            Train epipolar error pred: 137.60911560058594 Val epipolar error pred:  163.88168334960938
            penalty_coeff: 2, batch_size: 16 penalty: 0.001023976830765605
Epoch 9/15,  Training Loss: 0.012210858054459095 Val Loss: 0.07194258272647858 
            Training MAE: 0.053010087460279465 Val mae: 0.12422425299882889 
            Train epipolar error pred unormalized: 31.842500686645508 Val epipolar error pred unormalized: 25.728439331054688
            Train epipolar error pred: 108.5946044921875 Val epipolar error pred:  118.54117584228516
            penalty_coeff: 2, batch_size: 16 penalty: 0.0016730743227526546
Epoch 10/15,  Training Loss: 0.010519414208829403 Val Loss: 0.07533226162195206 
            Training MAE: 0.04828554764389992 Val mae: 0.12583240866661072 
            Train epipolar error pred unormalized: 32.97789764404297 Val epipolar error pred unormalized: 22.924959182739258
            Train epipolar error pred: 110.0876693725586 Val epipolar error pred:  132.8314971923828
            penalty_coeff: 2, batch_size: 16 penalty: 0.001624959404580295
Epoch 11/15,  Training Loss: 0.009923240169882774 Val Loss: 0.08451519161462784 
            Training MAE: 0.04573410004377365 Val mae: 0.1386910080909729 
            Train epipolar error pred unormalized: 29.36629867553711 Val epipolar error pred unormalized: 39.093563079833984
            Train epipolar error pred: 96.50025177001953 Val epipolar error pred:  226.6800079345703
            penalty_coeff: 2, batch_size: 16 penalty: 0.0022871913388371468
Epoch 12/15,  Training Loss: 0.009599680081009865 Val Loss: 0.07217046618461609 
            Training MAE: 0.04538777843117714 Val mae: 0.1264520287513733 
            Train epipolar error pred unormalized: 31.975746154785156 Val epipolar error pred unormalized: 30.274213790893555
            Train epipolar error pred: 99.51286315917969 Val epipolar error pred:  164.8496551513672
            penalty_coeff: 2, batch_size: 16 penalty: 0.001745917135849595
Epoch 13/15,  Training Loss: 0.00989754218608141 Val Loss: 0.07358574867248535 
            Training MAE: 0.045771073549985886 Val mae: 0.1291787177324295 
            Train epipolar error pred unormalized: 33.18012237548828 Val epipolar error pred unormalized: 37.36986541748047
            Train epipolar error pred: 97.36052703857422 Val epipolar error pred:  188.57119750976562
            penalty_coeff: 2, batch_size: 16 penalty: 0.0016702200518921018
Epoch 14/15,  Training Loss: 0.011639759875833988 Val Loss: 0.07710208743810654 
            Training MAE: 0.04854227229952812 Val mae: 0.12686122953891754 
            Train epipolar error pred unormalized: 37.95386505126953 Val epipolar error pred unormalized: 28.365686416625977
            Train epipolar error pred: 96.1427993774414 Val epipolar error pred:  119.18656921386719
            penalty_coeff: 2, batch_size: 16 penalty: 0.0013353369431570172
Epoch 15/15,  Training Loss: 0.009555217809975147 Val Loss: 0.07326572388410568 
            Training MAE: 0.04436570033431053 Val mae: 0.12844204902648926 
            Train epipolar error pred unormalized: 30.878408432006836 Val epipolar error pred unormalized: 22.013437271118164
            Train epipolar error pred: 79.05433654785156 Val epipolar error pred:  96.23790740966797
            penalty_coeff: 2, batch_size: 16 penalty: 0.0010586167918518186
Train ground truth error: 0.002412136411294341 val ground truth error: 0.0021608450915664434


learning_rate: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False, batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False

Epoch 1/15,  Training Loss: 0.7877817153930664 Val Loss: 0.09683342278003693 
            Training MAE: 0.32036641240119934 Val mae: 0.22456274926662445 
            Train epipolar error pred unormalized: 134453.5625 Val epipolar error pred unormalized: 6314.15185546875
            Train epipolar error pred: 9310.46875 Val epipolar error pred:  2664.12158203125
            penalty_coeff: 1, batch_size: 32 penalty: 0.057905085384845734
Epoch 2/15,  Training Loss: 0.2501974105834961 Val Loss: 0.09476785361766815 
            Training MAE: 0.2594127953052521 Val mae: 0.2168174386024475 
            Train epipolar error pred unormalized: 29419.5234375 Val epipolar error pred unormalized: 10407.25390625
            Train epipolar error pred: 4609.82958984375 Val epipolar error pred:  2987.866943359375
            penalty_coeff: 1, batch_size: 32 penalty: 0.047659583389759064
Epoch 3/15,  Training Loss: 0.13942237198352814 Val Loss: 0.054967477917671204 
            Training MAE: 0.20353417098522186 Val mae: 0.13928347826004028 
            Train epipolar error pred unormalized: 2559.003173828125 Val epipolar error pred unormalized: 305.9316711425781
            Train epipolar error pred: 991.933349609375 Val epipolar error pred:  288.388916015625
            penalty_coeff: 1, batch_size: 32 penalty: 0.017166338860988617
Epoch 4/15,  Training Loss: 0.09609489887952805 Val Loss: 0.052908435463905334 
            Training MAE: 0.17730136215686798 Val mae: 0.12118985503911972 
            Train epipolar error pred unormalized: 333.54095458984375 Val epipolar error pred unormalized: 82.80962371826172
            Train epipolar error pred: 226.8089141845703 Val epipolar error pred:  98.94034576416016
            penalty_coeff: 1, batch_size: 32 penalty: 0.0017205250915139914
Epoch 5/15,  Training Loss: 0.08792009949684143 Val Loss: 0.05257594585418701 
            Training MAE: 0.166121706366539 Val mae: 0.11774641275405884 
            Train epipolar error pred unormalized: 68.89845275878906 Val epipolar error pred unormalized: 49.011661529541016
            Train epipolar error pred: 74.98248291015625 Val epipolar error pred:  74.42386627197266
            penalty_coeff: 1, batch_size: 32 penalty: 0.0032841323409229517
Epoch 6/15,  Training Loss: 0.08641936630010605 Val Loss: 0.05276838317513466 
            Training MAE: 0.16397497057914734 Val mae: 0.11495783925056458 
            Train epipolar error pred unormalized: 43.81684875488281 Val epipolar error pred unormalized: 15.720787048339844
            Train epipolar error pred: 59.69865417480469 Val epipolar error pred:  26.662172317504883
            penalty_coeff: 1, batch_size: 32 penalty: 0.0013396601425483823
Epoch 7/15,  Training Loss: 0.08326855301856995 Val Loss: 0.052688803523778915 
            Training MAE: 0.16097690165042877 Val mae: 0.11502974480390549 
            Train epipolar error pred unormalized: 21.224828720092773 Val epipolar error pred unormalized: 4.538366317749023
            Train epipolar error pred: 36.53285217285156 Val epipolar error pred:  8.86792278289795
            penalty_coeff: 1, batch_size: 32 penalty: 0.0005184761248528957
Epoch 8/15,  Training Loss: 0.08311530202627182 Val Loss: 0.05231481418013573 
            Training MAE: 0.16080065071582794 Val mae: 0.11701543629169464 
            Train epipolar error pred unormalized: 14.646730422973633 Val epipolar error pred unormalized: 5.7403693199157715
            Train epipolar error pred: 29.47803497314453 Val epipolar error pred:  12.301016807556152
            penalty_coeff: 1, batch_size: 32 penalty: 0.0012484922772273421
Epoch 9/15,  Training Loss: 0.08238963037729263 Val Loss: 0.05384888872504234 
            Training MAE: 0.16151835024356842 Val mae: 0.12205637991428375 
            Train epipolar error pred unormalized: 20.53600311279297 Val epipolar error pred unormalized: 26.433849334716797
            Train epipolar error pred: 43.915775299072266 Val epipolar error pred:  112.4053955078125
            penalty_coeff: 1, batch_size: 32 penalty: 0.001877950388006866
Epoch 10/15,  Training Loss: 0.08071884512901306 Val Loss: 0.053375255316495895 
            Training MAE: 0.15936806797981262 Val mae: 0.12100157886743546 
            Train epipolar error pred unormalized: 22.060232162475586 Val epipolar error pred unormalized: 33.731719970703125
            Train epipolar error pred: 62.93228530883789 Val epipolar error pred:  106.90538024902344
            penalty_coeff: 1, batch_size: 32 penalty: 0.0020321072079241276
Epoch 11/15,  Training Loss: 0.07793372124433517 Val Loss: 0.05560511350631714 
            Training MAE: 0.15663498640060425 Val mae: 0.1213218942284584 
            Train epipolar error pred unormalized: 32.46877670288086 Val epipolar error pred unormalized: 20.156057357788086
            Train epipolar error pred: 96.28165435791016 Val epipolar error pred:  74.20585632324219
            penalty_coeff: 1, batch_size: 32 penalty: 0.0036410032771527767
Epoch 12/15,  Training Loss: 0.07299820333719254 Val Loss: 0.0685897096991539 
            Training MAE: 0.14987628161907196 Val mae: 0.13417695462703705 
            Train epipolar error pred unormalized: 29.102581024169922 Val epipolar error pred unormalized: 31.455759048461914
            Train epipolar error pred: 101.01795959472656 Val epipolar error pred:  192.62835693359375
            penalty_coeff: 1, batch_size: 32 penalty: 0.003033992601558566
Epoch 13/15,  Training Loss: 0.06800390034914017 Val Loss: 0.07731769233942032 
            Training MAE: 0.1434137374162674 Val mae: 0.13982966542243958 
            Train epipolar error pred unormalized: 36.161415100097656 Val epipolar error pred unormalized: 27.69919776916504
            Train epipolar error pred: 134.42042541503906 Val epipolar error pred:  166.56011962890625
            penalty_coeff: 1, batch_size: 32 penalty: 0.002330935560166836
Epoch 14/15,  Training Loss: 0.060362786054611206 Val Loss: 0.08098773658275604 
            Training MAE: 0.13310909271240234 Val mae: 0.13766399025917053 
            Train epipolar error pred unormalized: 37.30796432495117 Val epipolar error pred unormalized: 35.648658752441406
            Train epipolar error pred: 147.00621032714844 Val epipolar error pred:  183.3209228515625
            penalty_coeff: 1, batch_size: 32 penalty: 0.0030139561276882887
Epoch 15/15,  Training Loss: 0.05191320553421974 Val Loss: 0.08846959471702576 
            Training MAE: 0.12184581160545349 Val mae: 0.1496892124414444 
            Train epipolar error pred unormalized: 47.57541275024414 Val epipolar error pred unormalized: 52.747314453125
            Train epipolar error pred: 173.45494079589844 Val epipolar error pred:  196.43338012695312
            penalty_coeff: 1, batch_size: 32 penalty: 0.0020387088879942894
Train ground truth error: 0.0024112637620419264 val ground truth error: 0.002143849153071642


learning_rate: 5e-05, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 1, use_reconstruction_layer: False, batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False

Epoch 1/15,  Training Loss: 0.12525290250778198 Val Loss: 0.05259094387292862 
            Training MAE: 0.20806463062763214 Val mae: 0.11865032464265823 
            Train epipolar error pred unormalized: 3037.61376953125 Val epipolar error pred unormalized: 38.156044006347656
            Train epipolar error pred: 2561.5546875 Val epipolar error pred:  80.00963592529297
            penalty_coeff: 1, batch_size: 32 penalty: 0.0013936276081949472
Epoch 2/15,  Training Loss: 0.08374685049057007 Val Loss: 0.05362877994775772 
            Training MAE: 0.1634235680103302 Val mae: 0.11721052974462509 
            Train epipolar error pred unormalized: 32.07190704345703 Val epipolar error pred unormalized: 17.356517791748047
            Train epipolar error pred: 95.67997741699219 Val epipolar error pred:  65.72964477539062
            penalty_coeff: 1, batch_size: 32 penalty: 0.002525127027183771
Epoch 3/15,  Training Loss: nan Val Loss: nan 
            Training MAE: nan Val mae: nan 
            Train epipolar error pred unormalized: nan Val epipolar error pred unormalized: nan
            Train epipolar error pred: nan Val epipolar error pred:  nan
            penalty_coeff: 1, batch_size: 32 penalty: nan
Epoch 4/15,  Training Loss: nan Val Loss: nan 
            Training MAE: nan Val mae: nan 
            Train epipolar error pred unormalized: nan Val epipolar error pred unormalized: nan
            Train epipolar error pred: nan Val epipolar error pred:  nan
            penalty_coeff: 1, batch_size: 32 penalty: nan
Epoch 5/15,  Training Loss: nan Val Loss: nan 
            Training MAE: nan Val mae: nan 
            Train epipolar error pred unormalized: nan Val epipolar error pred unormalized: nan
            Train epipolar error pred: nan Val epipolar error pred:  nan
            penalty_coeff: 1, batch_size: 32 penalty: nan
Epoch 6/15,  Training Loss: nan Val Loss: nan 
            Training MAE: nan Val mae: nan 
            Train epipolar error pred unormalized: nan Val epipolar error pred unormalized: nan
            Train epipolar error pred: nan Val epipolar error pred:  nan
            penalty_coeff: 1, batch_size: 32 penalty: nan
Epoch 7/15,  Training Loss: nan Val Loss: nan 
            Training MAE: nan Val mae: nan 
            Train epipolar error pred unormalized: nan Val epipolar error pred unormalized: nan
            Train epipolar error pred: nan Val epipolar error pred:  nan
            penalty_coeff: 1, batch_size: 32 penalty: nan
Epoch 8/15,  Training Loss: nan Val Loss: nan 
            Training MAE: nan Val mae: nan 
            Train epipolar error pred unormalized: nan Val epipolar error pred unormalized: nan
            Train epipolar error pred: nan Val epipolar error pred:  nan
            penalty_coeff: 1, batch_size: 32 penalty: nan
Epoch 9/15,  Training Loss: nan Val Loss: nan 
            Training MAE: nan Val mae: nan 
            Train epipolar error pred unormalized: nan Val epipolar error pred unormalized: nan
            Train epipolar error pred: nan Val epipolar error pred:  nan
            penalty_coeff: 1, batch_size: 32 penalty: nan
Epoch 10/15,  Training Loss: nan Val Loss: nan 
            Training MAE: nan Val mae: nan 
            Train epipolar error pred unormalized: nan Val epipolar error pred unormalized: nan
            Train epipolar error pred: nan Val epipolar error pred:  nan
            penalty_coeff: 1, batch_size: 32 penalty: nan
Epoch 11/15,  Training Loss: nan Val Loss: nan 
            Training MAE: nan Val mae: nan 
            Train epipolar error pred unormalized: nan Val epipolar error pred unormalized: nan
            Train epipolar error pred: nan Val epipolar error pred:  nan
            penalty_coeff: 1, batch_size: 32 penalty: nan
Epoch 12/15,  Training Loss: nan Val Loss: nan 
            Training MAE: nan Val mae: nan 
            Train epipolar error pred unormalized: nan Val epipolar error pred unormalized: nan
            Train epipolar error pred: nan Val epipolar error pred:  nan
            penalty_coeff: 1, batch_size: 32 penalty: nan
Epoch 13/15,  Training Loss: nan Val Loss: nan 
            Training MAE: nan Val mae: nan 
            Train epipolar error pred unormalized: nan Val epipolar error pred unormalized: nan
            Train epipolar error pred: nan Val epipolar error pred:  nan
            penalty_coeff: 1, batch_size: 32 penalty: nan
Epoch 14/15,  Training Loss: nan Val Loss: nan 
            Training MAE: nan Val mae: nan 
            Train epipolar error pred unormalized: nan Val epipolar error pred unormalized: nan
            Train epipolar error pred: nan Val epipolar error pred:  nan
            penalty_coeff: 1, batch_size: 32 penalty: nan
Epoch 15/15,  Training Loss: nan Val Loss: nan 
            Training MAE: nan Val mae: nan 
            Train epipolar error pred unormalized: nan Val epipolar error pred unormalized: nan
            Train epipolar error pred: nan Val epipolar error pred:  nan
            penalty_coeff: 1, batch_size: 32 penalty: nan
Train ground truth error: 0.0024122362956404686 val ground truth error: 0.002143849153071642


learning_rate: 0.0001, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 2, use_reconstruction_layer: False, batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False

Epoch 1/15,  Training Loss: 1.1053005456924438 Val Loss: 0.2597060203552246 
            Training MAE: 0.4102010428905487 Val mae: 0.42868712544441223 
            Train epipolar error pred unormalized: 70357.046875 Val epipolar error pred unormalized: 19776.978515625
            Train epipolar error pred: 8420.9794921875 Val epipolar error pred:  5705.16796875
            penalty_coeff: 2, batch_size: 32 penalty: 0.029279092326760292
Epoch 2/15,  Training Loss: 2.9955503940582275 Val Loss: 0.24853327870368958 
            Training MAE: 0.385376900434494 Val mae: 0.39222148060798645 
            Train epipolar error pred unormalized: 119795.78125 Val epipolar error pred unormalized: 42463.4921875
            Train epipolar error pred: 5878.85400390625 Val epipolar error pred:  3708.938720703125
            penalty_coeff: 2, batch_size: 32 penalty: 0.5592503547668457
Epoch 3/15,  Training Loss: 0.44607359170913696 Val Loss: 0.13174709677696228 
            Training MAE: 0.3431757092475891 Val mae: 0.281175434589386 
            Train epipolar error pred unormalized: 48332.76171875 Val epipolar error pred unormalized: 12043.0302734375
            Train epipolar error pred: 5158.6162109375 Val epipolar error pred:  4356.78515625
            penalty_coeff: 2, batch_size: 32 penalty: 0.01408930029720068
Epoch 4/15,  Training Loss: 0.3984450101852417 Val Loss: 0.12871533632278442 
            Training MAE: 0.32441622018814087 Val mae: 0.29786190390586853 
            Train epipolar error pred unormalized: 31758.5859375 Val epipolar error pred unormalized: 6351.86181640625
            Train epipolar error pred: 4092.27880859375 Val epipolar error pred:  1742.622802734375
            penalty_coeff: 2, batch_size: 32 penalty: 0.030291397124528885
Epoch 5/15,  Training Loss: 0.19324377179145813 Val Loss: 0.09839517623186111 
            Training MAE: 0.2960963845252991 Val mae: 0.24586062133312225 
            Train epipolar error pred unormalized: 4152.64453125 Val epipolar error pred unormalized: 1171.9146728515625
            Train epipolar error pred: 1315.4932861328125 Val epipolar error pred:  492.9544982910156
            penalty_coeff: 2, batch_size: 32 penalty: 0.010491212829947472
Epoch 6/15,  Training Loss: 0.1519627571105957 Val Loss: 0.08843395859003067 
            Training MAE: 0.2620300054550171 Val mae: 0.2139793187379837 
            Train epipolar error pred unormalized: 2803.699951171875 Val epipolar error pred unormalized: 2448.42333984375
            Train epipolar error pred: 1484.98095703125 Val epipolar error pred:  1821.2584228515625
            penalty_coeff: 2, batch_size: 32 penalty: 0.013255917467176914
Epoch 7/15,  Training Loss: 0.13146284222602844 Val Loss: 0.07117785513401031 
            Training MAE: 0.23332147300243378 Val mae: 0.19117262959480286 
            Train epipolar error pred unormalized: 2757.0595703125 Val epipolar error pred unormalized: 2174.40673828125
            Train epipolar error pred: 1796.0323486328125 Val epipolar error pred:  1751.1287841796875
            penalty_coeff: 2, batch_size: 32 penalty: 0.0034641220699995756
Epoch 8/15,  Training Loss: 0.19416670501232147 Val Loss: 0.08798792213201523 
            Training MAE: 0.25748661160469055 Val mae: 0.2224314659833908 
            Train epipolar error pred unormalized: 5384.447265625 Val epipolar error pred unormalized: 7755.57666015625
            Train epipolar error pred: 1999.018798828125 Val epipolar error pred:  2958.544921875
            penalty_coeff: 2, batch_size: 32 penalty: 0.03962785378098488
Epoch 9/15,  Training Loss: 0.13674136996269226 Val Loss: 0.07171215116977692 
            Training MAE: 0.23731179535388947 Val mae: 0.20045579969882965 
            Train epipolar error pred unormalized: 4551.7080078125 Val epipolar error pred unormalized: 3086.156982421875
            Train epipolar error pred: 2369.849853515625 Val epipolar error pred:  2489.48779296875
            penalty_coeff: 2, batch_size: 32 penalty: 0.04158253222703934
Epoch 10/15,  Training Loss: 0.12557590007781982 Val Loss: 0.06933850795030594 
            Training MAE: 0.22209863364696503 Val mae: 0.19413213431835175 
            Train epipolar error pred unormalized: 2090.684814453125 Val epipolar error pred unormalized: 2400.31298828125
            Train epipolar error pred: 1602.746826171875 Val epipolar error pred:  2109.017578125
            penalty_coeff: 2, batch_size: 32 penalty: 0.00044726228225044906
Epoch 11/15,  Training Loss: 0.11982561647891998 Val Loss: 0.06385454535484314 
            Training MAE: 0.2141931802034378 Val mae: 0.1780467927455902 
            Train epipolar error pred unormalized: 1848.927734375 Val epipolar error pred unormalized: 2420.326171875
            Train epipolar error pred: 1607.017578125 Val epipolar error pred:  1384.00341796875
            penalty_coeff: 2, batch_size: 32 penalty: 0.048030201345682144
Epoch 12/15,  Training Loss: 0.1309678852558136 Val Loss: 0.05886729806661606 
            Training MAE: 0.20563632249832153 Val mae: 0.15362483263015747 
            Train epipolar error pred unormalized: 1959.554931640625 Val epipolar error pred unormalized: 622.777099609375
            Train epipolar error pred: 1099.580810546875 Val epipolar error pred:  809.2549438476562
            penalty_coeff: 2, batch_size: 32 penalty: 0.003947458229959011
Epoch 13/15,  Training Loss: 0.16350895166397095 Val Loss: 0.07865823805332184 
            Training MAE: 0.20185358822345734 Val mae: 0.210865780711174 
            Train epipolar error pred unormalized: 1254.5909423828125 Val epipolar error pred unormalized: 1398.864013671875
            Train epipolar error pred: 755.6887817382812 Val epipolar error pred:  272.2437744140625
            penalty_coeff: 2, batch_size: 32 penalty: 0.2108648121356964
Epoch 14/15,  Training Loss: 27.489330291748047 Val Loss: 0.12502214312553406 
            Training MAE: 0.2925933301448822 Val mae: 0.2884989380836487 
            Train epipolar error pred unormalized: 908121.3125 Val epipolar error pred unormalized: 2991052.25
            Train epipolar error pred: 4177.595703125 Val epipolar error pred:  6521.43701171875
            penalty_coeff: 2, batch_size: 32 penalty: 25.687999725341797
Epoch 15/15,  Training Loss: 3.760344982147217 Val Loss: 0.12842486798763275 
            Training MAE: 0.31915995478630066 Val mae: 0.3032201826572418 
            Train epipolar error pred unormalized: 619540.125 Val epipolar error pred unormalized: 232315.296875
            Train epipolar error pred: 5922.43359375 Val epipolar error pred:  6119.255859375
            penalty_coeff: 2, batch_size: 32 penalty: 0.12171810120344162
Train ground truth error: 0.002415382070466876 val ground truth error: 0.002143849153071642


learning_rate: 5e-05, mlp_hidden_sizes: [512, 256], jump_frames: 2, penalty_coeff: 2, use_reconstruction_layer: False, batch_size: 32, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], penaltize_normalized: False

Epoch 1/15,  Training Loss: 0.21515588462352753 Val Loss: 0.09363700449466705 
            Training MAE: 0.27222734689712524 Val mae: 0.22682152688503265 
            Train epipolar error pred unormalized: 2044.74169921875 Val epipolar error pred unormalized: 2975.621826171875
            Train epipolar error pred: 1525.95751953125 Val epipolar error pred:  1620.10595703125
            penalty_coeff: 2, batch_size: 32 penalty: 0.10005105286836624
Epoch 2/15,  Training Loss: 0.27031105756759644 Val Loss: 0.06500214338302612 
            Training MAE: 0.2270585596561432 Val mae: 0.1755865067243576 
            Train epipolar error pred unormalized: 3613.88818359375 Val epipolar error pred unormalized: 2111.0771484375
            Train epipolar error pred: 1580.0162353515625 Val epipolar error pred:  1402.761962890625
            penalty_coeff: 2, batch_size: 32 penalty: 0.006371890194714069
Epoch 3/15,  Training Loss: 0.16357176005840302 Val Loss: 0.05522727593779564 
            Training MAE: 0.20527179539203644 Val mae: 0.14143237471580505 
            Train epipolar error pred unormalized: 1727.0267333984375 Val epipolar error pred unormalized: 162.9952850341797
            Train epipolar error pred: 888.7266845703125 Val epipolar error pred:  173.3735809326172
            penalty_coeff: 2, batch_size: 32 penalty: 0.0030538374558091164
Epoch 4/15,  Training Loss: 0.09063099324703217 Val Loss: 0.0533657968044281 
            Training MAE: 0.17269834876060486 Val mae: 0.1245405524969101 
            Train epipolar error pred unormalized: 91.65123748779297 Val epipolar error pred unormalized: 81.41468811035156
            Train epipolar error pred: 111.44501495361328 Val epipolar error pred:  87.14339447021484
            penalty_coeff: 2, batch_size: 32 penalty: 0.01125379465520382
Epoch 5/15,  Training Loss: 0.09090449661016464 Val Loss: 0.053586073219776154 
            Training MAE: 0.1660526543855667 Val mae: 0.13382545113563538 
            Train epipolar error pred unormalized: 53.35236740112305 Val epipolar error pred unormalized: 506.19390869140625
            Train epipolar error pred: 77.88890075683594 Val epipolar error pred:  354.9787902832031
            penalty_coeff: 2, batch_size: 32 penalty: 0.02503267116844654
Epoch 6/15,  Training Loss: 0.10454437881708145 Val Loss: 0.053759749978780746 
            Training MAE: 0.17462043464183807 Val mae: 0.12765467166900635 
            Train epipolar error pred unormalized: 248.4026336669922 Val epipolar error pred unormalized: 70.6072006225586
            Train epipolar error pred: 194.23655700683594 Val epipolar error pred:  55.65430450439453
            penalty_coeff: 2, batch_size: 32 penalty: 0.014092672616243362
Epoch 7/15,  Training Loss: 0.1038835272192955 Val Loss: 0.05286231264472008 
            Training MAE: 0.17311549186706543 Val mae: 0.12252645194530487 
            Train epipolar error pred unormalized: 127.32559204101562 Val epipolar error pred unormalized: 27.209754943847656
            Train epipolar error pred: 122.04576873779297 Val epipolar error pred:  31.526885986328125
            penalty_coeff: 2, batch_size: 32 penalty: 0.001729245064780116
Epoch 8/15,  Training Loss: 0.08631690591573715 Val Loss: 0.052721720188856125 
            Training MAE: 0.16300198435783386 Val mae: 0.11908608675003052 
            Train epipolar error pred unormalized: 33.68500518798828 Val epipolar error pred unormalized: 23.285926818847656
            Train epipolar error pred: 49.787193298339844 Val epipolar error pred:  70.57318878173828
            penalty_coeff: 2, batch_size: 32 penalty: 0.001169470022432506
Epoch 9/15,  Training Loss: 0.08995775133371353 Val Loss: 0.05266248807311058 
            Training MAE: 0.16438166797161102 Val mae: 0.11906460672616959 
            Train epipolar error pred unormalized: 65.70378875732422 Val epipolar error pred unormalized: 49.44660186767578
            Train epipolar error pred: 94.98401641845703 Val epipolar error pred:  122.12937927246094
            penalty_coeff: 2, batch_size: 32 penalty: 0.001956002553924918
Epoch 10/15,  Training Loss: 0.07866092026233673 Val Loss: 0.059929873794317245 
            Training MAE: 0.15915732085704803 Val mae: 0.12071886658668518 
            Train epipolar error pred unormalized: 26.300926208496094 Val epipolar error pred unormalized: 26.50041961669922
            Train epipolar error pred: 119.02701568603516 Val epipolar error pred:  216.79440307617188
            penalty_coeff: 2, batch_size: 32 penalty: 0.0008309950353577733
Epoch 11/15,  Training Loss: 0.06831161677837372 Val Loss: 0.06807262450456619 
            Training MAE: 0.1448022574186325 Val mae: 0.1288733333349228 
            Train epipolar error pred unormalized: 35.43904113769531 Val epipolar error pred unormalized: 18.600948333740234
            Train epipolar error pred: 202.88941955566406 Val epipolar error pred:  179.7877960205078
            penalty_coeff: 2, batch_size: 32 penalty: 0.0022707851603627205
Epoch 12/15,  Training Loss: 0.04487119987607002 Val Loss: 0.06370419263839722 
            Training MAE: 0.11305395513772964 Val mae: 0.12896302342414856 
            Train epipolar error pred unormalized: 21.878515243530273 Val epipolar error pred unormalized: 34.86888885498047
            Train epipolar error pred: 188.94337463378906 Val epipolar error pred:  266.6513366699219
            penalty_coeff: 2, batch_size: 32 penalty: 0.0019565350376069546
Epoch 13/15,  Training Loss: 0.02568461187183857 Val Loss: 0.07746808230876923 
            Training MAE: 0.08313153684139252 Val mae: 0.13147090375423431 
            Train epipolar error pred unormalized: 28.538270950317383 Val epipolar error pred unormalized: 17.527448654174805
            Train epipolar error pred: 174.111572265625 Val epipolar error pred:  159.20962524414062
            penalty_coeff: 2, batch_size: 32 penalty: 0.001129888347350061
Epoch 14/15,  Training Loss: 0.014057156629860401 Val Loss: 0.06865282356739044 
            Training MAE: 0.06099427863955498 Val mae: 0.12453491985797882 
            Train epipolar error pred unormalized: 17.7488956451416 Val epipolar error pred unormalized: 15.540643692016602
            Train epipolar error pred: 115.40345764160156 Val epipolar error pred:  183.60464477539062
            penalty_coeff: 2, batch_size: 32 penalty: 0.00249915081076324
Epoch 15/15,  Training Loss: 0.00947433803230524 Val Loss: 0.06663288921117783 
            Training MAE: 0.05029396340250969 Val mae: 0.12103195488452911 
            Train epipolar error pred unormalized: 15.695277214050293 Val epipolar error pred unormalized: 10.845906257629395
            Train epipolar error pred: 100.80923461914062 Val epipolar error pred:  119.7811050415039
            penalty_coeff: 2, batch_size: 32 penalty: 0.0006590551929548383
Train ground truth error: 0.0024083186872303486 val ground truth error: 0.002143849153071642


