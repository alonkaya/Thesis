/home/alonkay/conda/alon/lib/python3.9/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/home/alonkay/conda/alon/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/alonkay/conda/alon/lib/python3.9/site-packages/transformers/modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location=map_location)
/home/alonkay/Thesis/FMatrixRegressor.py:331: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(model_path, map_location='cpu')
###########################################################################################################################################################

 learning rate: 0.0001, mlp_hidden_sizes: [1024, 512], jump_frames: 6, use_reconstruction_layer: True
batch_size: 8, norm: True, train_seqeunces: [0, 2, 3, 5], val_sequences: [6, 7, 8], RL_TEST_NAMES: ['fe2fadf89a84e92a', 'f01e8b6f8e10fdd9', 'f1ee9dc6135e5307', 'a41df4fa06fd391b', 'bc0ebb7482f14795', '9bdd34e784c04e3a', '98ebee1c36ecec55'], dataset: Stereo,
average embeddings: False, model: openai/clip-vit-base-patch32, augmentation: True, random crop: True, part: head, get_old_path: False,
RE1 coeff: 0 SED coeff: 0.5, ALG_COEFF: 0, L2_coeff: 1, huber_coeff: 1, frozen layers: 4, trained vit: None,
crop: 224 resize: 256, use conv: True pretrained: None, train_size: 0.2, norm_mean: tensor([0.4815, 0.4578, 0.4082], device='cuda:0'), norm_std: tensor([0.2686, 0.2613, 0.2758], device='cuda:0'), sched: None seed: 42, 

train size: 2166, val size: 736, test size: 1064

##### CONTINUE TRAINING #####

Epoch 3033/4500: Training Loss: 0.1382354511106146		 Val Loss: 0.17955836005832837
             	Training MAE: 0.06227028742432594		 Val MAE: 0.059895534068346024
             	Algebraic dist: 0.2494907449532259		 Val Algebraic dist: 0.2768641347470491
             	RE1 dist: 0.061871679946505276		 Val RE1 dist: 0.08988087073616359
             	SED dist: 0.24326116132560252		 Val SED dist: 0.3267387099888014

Epoch 3034/4500: Training Loss: 0.274243344240083		 Val Loss: 1.244955477507218
             	Training MAE: 0.06258414685726166		 Val MAE: 0.0627327486872673
             	Algebraic dist: 0.35681363489355106		 Val Algebraic dist: 1.0078161488408628
             	RE1 dist: 0.13871369590618512		 Val RE1 dist: 0.7500413811725118
             	SED dist: 0.5151812000908095		 Val SED dist: 2.457238902216372


################
Empty points at 02


Epoch 3035/4500: Training Loss: 0.32498689771138434		 Val Loss: 0.2174171364825705
             	Training MAE: 0.06204398721456528		 Val MAE: 0.06384772807359695
             	Algebraic dist: 0.40796320728710217		 Val Algebraic dist: 0.34110237204510235
             	RE1 dist: 0.17163913628272026		 Val RE1 dist: 0.11875992235930069
             	SED dist: 0.6169165016540302		 Val SED dist: 0.4016187501990277

Epoch 3036/4500: Training Loss: 0.2827991049228119		 Val Loss: 0.2227028971133025
             	Training MAE: 0.06204672530293465		 Val MAE: 0.060401566326618195
             	Algebraic dist: 0.36982051384844905		 Val Algebraic dist: 0.3279834208281144
             	RE1 dist: 0.14960068706216847		 Val RE1 dist: 0.12264382320901622
             	SED dist: 0.5325834830308752		 Val SED dist: 0.41318317081617273

Epoch 3037/4500: Training Loss: 0.14179871618967654		 Val Loss: 0.1952281620191491
             	Training MAE: 0.06098027154803276		 Val MAE: 0.06327517330646515
             	Algebraic dist: 0.2558131481888549		 Val Algebraic dist: 0.299374476723049
             	RE1 dist: 0.06747183148711369		 Val RE1 dist: 0.1046589353810186
             	SED dist: 0.2509702281318468		 Val SED dist: 0.3568754196166992

Epoch 3038/4500: Training Loss: 0.16806421596625634		 Val Loss: 0.24348300436268683
             	Training MAE: 0.061670225113630295		 Val MAE: 0.060458842664957047
             	Algebraic dist: 0.28063556628913455		 Val Algebraic dist: 0.33919738686603046
             	RE1 dist: 0.07956812390542119		 Val RE1 dist: 0.1277393154476
             	SED dist: 0.3031738112333516		 Val SED dist: 0.45472074591595196

Epoch 3039/4500: Training Loss: 0.19010560714890595		 Val Loss: 0.2986424902211065
             	Training MAE: 0.06256145238876343		 Val MAE: 0.06013888865709305
             	Algebraic dist: 0.30379973126513493		 Val Algebraic dist: 0.4277845050977624
             	RE1 dist: 0.09078106053201035		 Val RE1 dist: 0.16707172601119333
             	SED dist: 0.34687025344679717		 Val SED dist: 0.5651738125344982

Epoch 3040/4500: Training Loss: 0.23467168772792465		 Val Loss: 1.139356696087381
             	Training MAE: 0.06198898330330849		 Val MAE: 0.05939893051981926
             	Algebraic dist: 0.3381112580809646		 Val Algebraic dist: 0.951469670171323
             	RE1 dist: 0.11622309244866741		 Val RE1 dist: 0.7002147176991338
             	SED dist: 0.4362920500695485		 Val SED dist: 2.246915900188944

Epoch 3041/4500: Training Loss: 0.3331031377025196		 Val Loss: 0.23346753742383874
             	Training MAE: 0.06244179233908653		 Val MAE: 0.059876520186662674
             	Algebraic dist: 0.4119933293754324		 Val Algebraic dist: 0.33230188618535583
             	RE1 dist: 0.17646058986987576		 Val RE1 dist: 0.1373648332512897
             	SED dist: 0.6330690841393277		 Val SED dist: 0.4346853339153787

Epoch 3042/4500: Training Loss: 0.29181752785545434		 Val Loss: 0.3652602071347444
             	Training MAE: 0.062029141932725906		 Val MAE: 0.06171800568699837
             	Algebraic dist: 0.3761673818215233		 Val Algebraic dist: 0.41698207025942596
             	RE1 dist: 0.15590766259225092		 Val RE1 dist: 0.22350284327631412
             	SED dist: 0.5505930207312327		 Val SED dist: 0.697879293690557


################
Empty points at 02


Epoch 3043/4500: Training Loss: 0.22350753277430235		 Val Loss: 0.5443417922310207
             	Training MAE: 0.06168442592024803		 Val MAE: 0.06693785637617111
             	Algebraic dist: 0.3342686895954653		 Val Algebraic dist: 0.5908302224200704
             	RE1 dist: 0.11090087186806316		 Val RE1 dist: 0.30955335368280823
             	SED dist: 0.4140597973362546		 Val SED dist: 1.0536907030188518

Epoch 3044/4500: Training Loss: 0.22306239560961283		 Val Loss: 0.22827233438906464
             	Training MAE: 0.061429258435964584		 Val MAE: 0.0602463036775589
             	Algebraic dist: 0.3371194367919021		 Val Algebraic dist: 0.31325839913409687
             	RE1 dist: 0.1129958304092013		 Val RE1 dist: 0.12703138849009638
             	SED dist: 0.41336315760313364		 Val SED dist: 0.4242885009102199

Epoch 3045/4500: Training Loss: 0.18684297118239737		 Val Loss: 0.22711901042772376
             	Training MAE: 0.06151141598820686		 Val MAE: 0.05975966528058052
             	Algebraic dist: 0.299620934518061		 Val Algebraic dist: 0.33195555728414783
             	RE1 dist: 0.0917815035999481		 Val RE1 dist: 0.12303244549295177
             	SED dist: 0.3408838250980166		 Val SED dist: 0.4223091291344684

Epoch 3046/4500: Training Loss: 0.22995462452793472		 Val Loss: 0.37395634858504584
             	Training MAE: 0.06244127079844475		 Val MAE: 0.0697854608297348
             	Algebraic dist: 0.31948973595876096		 Val Algebraic dist: 0.4323512367580248
             	RE1 dist: 0.11206806365854186		 Val RE1 dist: 0.22668722401494565
             	SED dist: 0.4264542414253488		 Val SED dist: 0.7113124183986498

Epoch 3047/4500: Training Loss: 0.1899764001149533		 Val Loss: 0.3133940904036812
             	Training MAE: 0.06199302151799202		 Val MAE: 0.060820676386356354
             	Algebraic dist: 0.29997774243794684		 Val Algebraic dist: 0.38342961021091626
             	RE1 dist: 0.09418799340505002		 Val RE1 dist: 0.17095252741938052
             	SED dist: 0.346875827690772		 Val SED dist: 0.5944298868593962

