nohup: ignoring input
/home/aviran/miniconda3/envs/alon_env/lib/python3.9/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  torch.utils._pytree._register_pytree_node(
###########################################################################################################################################################

                         learning rate: 0.0001, lr_decay: 0.8, mlp_hidden_sizes: [1024, 512], jump_frames: 2, use_reconstruction_layer: True
                        batch_size: 4, norm: True, train_seqeunces: [0, 2, 3, 5], val_sequences: [6, 7, 8], dataset: Stereo,
                        average embeddings: False, model: openai/clip-vit-base-patch32, augmentation: True, random crop: True, deepF_nocorrs: False, part: tail, get_old_path: False,
                        SVD coeff: 0, RE1 coeff: 0 SED coeff: 0.5, ALG_COEFF: 0, L2_coeff: 1, huber_coeff: 1, frozen layers: 4,
                        crop: 224 resize: 256, use conv: True pretrained: None, data_ratio: 0.05, norm_mean: tensor([0.4815, 0.4578, 0.4082], device='cuda:0'), norm_std: tensor([0.2686, 0.2613, 0.2758], device='cuda:0'), sched: None seed: 42, 


algebraic_truth: 0.0167518345748677		 val_algebraic_truth: 0.0173861941565638
RE1_truth: 0.0001886974581900765		 val_RE1_truth: 0.00021129980197419292
SED_truth: 0.0015095785698469948		 val_SED_truth: 0.00169039161308952


Epoch 1/5500: Training Loss: 260.5921415441176		 Val Loss: 4.5941009521484375
             Training MAE: 0.36946526169776917		 Val MAE: 0.3668895363807678
             Algebraic dist: 334.91345932904414		 Val Algebraic dist: 48.64285941745924
             RE1 dist: 1436606.9411764706		 Val RE1 dist: 2168.0444972826085
             SED dist: 520.2316176470588		 Val SED dist: 8.275332243546195


Epoch 2/5500: Training Loss: 2.4237675386316635		 Val Loss: 6.054242341414742
             Training MAE: 0.3625330328941345		 Val MAE: 0.3593325614929199
             Algebraic dist: 29.90280330882353		 Val Algebraic dist: 54.80867336107337
             RE1 dist: 1118.7473575367646		 Val RE1 dist: 3662.054008152174
             SED dist: 3.96727393655216		 Val SED dist: 11.257839037024457


Epoch 3/5500: Training Loss: 2.358237995820887		 Val Loss: 4.650333238684612
             Training MAE: 0.357654869556427		 Val MAE: 0.3572889268398285
             Algebraic dist: 30.886783375459558		 Val Algebraic dist: 49.54703422214674
             RE1 dist: 1151.2286305147059		 Val RE1 dist: 2469.537703804348
             SED dist: 3.8822241390452668		 Val SED dist: 8.483847576638926


Epoch 4/5500: Training Loss: 2.3761699900907627		 Val Loss: 6.471746030061142
             Training MAE: 0.35578107833862305		 Val MAE: 0.35718414187431335
             Algebraic dist: 33.385659610523895		 Val Algebraic dist: 67.07526961616848
             RE1 dist: 1345.7452895220588		 Val RE1 dist: 5565.545516304348
             SED dist: 3.9521695305319393		 Val SED dist: 12.155882462211277


Epoch 5/5500: Training Loss: 2.216068716610179		 Val Loss: 8.77800120478091
             Training MAE: 0.353719025850296		 Val MAE: 0.3527131974697113
             Algebraic dist: 35.12491024241728		 Val Algebraic dist: 86.57902725883152
             RE1 dist: 1508.6634880514705		 Val RE1 dist: 9192.985054347826
             SED dist: 3.671961616067325		 Val SED dist: 16.814717168393344


Epoch 6/5500: Training Loss: 2.5658030790441178		 Val Loss: 8.351504781971807
             Training MAE: 0.34847453236579895		 Val MAE: 0.3377111256122589
             Algebraic dist: 42.235890107996326		 Val Algebraic dist: 86.55012843919837
             RE1 dist: 2222.3982077205883		 Val RE1 dist: 9212.103260869566
             SED dist: 4.4196772855870865		 Val SED dist: 16.03542294709579


Epoch 7/5500: Training Loss: 2.242106493781595		 Val Loss: 5.347584600033968
             Training MAE: 0.3409886360168457		 Val MAE: 0.3375012278556824
             Algebraic dist: 41.33627857881434		 Val Algebraic dist: 71.4503757642663
             RE1 dist: 2039.5983455882354		 Val RE1 dist: 5867.820652173913
             SED dist: 3.8214335722081803		 Val SED dist: 10.057286138119904


Epoch 8/5500: Training Loss: 2.3318261539234832		 Val Loss: 5.47137451171875
             Training MAE: 0.3380865156650543		 Val MAE: 0.32525962591171265
             Algebraic dist: 47.09699922449448		 Val Algebraic dist: 77.22061289911684
             RE1 dist: 2614.7028952205883		 Val RE1 dist: 6590.349184782609
             SED dist: 4.036245458266315		 Val SED dist: 10.362781027088994


Epoch 9/5500: Training Loss: 2.3431777954101562		 Val Loss: 5.4058064999787705
             Training MAE: 0.32000333070755005		 Val MAE: 0.30996406078338623
             Algebraic dist: 50.07248104319853		 Val Algebraic dist: 87.43557871942934
             RE1 dist: 3010.44140625		 Val RE1 dist: 9231.578125
             SED dist: 4.138347850126379		 Val SED dist: 10.304465252420176


Epoch 10/5500: Training Loss: 2.186069039737477		 Val Loss: 5.521325484566066
             Training MAE: 0.30357688665390015		 Val MAE: 0.2910364270210266
             Algebraic dist: 52.1265869140625		 Val Algebraic dist: 85.75868291440217
             RE1 dist: 3365.7810202205883		 Val RE1 dist: 8874.025815217392
             SED dist: 3.8900640151079964		 Val SED dist: 10.596738068953805


Epoch 11/5500: Training Loss: 2.174602508544922		 Val Loss: 5.103287406589674
             Training MAE: 0.2843680679798126		 Val MAE: 0.2740573585033417
             Algebraic dist: 52.32226921530331		 Val Algebraic dist: 87.69750445822011
             RE1 dist: 3236.8853400735293		 Val RE1 dist: 8694.37160326087
             SED dist: 3.9231293622185204		 Val SED dist: 9.812176911727242


Epoch 12/5500: Training Loss: 2.0424741857192097		 Val Loss: 5.229037409243376
             Training MAE: 0.2679731547832489		 Val MAE: 0.26902568340301514
             Algebraic dist: 52.97853357651655		 Val Algebraic dist: 97.98765497622283
             RE1 dist: 3357.567325367647		 Val RE1 dist: 11879.422554347826
             SED dist: 3.706180123721852		 Val SED dist: 10.087588766346807


Epoch 13/5500: Training Loss: 2.061835569493911		 Val Loss: 5.7152232294497285
             Training MAE: 0.26609769463539124		 Val MAE: 0.24844267964363098
             Algebraic dist: 57.37161075367647		 Val Algebraic dist: 95.50277046535327
             RE1 dist: 4016.8570772058824		 Val RE1 dist: 11439.408967391304
             SED dist: 3.7617490431841683		 Val SED dist: 11.09913502568784


Epoch 14/5500: Training Loss: 2.2385009316837086		 Val Loss: 4.123163306194803
             Training MAE: 0.2498256415128708		 Val MAE: 0.26299431920051575
             Algebraic dist: 57.53563017003677		 Val Algebraic dist: 90.84375
             RE1 dist: 3844.651424632353		 Val RE1 dist: 8487.077445652174
             SED dist: 4.147223079905791		 Val SED dist: 7.903740924337636


Epoch 15/5500: Training Loss: 2.1358546088723576		 Val Loss: 4.525404225225034
             Training MAE: 0.25069549679756165		 Val MAE: 0.2384142130613327
             Algebraic dist: 57.64781278722427		 Val Algebraic dist: 84.24141792629077
             RE1 dist: 3905.563419117647		 Val RE1 dist: 8505.185461956522
             SED dist: 3.9478153901941635		 Val SED dist: 8.749182659646738


Epoch 16/5500: Training Loss: 2.022347842945772		 Val Loss: 4.092057932978091
             Training MAE: 0.23575656116008759		 Val MAE: 0.2354152947664261
             Algebraic dist: 55.585991354549634		 Val Algebraic dist: 84.7296832540761
             RE1 dist: 3700.885799632353		 Val RE1 dist: 7993.700407608696
             SED dist: 3.752286798813764		 Val SED dist: 7.896822058636209


Epoch 17/5500: Training Loss: 2.3347771588493798		 Val Loss: 4.361674764881963
             Training MAE: 0.23204770684242249		 Val MAE: 0.24739935994148254
             Algebraic dist: 59.04885684742647		 Val Algebraic dist: 96.83592688519022
             RE1 dist: 4256.68106617647		 Val RE1 dist: 9114.445652173914
             SED dist: 4.386366451487822		 Val SED dist: 8.426079791525137


Fatal Python error: Illegal instruction

Thread 0x0000738c5f000640 (most recent call first):
<no Python frame>

Current thread 0x0000738d95f89740 (most recent call first):
  File "/home/aviran/miniconda3/envs/alon_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541 in _call_impl
  File "/home/aviran/miniconda3/envs/alon_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532 in _wrapped_call_impl
  File "/home/aviran/miniconda3/envs/alon_env/lib/python3.9/site-packages/transformers/models/clip/modeling_clip.py", line 395 in forward
  File "/home/aviran/miniconda3/envs/alon_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541 in _call_impl
  File "/home/aviran/miniconda3/envs/alon_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532 in _wrapped_call_impl
  File "/home/aviran/miniconda3/envs/alon_env/lib/python3.9/site-packages/transformers/models/clip/modeling_clip.py", line 656 in forward
  File "/home/aviran/miniconda3/envs/alon_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541 in _call_impl
  File "/home/aviran/miniconda3/envs/alon_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532 in _wrapped_call_impl
  File "/home/aviran/miniconda3/envs/alon_env/lib/python3.9/site-packages/transformers/models/clip/modeling_clip.py", line 886 in forward
  File "/home/aviran/miniconda3/envs/alon_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541 in _call_impl
  File "/home/aviran/miniconda3/envs/alon_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532 in _wrapped_call_impl
  File "/home/aviran/miniconda3/envs/alon_env/lib/python3.9/site-packages/transformers/models/clip/modeling_clip.py", line 958 in forward
  File "/home/aviran/miniconda3/envs/alon_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541 in _call_impl
  File "/home/aviran/miniconda3/envs/alon_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532 in _wrapped_call_impl
  File "/home/aviran/Alon/Thesis/FMatrixRegressor.py", line 143 in FeatureExtractor
  File "/home/aviran/Alon/Thesis/FMatrixRegressor.py", line 171 in forward
  File "/home/aviran/Alon/Thesis/FMatrixRegressor.py", line 389 in dataloader_step
  File "/home/aviran/Alon/Thesis/FMatrixRegressor.py", line 195 in train_model
  File "/home/aviran/Alon/Thesis/Main.py", line 88 in <module>
