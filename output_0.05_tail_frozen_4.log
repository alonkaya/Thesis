nohup: ignoring input
/home/alonkay/conda/alon/lib/python3.9/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/home/alonkay/conda/alon/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/alonkay/conda/alon/lib/python3.9/site-packages/transformers/modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location=map_location)
/home/alonkay/Thesis/FMatrixRegressor.py:306: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(model_path, map_location='cpu')
QObject::moveToThread: Current thread (0x329383f0) is not the object's thread (0x2d318f90).
Cannot move to target thread (0x329383f0)

qt.qpa.plugin: Could not load the Qt platform plugin "xcb" in "/home/alonkay/conda/alon/lib/python3.9/site-packages/cv2/qt/plugins" even though it was found.
This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.

Available platform plugins are: xcb, eglfs, minimal, minimalegl, offscreen, vnc, webgl.

Fatal Python error: Aborted

Thread 0x00007adc790006c0 (most recent call first):
<no Python frame>

Thread 0x00007adc70a006c0 (most recent call first):
<no Python frame>

Thread 0x00007adc74a006c0 (most recent call first):
<no Python frame>

Thread 0x00007adc7cc006c0 (most recent call first):
<no Python frame>

Current thread 0x00007ade1fb6f580 (most recent call first):
  File "/home/alonkay/conda/alon/lib/python3.9/site-packages/matplotlib/backends/backend_qt.py", line 137 in _create_qApp
  File "/home/alonkay/conda/alon/lib/python3.9/site-packages/matplotlib/backends/backend_qt.py", line 227 in __init__
  File "/home/alonkay/conda/alon/lib/python3.9/site-packages/matplotlib/backend_bases.py", line 2681 in create_with_canvas
  File "/home/alonkay/conda/alon/lib/python3.9/site-packages/matplotlib/backend_bases.py", line 1797 in new_manager
  File "/home/alonkay/conda/alon/lib/python3.9/site-packages/matplotlib/backend_bases.py", line 3512 in new_figure_manager_given_figure
  File "/home/alonkay/conda/alon/lib/python3.9/site-packages/matplotlib/backend_bases.py", line 3507 in new_figure_manager
  File "/home/alonkay/conda/alon/lib/python3.9/site-packages/matplotlib/pyplot.py", line 550 in new_figure_manager
  File "/home/alonkay/conda/alon/lib/python3.9/site-packages/matplotlib/pyplot.py", line 1027 in figure
  File "/home/alonkay/conda/alon/lib/python3.9/site-packages/matplotlib/pyplot.py", line 1759 in subplots
  File "/home/alonkay/Thesis/utils.py", line 78 in plot
  File "/home/alonkay/Thesis/FMatrixRegressor.py", line 415 in plot_all
  File "/home/alonkay/Thesis/FMatrixRegressor.py", line 234 in train_model
  File "/home/alonkay/Thesis/Main.py", line 90 in <module>
640831988791


Epoch 6/5500: Training Loss: 2.4538872612847222		 Val Loss: 9.290930043096127
             Training MAE: 0.27095404267311096		 Val MAE: 0.2740449905395508
             Algebraic dist: 33.293352141203705		 Val Algebraic dist: 79.22501273777173
             RE1 dist: 1385.843287037037		 Val RE1 dist: 8029.582880434783
             SED dist: 4.441908094618055		 Val SED dist: 18.109701405400816


Epoch 7/5500: Training Loss: 2.403944001374421		 Val Loss: 6.22331834876019
             Training MAE: 0.2626986503601074		 Val MAE: 0.2566465735435486
             Algebraic dist: 30.97289134837963		 Val Algebraic dist: 60.63100798233695
             RE1 dist: 1252.292476851852		 Val RE1 dist: 4593.216711956522
             SED dist: 4.354629177517361		 Val SED dist: 12.015586521314537


Epoch 8/5500: Training Loss: 2.277535671657986		 Val Loss: 11.387999161430027
             Training MAE: 0.25888311862945557		 Val MAE: 0.25346341729164124
             Algebraic dist: 31.790147569444443		 Val Algebraic dist: 82.49068550441577
             RE1 dist: 1259.5628472222222		 Val RE1 dist: 8372.807065217392
             SED dist: 4.112238226996528		 Val SED dist: 22.341029954993207


Epoch 9/5500: Training Loss: 2.2256655092592594		 Val Loss: 4.441804637079653
             Training MAE: 0.2596259117126465		 Val MAE: 0.21329331398010254
             Algebraic dist: 31.63511284722222		 Val Algebraic dist: 46.12271250849185
             RE1 dist: 1260.306712962963		 Val RE1 dist: 2425.6469089673915
             SED dist: 4.00390941478588		 Val SED dist: 8.565689086914062


Epoch 10/5500: Training Loss: 2.4851268627025465		 Val Loss: 6.7950572138247285
             Training MAE: 0.24975702166557312		 Val MAE: 0.25891873240470886
             Algebraic dist: 31.112782118055556		 Val Algebraic dist: 70.2741115404212
             RE1 dist: 1159.1082175925926		 Val RE1 dist: 6632.874320652174
             SED dist: 4.538587782118055		 Val SED dist: 13.149903670601223


Epoch 11/5500: Training Loss: 2.0617888274016205		 Val Loss: 5.186119079589844
             Training MAE: 0.2550618350505829		 Val MAE: 0.24608710408210754
             Algebraic dist: 30.192100694444445		 Val Algebraic dist: 60.60660984205163
             RE1 dist: 1188.7255787037036		 Val RE1 dist: 3429.133831521739
             SED dist: 3.6786718297887733		 Val SED dist: 9.964297087296195


Epoch 12/5500: Training Loss: 2.2283623589409722		 Val Loss: 4.822170091711956
             Training MAE: 0.25529664754867554		 Val MAE: 0.2212323695421219
             Algebraic dist: 32.47119502314815		 Val Algebraic dist: 52.86380668308424
             RE1 dist: 1296.4454861111112		 Val RE1 dist: 2718.415760869565
             SED dist: 4.0100278501157405		 Val SED dist: 9.296790081521738


Epoch 13/5500: Training Loss: 2.5678077980324074		 Val Loss: 4.777217367421025
             Training MAE: 0.24225175380706787		 Val MAE: 0.2028762549161911
             Algebraic dist: 33.162348090277774		 Val Algebraic dist: 44.126839015794836
             RE1 dist: 1371.2589120370371		 Val RE1 dist: 1984.4006453804348
             SED dist: 4.715728081597222		 Val SED dist: 9.246105028235394


Epoch 14/5500: Training Loss: 2.982115794994213		 Val Loss: 5.150774748429008
             Training MAE: 0.2398487776517868		 Val MAE: 0.24675846099853516
             Algebraic dist: 35.67390046296296		 Val Algebraic dist: 65.14293902853261
             RE1 dist: 1572.0861111111112		 Val RE1 dist: 5208.55910326087
             SED dist: 5.548246708622685		 Val SED dist: 9.891933275305707


Epoch 15/5500: Training Loss: 1.8491649486400463		 Val Loss: 11.319990075152853
             Training MAE: 0.2513291537761688		 Val MAE: 0.222284734249115
             Algebraic dist: 31.085944733796296		 Val Algebraic dist: 85.46651558254077
             RE1 dist: 1232.7471064814815		 Val RE1 dist: 8925.761548913044
             SED dist: 3.2670991120515045		 Val SED dist: 22.270688264266305


Epoch 16/5500: Training Loss: 2.4563053837528934		 Val Loss: 6.573551343834919
             Training MAE: 0.2441285401582718		 Val MAE: 0.22283601760864258
             Algebraic dist: 33.56104962384259		 Val Algebraic dist: 61.84537406589674
             RE1 dist: 1443.3819444444443		 Val RE1 dist: 5278.450067934783
             SED dist: 4.492745406539352		 Val SED dist: 12.786268151324728


Epoch 17/5500: Training Loss: 2.1588356300636575		 Val Loss: 5.229289179262907
             Training MAE: 0.24547141790390015		 Val MAE: 0.26430442929267883
             Algebraic dist: 31.935300925925926		 Val Algebraic dist: 54.70384680706522
             RE1 dist: 1338.0509259259259		 Val RE1 dist: 3545.6290760869565
             SED dist: 3.9018604419849536		 Val SED dist: 9.998382568359375


Epoch 18/5500: Training Loss: 1.99246826171875		 Val Loss: 6.930167156717052
             Training MAE: 0.24786633253097534		 Val MAE: 0.2307375967502594
             Algebraic dist: 31.094299768518518		 Val Algebraic dist: 63.613955290421195
             RE1 dist: 1202.4251157407407		 Val RE1 dist: 5518.536345108696
             SED dist: 3.5669083206741896		 Val SED dist: 13.487258247707201


Epoch 19/5500: Training Loss: 1.93162841796875		 Val Loss: 5.126598192297894
             Training MAE: 0.24139048159122467		 Val MAE: 0.2218664139509201
             Algebraic dist: 26.671580222800927		 Val Algebraic dist: 62.158500339673914
             RE1 dist: 943.8363425925926		 Val RE1 dist: 4303.301970108696
             SED dist: 3.455126727068866		 Val SED dist: 9.9187535824983


Epoch 20/5500: Training Loss: 1.9195418746383102		 Val Loss: 8.831489231275475
             Training MAE: 0.24567803740501404		 Val MAE: 0.21977581083774567
             Algebraic dist: 30.54763454861111		 Val Algebraic dist: 76.8523586107337
             RE1 dist: 1227.6090277777778		 Val RE1 dist: 7724.679347826087
             SED dist: 3.4377384892216436		 Val SED dist: 17.32531207540761


Epoch 21/5500: Training Loss: 2.7213374385127316		 Val Loss: 5.218310812245244
             Training MAE: 0.24171577394008636		 Val MAE: 0.22308488190174103
             Algebraic dist: 35.44379701967593		 Val Algebraic dist: 55.65572987432065
             RE1 dist: 1658.3905092592593		 Val RE1 dist: 3778.7989130434785
             SED dist: 5.046151168258102		 Val SED dist: 10.091218367866848


Epoch 22/5500: Training Loss: 2.135639331958912		 Val Loss: 4.61931212052055
             Training MAE: 0.24447228014469147		 Val MAE: 0.26284533739089966
             Algebraic dist: 31.836179832175926		 Val Algebraic dist: 63.52177628226902
             RE1 dist: 1331.1820601851853		 Val RE1 dist: 4045.952105978261
             SED dist: 3.8746970847800926		 Val SED dist: 8.820977915888248


Epoch 23/5500: Training Loss: 2.0660621925636575		 Val Loss: 6.390207705290421
             Training MAE: 0.24317128956317902		 Val MAE: 0.22461596131324768
             Algebraic dist: 29.105521195023147		 Val Algebraic dist: 54.424491550611414
             RE1 dist: 1047.384375		 Val RE1 dist: 3947.8087635869565
             SED dist: 3.736669921875		 Val SED dist: 12.427461043648098


Epoch 24/5500: Training Loss: 2.3947844328703702		 Val Loss: 7.177155867866848
             Training MAE: 0.24130494892597198		 Val MAE: 0.2158808559179306
             Algebraic dist: 31.82880859375		 Val Algebraic dist: 58.30227793817935
             RE1 dist: 1259.5835648148147		 Val RE1 dist: 4586.735394021739
             SED dist: 4.403736255787037		 Val SED dist: 14.027339769446332


Epoch 25/5500: Training Loss: 2.8482842339409724		 Val Loss: 5.949060854704483
             Training MAE: 0.2461490035057068		 Val MAE: 0.22231687605381012
             Algebraic dist: 37.83207465277778		 Val Algebraic dist: 72.48435907778533
             RE1 dist: 1960.933101851852		 Val RE1 dist: 6532.002038043478
             SED dist: 5.30762939453125		 Val SED dist: 11.591780952785326


Epoch 26/5500: Training Loss: 2.308467384620949		 Val Loss: 5.136067597762398
             Training MAE: 0.24742300808429718		 Val MAE: 0.2245626151561737
             Algebraic dist: 32.76739366319445		 Val Algebraic dist: 54.15764054008152
             RE1 dist: 1372.0974537037036		 Val RE1 dist: 2745.1557404891305
             SED dist: 4.229001193576389		 Val SED dist: 9.936995133109715


Epoch 27/5500: Training Loss: 1.7906177662037037		 Val Loss: 6.576896335767663
             Training MAE: 0.24627353250980377		 Val MAE: 0.23533932864665985
             Algebraic dist: 27.849593098958334		 Val Algebraic dist: 64.8346637228261
             RE1 dist: 1013.7251157407408		 Val RE1 dist: 5588.145380434783
             SED dist: 3.1968630190248843		 Val SED dist: 12.803425664487092


Epoch 28/5500: Training Loss: 1.6256842719184028		 Val Loss: 6.950202610181726
             Training MAE: 0.24984419345855713		 Val MAE: 0.2530656158924103
             Algebraic dist: 28.77187861689815		 Val Algebraic dist: 62.815854279891305
             RE1 dist: 1148.1574074074074		 Val RE1 dist: 5248.938858695652
             SED dist: 2.8688340928819445		 Val SED dist: 13.507369331691576


Epoch 29/5500: Training Loss: 1.7946906195746528		 Val Loss: 6.604762865149456
             Training MAE: 0.24720168113708496		 Val MAE: 0.24190784990787506
             Algebraic dist: 26.312693504050927		 Val Algebraic dist: 57.70994501528533
             RE1 dist: 948.3622106481481		 Val RE1 dist: 4553.514266304348
             SED dist: 3.20247960973669		 Val SED dist: 12.842583697775137


Epoch 30/5500: Training Loss: 1.7581704598885994		 Val Loss: 5.813633794369905
             Training MAE: 0.25320005416870117		 Val MAE: 0.23704618215560913
             Algebraic dist: 27.395328776041666		 Val Algebraic dist: 61.556704313858695
             RE1 dist: 976.3537037037037		 Val RE1 dist: 5169.205842391304
             SED dist: 3.1218092176649304		 Val SED dist: 11.28294040845788


Epoch 31/5500: Training Loss: 1.7060692681206597		 Val Loss: 6.659598309060802
             Training MAE: 0.24995192885398865		 Val MAE: 0.25238463282585144
             Algebraic dist: 27.711281105324073		 Val Algebraic dist: 70.72153108016305
             RE1 dist: 1100.6082175925926		 Val RE1 dist: 6713.257472826087
             SED dist: 3.028246166087963		 Val SED dist: 12.94915240743886


Epoch 32/5500: Training Loss: 1.6730414496527777		 Val Loss: 6.36083519977072
             Training MAE: 0.248896062374115		 Val MAE: 0.23920942842960358
             Algebraic dist: 26.37067238136574		 Val Algebraic dist: 62.48366380774456
             RE1 dist: 935.7215277777777		 Val RE1 dist: 5337.072690217391
             SED dist: 2.965368878399884		 Val SED dist: 12.37573772927989


Epoch 33/5500: Training Loss: 1.8894800256799769		 Val Loss: 11.676614512567935
             Training MAE: 0.2515588700771332		 Val MAE: 0.24996772408485413
             Algebraic dist: 27.602293113425926		 Val Algebraic dist: 69.15234905740489
             RE1 dist: 1040.9166666666667		 Val RE1 dist: 5665.297554347826
             SED dist: 3.391705322265625		 Val SED dist: 22.95963718580163


Epoch 34/5500: Training Loss: 1.8247546160662615		 Val Loss: 7.513939898947011
             Training MAE: 0.24944058060646057		 Val MAE: 0.24156029522418976
             Algebraic dist: 27.10526439525463		 Val Algebraic dist: 53.66145656419837
             RE1 dist: 954.6035879629629		 Val RE1 dist: 3692.991508152174
             SED dist: 3.2698673954716435		 Val SED dist: 14.661230999490488


Epoch 35/5500: Training Loss: 1.5361928304036458		 Val Loss: 5.967480203379756
             Training MAE: 0.25182992219924927		 Val MAE: 0.2624412775039673
             Algebraic dist: 24.61469184027778		 Val Algebraic dist: 65.0643310546875
             RE1 dist: 802.9446759259259		 Val RE1 dist: 5440.161005434783
             SED dist: 2.689273636429398		 Val SED dist: 11.542732570482338


Epoch 36/5500: Training Loss: 1.660155345775463		 Val Loss: 7.438946267832881
             Training MAE: 0.25046005845069885		 Val MAE: 0.2536635994911194
             Algebraic dist: 25.974571397569445		 Val Algebraic dist: 74.44787066915761
             RE1 dist: 884.389525462963		 Val RE1 dist: 7565.98097826087
             SED dist: 2.9439982096354167		 Val SED dist: 14.514318051545516


Epoch 37/5500: Training Loss: 1.776152773256655		 Val Loss: 7.665335613748302
             Training MAE: 0.2519453763961792		 Val MAE: 0.23029953241348267
             Algebraic dist: 28.29504304108796		 Val Algebraic dist: 68.51701554008152
             RE1 dist: 1036.7108796296295		 Val RE1 dist: 6593.098505434783
             SED dist: 3.1748571325231483		 Val SED dist: 15.018360967221467


