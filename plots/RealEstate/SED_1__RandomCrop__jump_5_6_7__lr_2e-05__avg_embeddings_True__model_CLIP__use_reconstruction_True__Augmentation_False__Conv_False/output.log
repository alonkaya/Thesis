###########################################################################################################################################################

RandomCrop__jump_5_6_7__learning rate vit: 2e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, use_reconstruction_layer: True
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], RealEstate: True, batchnorm & dropout: False, 
average embeddings: True, model: openai/clip-vit-base-patch32, augmentation: False, 
predict pose: False, SVD coeff: 0, RE1 coeff: 0 SED coeff: 1, ALG_COEFF: 0, unforzen layers: 0, group conv: False
Dataset: 

algebraic_truth: 0.005921595877403986       RE1_truth: 0.01562725066783453        SED_truth: 0.06288100510005878
val_algebraic_truth: 0.0028065450964470046   val_RE1_truth: 0.013149077975288423    val_SED_truth: 0.05264691594153305

Epoch 1/60: Training Loss: 27.728783522674366   Val Loss: 23.950048274344937
            Training MAE: 0.3726823031902313   Val MAE: 0.36683419346809387
            Algebraic dist: 148452.6574168917  Val Algebraic dist: 168727.65271802893
            RE1 dist: 6.1314033545954          Val RE1 dist: 5.927366970570982
            SED dist: 27.502752816835834        Val SED dist: 23.731411321861557

