learning rate vit: 2e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, use_reconstruction_layer: True
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], RealEstate: True, batchnorm & dropout: False, 
average embeddings: True, customdataset type: CustomDataset_first_two_thirds_train, model: openai/clip-vit-base-patch32, augmentation: False, 
enforce_rank_2:False, predict pose: False, SVD coeff: 0, RE1 coeff: 0 SED coeff: 0.01, ALG_COEFF: 0, unforzen layers: 0, group conv: {'use': False, 'out_channels': 256, 'num_groups': 256}

learning rate vit: 2e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, use_reconstruction_layer: True
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], RealEstate: True, batchnorm & dropout: False, 
average embeddings: True, customdataset type: CustomDataset_first_two_thirds_train, model: openai/clip-vit-base-patch32, augmentation: False, 
enforce_rank_2:False, predict pose: False, SVD coeff: 0, RE1 coeff: 0 SED coeff: 0.01, ALG_COEFF: 0, unforzen layers: 0, group conv: {'use': False, 'out_channels': 256, 'num_groups': 256}

learning rate vit: 2e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, use_reconstruction_layer: True
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], RealEstate: True, batchnorm & dropout: False, 
average embeddings: True, customdataset type: CustomDataset_first_two_thirds_train, model: openai/clip-vit-base-patch32, augmentation: False, 
enforce_rank_2:False, predict pose: False, SVD coeff: 0, RE1 coeff: 0 SED coeff: 0.01, ALG_COEFF: 0, unforzen layers: 0, group conv: {'use': False, 'out_channels': 256, 'num_groups': 256}

RE1_truth: 0.08155534551007107, SED_truth: 0.33516242745689356, algebraic_truth: 0.041786256865782884
val_RE1_truth: 0.13056560315583882, val_SED_truth: 0.5419180458470395, val_algebraic_truth: 0.029041044000993697
Epoch 1/100:  Training Loss: 0.25489465990780735 Val Loss: 0.2821706885622259 last sv: 0.0
            Training MAE: 0.270875483751297 Val MAE: 0.29134050011634827
            algebraic dist: 182.71959319933922 val algebraic dist: 134.46247807017545
            RE1 dist: 11.178173182819384 val RE1 dist: 9.756493969298246
            SED dist: 67.40269221503304 val SED dist: 39.1370038377193

Epoch 2/100:  Training Loss: 0.1585353733684523 Val Loss: 0.2738157680578399 last sv: 0.0
            Training MAE: 0.2361346036195755 Val MAE: 0.28123724460601807
            algebraic dist: 68.0926400743392 val algebraic dist: 118.31612938596491
            RE1 dist: 3.6973226269961454 val RE1 dist: 9.475431743421053
            SED dist: 14.832386168089206 val SED dist: 38.04578125

Epoch 3/100:  Training Loss: 0.1047310261999458 Val Loss: 0.22449936180783991 last sv: 0.0
            Training MAE: 0.17514309287071228 Val MAE: 0.24900439381599426
            algebraic dist: 39.53430444658591 val algebraic dist: 62.0528125
            RE1 dist: 2.889046152257709 val RE1 dist: 6.293315515350877
            SED dist: 11.590023360063325 val SED dist: 25.269945175438597

Epoch 4/100:  Training Loss: 0.06423170030904761 Val Loss: 0.23235210217927632 last sv: 0.0
            Training MAE: 0.12267699092626572 Val MAE: 0.2452770322561264
            algebraic dist: 20.289832564702643 val algebraic dist: 67.8209923245614
            RE1 dist: 2.135816263207255 val RE1 dist: 7.561100603070176
            SED dist: 8.57341588226184 val SED dist: 30.367097039473684

Epoch 5/100:  Training Loss: 0.05638261198472346 Val Loss: 0.24985916940789474 last sv: 0.0
            Training MAE: 0.111831434071064 Val MAE: 0.23834629356861115
            algebraic dist: 15.558423819520925 val algebraic dist: 49.88134868421053
            RE1 dist: 1.8155902072721641 val RE1 dist: 8.802875548245614
            SED dist: 7.291742669328194 val SED dist: 35.35148848684211

