learning rate vit: 2e-05, learning rate mlp: 2e-05, mlp_hidden_sizes: [512, 256], jump_frames: 6, use_reconstruction_layer: True
batch_size: 1, train_seqeunces: [0, 2], val_sequences: [1, 3, 4], RealEstate: True, batchnorm & dropout: False, 
average embeddings: True, customdataset type: CustomDataset_first_two_thirds_train, model: openai/clip-vit-base-patch32, augmentation: False, 
enforce_rank_2:False, predict pose: False, SVD coeff: 0, RE1 coeff: 0.01 SED coeff: 0, ALG_COEFF: 0, unforzen layers: 0, group conv: {'use': False, 'out_channels': 256, 'num_groups': 256}

