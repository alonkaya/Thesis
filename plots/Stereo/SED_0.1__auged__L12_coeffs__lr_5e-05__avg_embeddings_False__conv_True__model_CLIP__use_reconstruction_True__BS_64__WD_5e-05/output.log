###########################################################################################################################################################

        auged__L12_coeffs__learning rate vit: 5e-05, learning rate mlp: 5e-05, lr_decay: 0.85, mlp_hidden_sizes: [1024, 512], jump_frames: 2, use_reconstruction_layer: True
        batch_size: 64, norm: True, train_seqeunces: [0, 2, 3, 5], val_sequences: [6, 7, 8], dataset: Stereo,
        average embeddings: False, model: openai/clip-vit-base-patch32, augmentation: True, random crop: True, deepF_nocorrs: False, wieght_decay: 5e-05
        SVD coeff: 0, RE1 coeff: 0 SED coeff: 0.1, ALG_COEFF: 0, unforzen layers: 0, group conv: False
        crop: 224 resize: 256, use conv: True pretrained: None, seq_ratio: 0.3, norm_mean: tensor([0.4815, 0.4578, 0.4082], device='cuda:0'), norm_std: tensor([0.2686, 0.2613, 0.2758], device='cuda:0')

