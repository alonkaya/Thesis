Thu 19 Dec 2024 17:06:38 IST

SLURM_JOBID:		 1979267
SLURM_JOB_NODELIST:	 cs-4090-09 


/home/alonkay/.conda/envs/alon_env/lib/python3.9/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/home/alonkay/.conda/envs/alon_env/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/alonkay/.conda/envs/alon_env/lib/python3.9/site-packages/transformers/modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location=map_location)
/cs_storage/alonkay/Thesis/FMatrixRegressor.py:343: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(model_path, map_location='cpu')

###########################################################################################################################################################

 learning rate: 0.0001, mlp_hidden_sizes: [1024, 512], jump_frames: 6, use_reconstruction_layer: True
batch_size: 8, norm: True, train_seqeunces: [0, 2, 3, 5], val_sequences: [6, 7, 8], RL_TEST_NAMES: ['fe2fadf89a84e92a', 'f01e8b6f8e10fdd9', 'f1ee9dc6135e5307', 'a41df4fa06fd391b', 'bc0ebb7482f14795', '9bdd34e784c04e3a', '98ebee1c36ecec55'], dataset: Flying,
average embeddings: False, model: openai/clip-vit-base-patch32, augmentation: True, random crop: True, part: head, get_old_path: False, computer: 1,
RE1 coeff: 0 SED coeff: 0.5, ALG_COEFF: 0, L2_coeff: 1, huber_coeff: 1, frozen layers: 6, trained vit: None,
crop: 224 resize: 256, use conv: True pretrained: None, train_size: 150, norm_mean: tensor([0.4815, 0.4578, 0.4082], device='cuda:0'), norm_std: tensor([0.2686, 0.2613, 0.2758], device='cuda:0'), sched: None seed: 42

train size: 1472, val size: 361, test size: 968

##### CONTINUE TRAINING #####

Epoch 8081/8000: Training Loss: 0.23012223451033884		 Val Loss: 0.9368399744448455
             	Training MAE: 0.05664292722940445		 Val MAE: 0.04521723464131355
             	Algebraic dist: 0.2759721175484035		 Val Algebraic dist: 0.4136837669040846
             	RE1 dist: 0.0761025159255318		 Val RE1 dist: 0.3590237161387568
             	SED dist: 0.41836377848749573		 Val SED dist: 1.8497375819994055

Epoch 8082/8000: Training Loss: 0.2574013005132261		 Val Loss: 0.9942150115966797
             	Training MAE: 0.05866685509681702		 Val MAE: 0.04356632009148598
             	Algebraic dist: 0.2945492578589398		 Val Algebraic dist: 0.5066912692526112
             	RE1 dist: 0.08481880892877994		 Val RE1 dist: 0.3837681645932405
             	SED dist: 0.4689860136612602		 Val SED dist: 1.9682207522184954

Epoch 8083/8000: Training Loss: 0.30010293877643085		 Val Loss: 1.0966970194940981
             	Training MAE: 0.060134150087833405		 Val MAE: 0.03886561095714569
             	Algebraic dist: 0.3280223141545835		 Val Algebraic dist: 0.5244845514712126
             	RE1 dist: 0.10424714503080948		 Val RE1 dist: 0.4319781013157057
             	SED dist: 0.5541744232177734		 Val SED dist: 2.1799706168796704

Epoch 8084/8000: Training Loss: 0.39724702420442		 Val Loss: 1.848950593367867
             	Training MAE: 0.05875629931688309		 Val MAE: 0.043559443205595016
             	Algebraic dist: 0.37626876001772674		 Val Algebraic dist: 0.7017867876135785
             	RE1 dist: 0.14481828523718793		 Val RE1 dist: 0.8058666560960852
             	SED dist: 0.7514095306396484		 Val SED dist: 3.677984154742697

Epoch 8085/8000: Training Loss: 0.41176509857177734		 Val Loss: 1.0976089809251868
             	Training MAE: 0.05962945148348808		 Val MAE: 0.04047253355383873
             	Algebraic dist: 0.393821384595788		 Val Algebraic dist: 0.5216896637626316
             	RE1 dist: 0.15474055124365765		 Val RE1 dist: 0.4517795728600543
             	SED dist: 0.7783991772195568		 Val SED dist: 2.1806962386421533

Epoch 8086/8000: Training Loss: 0.3471992534139882		 Val Loss: 1.7241592407226562
             	Training MAE: 0.05915867164731026		 Val MAE: 0.06638830155134201
             	Algebraic dist: 0.353931012360946		 Val Algebraic dist: 0.7687927743662959
             	RE1 dist: 0.12807804605235223		 Val RE1 dist: 0.6911274453868037
             	SED dist: 0.6517632525900136		 Val SED dist: 3.409336587657099

Epoch 8087/8000: Training Loss: 0.29765925200089166		 Val Loss: 1.6029104149859885
             	Training MAE: 0.05815693736076355		 Val MAE: 0.047663938254117966
             	Algebraic dist: 0.32673452211462933		 Val Algebraic dist: 0.74615478515625
             	RE1 dist: 0.10618970705115277		 Val RE1 dist: 0.6650932146155316
             	SED dist: 0.5525212495223336		 Val SED dist: 3.183210621709409

Epoch 8088/8000: Training Loss: 0.3218593390091606		 Val Loss: 0.9820948061735734
             	Training MAE: 0.06095120310783386		 Val MAE: 0.0428648479282856
             	Algebraic dist: 0.34383539531541907		 Val Algebraic dist: 0.4714128660119098
             	RE1 dist: 0.11456846154254416		 Val RE1 dist: 0.38546114382536517
             	SED dist: 0.5965126701023268		 Val SED dist: 1.9449741529381794

Epoch 8089/8000: Training Loss: 0.21679693719615106		 Val Loss: 1.0159270245095957
             	Training MAE: 0.05839885026216507		 Val MAE: 0.048639118671417236
             	Algebraic dist: 0.2585483633953592		 Val Algebraic dist: 0.5581905945487644
             	RE1 dist: 0.06851576203885286		 Val RE1 dist: 0.3905963897705078
             	SED dist: 0.38985658728558087		 Val SED dist: 2.007115903108016

Epoch 8090/8000: Training Loss: 0.3138723373413086		 Val Loss: 1.188626828400985
             	Training MAE: 0.057370200753211975		 Val MAE: 0.04147573560476303
             	Algebraic dist: 0.33095372241476306		 Val Algebraic dist: 0.4877830588299295
             	RE1 dist: 0.10799476374750552		 Val RE1 dist: 0.49159356822138245
             	SED dist: 0.5858555669369905		 Val SED dist: 2.36169317494268

Epoch 8091/8000: Training Loss: 0.3471216326174529		 Val Loss: 1.3401956972868547
             	Training MAE: 0.05899727717041969		 Val MAE: 0.046197112649679184
             	Algebraic dist: 0.3580649417379628		 Val Algebraic dist: 0.746567850527556
             	RE1 dist: 0.12390344039253566		 Val RE1 dist: 0.5522281397943911
             	SED dist: 0.6518588688062585		 Val SED dist: 2.659890548042629

Epoch 8092/8000: Training Loss: 0.5672536932903788		 Val Loss: 1.2869614310886548
             	Training MAE: 0.058605462312698364		 Val MAE: 0.05144873633980751
             	Algebraic dist: 0.4608371568762738		 Val Algebraic dist: 0.6049866469010062
             	RE1 dist: 0.22573504240616507		 Val RE1 dist: 0.5401982846467391
             	SED dist: 1.0903568267822266		 Val SED dist: 2.549541473388672

Epoch 8093/8000: Training Loss: 0.3897087677665379		 Val Loss: 1.0699469524881113
             	Training MAE: 0.0591970719397068		 Val MAE: 0.05710241571068764
             	Algebraic dist: 0.37806560682213824		 Val Algebraic dist: 0.45867248203443445
             	RE1 dist: 0.14454438375390094		 Val RE1 dist: 0.4246736609417459
             	SED dist: 0.7346765269403872		 Val SED dist: 2.1100727578868037

Epoch 8094/8000: Training Loss: 0.235791828321374		 Val Loss: 0.9206695556640625
             	Training MAE: 0.05671851336956024		 Val MAE: 0.046499527990818024
             	Algebraic dist: 0.2814244602037513		 Val Algebraic dist: 0.46887078492537787
             	RE1 dist: 0.07914708489957063		 Val RE1 dist: 0.3594890262769616
             	SED dist: 0.43024092135222064		 Val SED dist: 1.8230607405952786

Epoch 8095/8000: Training Loss: 0.326124440068784		 Val Loss: 1.1805743341860564
             	Training MAE: 0.05776062607765198		 Val MAE: 0.05927685275673866
             	Algebraic dist: 0.34187022499416186		 Val Algebraic dist: 0.4857044219970703
             	RE1 dist: 0.11478721577188243		 Val RE1 dist: 0.46011667666227923
             	SED dist: 0.6106372086898141		 Val SED dist: 2.32794886050017

Epoch 8096/8000: Training Loss: 0.3626448175181513		 Val Loss: 1.818026003630265
             	Training MAE: 0.05837532505393028		 Val MAE: 0.0672849491238594
             	Algebraic dist: 0.3616834723431131		 Val Algebraic dist: 0.7738096817680027
             	RE1 dist: 0.1344573808752972		 Val RE1 dist: 0.6747376400491466
             	SED dist: 0.6827718900597614		 Val SED dist: 3.5907224572223164

Epoch 8097/8000: Training Loss: 0.2843867177548616		 Val Loss: 1.0567781199579653
             	Training MAE: 0.05907059460878372		 Val MAE: 0.04095000401139259
             	Algebraic dist: 0.311016787653384		 Val Algebraic dist: 0.5140597716621731
             	RE1 dist: 0.09591054916381836		 Val RE1 dist: 0.42530246402906335
             	SED dist: 0.5242527671482252		 Val SED dist: 2.098259801449983

Epoch 8098/8000: Training Loss: 0.41990072830863623		 Val Loss: 1.611834650454314
             	Training MAE: 0.058231890201568604		 Val MAE: 0.06076434627175331
             	Algebraic dist: 0.38938356482464337		 Val Algebraic dist: 0.7187665856402853
             	RE1 dist: 0.1564083721326745		 Val RE1 dist: 0.7075498000435207
             	SED dist: 0.7980619513470194		 Val SED dist: 3.1915900188943613

Epoch 8099/8000: Training Loss: 0.2674771806468134		 Val Loss: 0.9744637530782948
             	Training MAE: 0.05606566369533539		 Val MAE: 0.046934567391872406
             	Algebraic dist: 0.2987189292907715		 Val Algebraic dist: 0.5084084635195525
             	RE1 dist: 0.09238472192183785		 Val RE1 dist: 0.38744167659593665
             	SED dist: 0.4955697266951851		 Val SED dist: 1.9297730819038723

Epoch 8100/8000: Training Loss: 0.370337900908097		 Val Loss: 0.9419654348622197
             	Training MAE: 0.05777581408619881		 Val MAE: 0.056524209678173065
             	Algebraic dist: 0.35791405387546704		 Val Algebraic dist: 0.467267948648204
             	RE1 dist: 0.13237928307574728		 Val RE1 dist: 0.36019486966340436
             	SED dist: 0.6976606949515964		 Val SED dist: 1.8565634022588315

Epoch 8101/8000: Training Loss: 0.4805351754893427		 Val Loss: 2.747866257377293
             	Training MAE: 0.061209313571453094		 Val MAE: 0.05051010474562645
             	Algebraic dist: 0.397630732992421		 Val Algebraic dist: 1.2335773965586787
             	RE1 dist: 0.17009425163269043		 Val RE1 dist: 1.3376358695652173
             	SED dist: 0.9133076875106149		 Val SED dist: 5.472524560016135

Epoch 8102/8000: Training Loss: 0.5234973326973293		 Val Loss: 1.147283471148947
             	Training MAE: 0.060630448162555695		 Val MAE: 0.04453423619270325
             	Algebraic dist: 0.44442599752674933		 Val Algebraic dist: 0.49627275052277936
             	RE1 dist: 0.2081492465475331		 Val RE1 dist: 0.4751265567281972
             	SED dist: 1.0035397073496943		 Val SED dist: 2.2778001868206523

Epoch 8103/8000: Training Loss: 0.2797245150027068		 Val Loss: 1.1411458720331606
             	Training MAE: 0.05736519396305084		 Val MAE: 0.04171400144696236
             	Algebraic dist: 0.3155211573061736		 Val Algebraic dist: 0.524227930151898
             	RE1 dist: 0.09796340569205907		 Val RE1 dist: 0.477729258329972
             	SED dist: 0.5174402568651282		 Val SED dist: 2.266199526579484

Epoch 8104/8000: Training Loss: 0.3782483805780825		 Val Loss: 1.1773213925568953
             	Training MAE: 0.058273617178201675		 Val MAE: 0.05987347662448883
             	Algebraic dist: 0.36531991543977155		 Val Algebraic dist: 0.4973788468734078
             	RE1 dist: 0.13808696166328763		 Val RE1 dist: 0.4706393532131029
             	SED dist: 0.711819026781165		 Val SED dist: 2.320831464684528

Epoch 8105/8000: Training Loss: 0.29683111024939496		 Val Loss: 1.3971690302309783
             	Training MAE: 0.05796283110976219		 Val MAE: 0.0590154267847538
             	Algebraic dist: 0.3076672139375106		 Val Algebraic dist: 0.5563929599264393
             	RE1 dist: 0.10185589997664742		 Val RE1 dist: 0.5701349921848463
             	SED dist: 0.5515609824139139		 Val SED dist: 2.7633502794348677

Epoch 8106/8000: Training Loss: 0.30846386370451556		 Val Loss: 1.0678115513013757
             	Training MAE: 0.05827876925468445		 Val MAE: 0.05199858918786049
             	Algebraic dist: 0.3285871588665506		 Val Algebraic dist: 0.5494942457779594
             	RE1 dist: 0.10755914190541142		 Val RE1 dist: 0.4093777615091075
             	SED dist: 0.5729807978091033		 Val SED dist: 2.106289407481318

Epoch 8107/8000: Training Loss: 0.7691403264584749		 Val Loss: 1.663886028787364
             	Training MAE: 0.059570420533418655		 Val MAE: 0.058567114174366
             	Algebraic dist: 0.5635157046110734		 Val Algebraic dist: 0.6019984950190005
             	RE1 dist: 0.32839555325715436		 Val RE1 dist: 0.694892054018767
             	SED dist: 1.4948884715204653		 Val SED dist: 3.292015739109205

Epoch 8108/8000: Training Loss: 0.34233368997988495		 Val Loss: 1.257285905920941
             	Training MAE: 0.05751063674688339		 Val MAE: 0.04718710854649544
             	Algebraic dist: 0.35432487985362177		 Val Algebraic dist: 0.5068412863689921
             	RE1 dist: 0.12365116243777068		 Val RE1 dist: 0.5167257474816364
             	SED dist: 0.6427266908728558		 Val SED dist: 2.493414173955503

Epoch 8109/8000: Training Loss: 0.21640437582264777		 Val Loss: 0.9129773015561311
             	Training MAE: 0.05692945793271065		 Val MAE: 0.04412189498543739
             	Algebraic dist: 0.26316414708676544		 Val Algebraic dist: 0.4312117618063222
             	RE1 dist: 0.07168974565423053		 Val RE1 dist: 0.34543839744899585
             	SED dist: 0.39037766663924506		 Val SED dist: 1.8078515425972317

Epoch 8110/8000: Training Loss: 0.28161417919656506		 Val Loss: 1.2127920233685037
             	Training MAE: 0.057593848556280136		 Val MAE: 0.0533764585852623
             	Algebraic dist: 0.3032235684602157		 Val Algebraic dist: 0.5146342153134553
             	RE1 dist: 0.09631189056064772		 Val RE1 dist: 0.5009556645932405
             	SED dist: 0.5203483001045559		 Val SED dist: 2.400980907937755

Epoch 8111/8000: Training Loss: 0.3407257121542226		 Val Loss: 1.2169351992399797
             	Training MAE: 0.05990346521139145		 Val MAE: 0.04858991131186485
             	Algebraic dist: 0.350323718527089		 Val Algebraic dist: 0.507892484250276
             	RE1 dist: 0.12199841374936311		 Val RE1 dist: 0.4743786687436311
             	SED dist: 0.6366973959881327		 Val SED dist: 2.410967785379161

Epoch 8112/8000: Training Loss: 0.3291372838227645		 Val Loss: 1.0955073315164316
             	Training MAE: 0.05822400003671646		 Val MAE: 0.042330943048000336
             	Algebraic dist: 0.34676031444383704		 Val Algebraic dist: 0.53265206710152
             	RE1 dist: 0.12034485651099164		 Val RE1 dist: 0.4552082808121391
             	SED dist: 0.6158986713575281		 Val SED dist: 2.1748643958050273

Epoch 8113/8000: Training Loss: 0.3400735025820525		 Val Loss: 1.0083428258481233
             	Training MAE: 0.05694296956062317		 Val MAE: 0.051471609622240067
             	Algebraic dist: 0.3431164907372516		 Val Algebraic dist: 0.4853095179018767
             	RE1 dist: 0.12339366000631581		 Val RE1 dist: 0.3920733825020168
             	SED dist: 0.6384877329287322		 Val SED dist: 1.9920369023862092

