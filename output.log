nohup: ignoring input
/home/aviran/miniconda3/envs/alon_env/lib/python3.9/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/home/aviran/miniconda3/envs/alon_env/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/aviran/miniconda3/envs/alon_env/lib/python3.9/site-packages/transformers/modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location=map_location)
/home/aviran/Alon/Thesis/AffineRegressor.py:305: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(model_path, map_location='cpu')
###########################################################################################################################################################

                        __2 learning rate: 6e-05,  mlp_hidden_sizes: [1024, 512], batch_size: 32, norm: True, alpha: 10, avg embeddings: True, 
                        crop: 224 resize: 256, use conv: False pretrained: None, seed: 42, angle range: 90, shift range: 100, 
                        train length: 6144, val length: 780, test length: 780, get old path: False



##### CONTINUE TRAINING #####


Epoch 141/150: Training Loss: 0.026668064296245575		 Val Loss: 0.04355401992797851

	      Training MAE Angle: 0.10157622893651326		 Val MAE Angle: 0.12834331512451172
              Training MSE Angle: 0.020279577622811		 Val MSE Angle: 0.034188332557678225

	      Training MAE Shift: 0.018419173856576283		 Val MAE Shift: 0.021124737262725832
              Training Euclidean Shift: 0.02900560200214386	 Val Euclidean Shift: 0.03318998336791992




Epoch 142/150: Training Loss: 0.02575840801000595		 Val Loss: 0.04265199184417725

	      Training MAE Angle: 0.09830134113629659		 Val MAE Angle: 0.12510832786560058
              Training MSE Angle: 0.019284452001253765		 Val MSE Angle: 0.03176830291748047

	      Training MAE Shift: 0.018630754202604294		 Val MAE Shift: 0.021051781177520754
              Training Euclidean Shift: 0.02933354675769806	 Val Euclidean Shift: 0.0329513430595398




Epoch 143/150: Training Loss: 0.025182242194811504		 Val Loss: 0.055175309181213376

	      Training MAE Angle: 0.09714079896608989		 Val MAE Angle: 0.12928614616394044
              Training MSE Angle: 0.018569204956293106		 Val MSE Angle: 0.036193602085113526

	      Training MAE Shift: 0.01839066172639529		 Val MAE Shift: 0.020507476329803466
              Training Euclidean Shift: 0.02890404810508092	 Val Euclidean Shift: 0.03209353685379028




Epoch 144/150: Training Loss: 0.02381378908952077		 Val Loss: 0.03265531063079834

	      Training MAE Angle: 0.09521691997845967		 Val MAE Angle: 0.10867674827575684
              Training MSE Angle: 0.017782167841990788		 Val MSE Angle: 0.024737427234649657

	      Training MAE Shift: 0.017848655581474304		 Val MAE Shift: 0.01933452010154724
              Training Euclidean Shift: 0.028052511314551037	 Val Euclidean Shift: 0.030602238178253173




Epoch 145/150: Training Loss: 0.024248473346233368		 Val Loss: 0.03899233102798462

	      Training MAE Angle: 0.09589590628941853		 Val MAE Angle: 0.11750486373901367
              Training MSE Angle: 0.018154136836528778		 Val MSE Angle: 0.029987630844116212

	      Training MAE Shift: 0.01811317851146062		 Val MAE Shift: 0.019978960752487184
              Training Euclidean Shift: 0.028479712704817455	 Val Euclidean Shift: 0.03153076171875




Epoch 146/150: Training Loss: 0.02286325643459956		 Val Loss: 0.045493059158325196

	      Training MAE Angle: 0.09500771760940552		 Val MAE Angle: 0.12154862403869629
              Training MSE Angle: 0.017041022578875225		 Val MSE Angle: 0.03655965566635132

	      Training MAE Shift: 0.017833763112624485		 Val MAE Shift: 0.019839438199996947
              Training Euclidean Shift: 0.028085360924402874	 Val Euclidean Shift: 0.031319923400878906




Epoch 147/150: Training Loss: 0.023321670790513355		 Val Loss: 0.04105404853820801

	      Training MAE Angle: 0.09527604778607686		 Val MAE Angle: 0.12515728950500488
              Training MSE Angle: 0.017527031401793163		 Val MSE Angle: 0.032942681312561034

	      Training MAE Shift: 0.017823395629723866		 Val MAE Shift: 0.01851476192474365
              Training Euclidean Shift: 0.028055051962534588	 Val Euclidean Shift: 0.029175777435302735




Epoch 148/150: Training Loss: 0.02534623195727666		 Val Loss: 0.04766901016235352

	      Training MAE Angle: 0.09852245450019836		 Val MAE Angle: 0.12944198608398438
              Training MSE Angle: 0.01856302097439766		 Val MSE Angle: 0.03742263317108154

	      Training MAE Shift: 0.018760964274406433		 Val MAE Shift: 0.021664178371429442
              Training Euclidean Shift: 0.02951056758562724	 Val Euclidean Shift: 0.03433492660522461




Epoch 149/150: Training Loss: 0.024771392345428467		 Val Loss: 0.0399203896522522

	      Training MAE Angle: 0.09698944290479024		 Val MAE Angle: 0.1173381233215332
              Training MSE Angle: 0.018153447657823563		 Val MSE Angle: 0.030829319953918456

	      Training MAE Shift: 0.018906192233165104		 Val MAE Shift: 0.019922759532928467
              Training Euclidean Shift: 0.02978542943795522	 Val Euclidean Shift: 0.03126793384552002




Epoch 150/150: Training Loss: 0.0252152681350708		 Val Loss: 0.044759912490844725

	      Training MAE Angle: 0.09739554921785991		 Val MAE Angle: 0.12411295890808105
              Training MSE Angle: 0.01874151701728503		 Val MSE Angle: 0.03522247552871704

	      Training MAE Shift: 0.018475630631049473		 Val MAE Shift: 0.020679483413696288
              Training Euclidean Shift: 0.02904544770717621	 Val Euclidean Shift: 0.03250560522079468




## TEST RESULTS: ##
Test Loss: 0.0408911406993866 
Test MAE Shift: 0.02141929417848587		 Test Euclidean Shift: 0.03365379571914673
Test MAE Angle: 0.11871501058340073		 Test MSE Angle: 0.030311036854982376


