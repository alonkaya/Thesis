Thu 19 Dec 2024 17:26:38 IST

SLURM_JOBID:		 1979422
SLURM_JOB_NODELIST:	 ise-cpu256-10 


/home/alonkay/.conda/envs/alon_env/lib/python3.9/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/home/alonkay/.conda/envs/alon_env/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/cs_storage/alonkay/Thesis/FMatrixRegressor.py:343: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(model_path, map_location='cpu')

###########################################################################################################################################################

 learning rate: 0.0001, mlp_hidden_sizes: [1024, 512], jump_frames: 6, use_reconstruction_layer: True
batch_size: 8, norm: True, train_seqeunces: [0, 2, 3, 5], val_sequences: [6, 7, 8], RL_TEST_NAMES: ['fe2fadf89a84e92a', 'f01e8b6f8e10fdd9', 'f1ee9dc6135e5307', 'a41df4fa06fd391b', 'bc0ebb7482f14795', '9bdd34e784c04e3a', '98ebee1c36ecec55'], dataset: Flying,
average embeddings: False, model: microsoft/resnet-152, augmentation: True, random crop: True, part: None, get_old_path: False, computer: 1,
RE1 coeff: 0 SED coeff: 0.5, ALG_COEFF: 0, L2_coeff: 1, huber_coeff: 1, frozen layers: 0, trained vit: None,
crop: 224 resize: 256, use conv: True pretrained: None, train_size: 150, norm_mean: tensor([0.5000, 0.5000, 0.5000], device='cuda:0'), norm_std: tensor([0.5000, 0.5000, 0.5000], device='cuda:0'), sched: None seed: 42

train size: 1472, val size: 361, test size: 968

##### CONTINUE TRAINING #####

Epoch 5071/8000: Training Loss: 0.4753252941629161		 Val Loss: 2.043477431587551
             	Training MAE: 0.07754140347242355		 Val MAE: 0.07575637102127075
             	Algebraic dist: 0.4183889471966287		 Val Algebraic dist: 0.6792746419491975
             	RE1 dist: 0.19731175381204355		 Val RE1 dist: 1.0350077255912449
             	SED dist: 0.8809053172235903		 Val SED dist: 4.041431592858356

### Not decreasing ###

Epoch 5072/8000: Training Loss: 0.28050043271935504		 Val Loss: 1.4951744079589844
             	Training MAE: 0.07468091696500778		 Val MAE: 0.05805761739611626
             	Algebraic dist: 0.31521569127621857		 Val Algebraic dist: 0.603251374286154
             	RE1 dist: 0.10431030522222104		 Val RE1 dist: 0.7018616717794667
             	SED dist: 0.4942028626151707		 Val SED dist: 2.962182749872622

### Not decreasing ###

Epoch 5073/8000: Training Loss: 0.3072399678437606		 Val Loss: 2.054423954175866
             	Training MAE: 0.07741740345954895		 Val MAE: 0.05997498705983162
             	Algebraic dist: 0.3314276778179666		 Val Algebraic dist: 0.7840742028277853
             	RE1 dist: 0.11381620946137802		 Val RE1 dist: 1.0267350570015286
             	SED dist: 0.5440775829812755		 Val SED dist: 4.077258566151494

### Not decreasing ###

Epoch 5074/8000: Training Loss: 0.5021546405294667		 Val Loss: 1.714447021484375
             	Training MAE: 0.07976789772510529		 Val MAE: 0.07230419665575027
             	Algebraic dist: 0.45217476720395294		 Val Algebraic dist: 0.6715541507886804
             	RE1 dist: 0.2127925209377123		 Val RE1 dist: 0.8286585600479789
             	SED dist: 0.9319464642068614		 Val SED dist: 3.386666671089504

### Not decreasing ###

Epoch 5075/8000: Training Loss: 0.3039001174595045		 Val Loss: 1.4753660119098166
             	Training MAE: 0.07644744217395782		 Val MAE: 0.06121639162302017
             	Algebraic dist: 0.3356204240218453		 Val Algebraic dist: 0.5786820701930834
             	RE1 dist: 0.11789413120435632		 Val RE1 dist: 0.6690998492033585
             	SED dist: 0.5390935151473336		 Val SED dist: 2.919986227284307

### Not decreasing ###

Epoch 5076/8000: Training Loss: 0.46104907989501953		 Val Loss: 1.977060898490574
             	Training MAE: 0.0772542878985405		 Val MAE: 0.061093416064977646
             	Algebraic dist: 0.438867942146633		 Val Algebraic dist: 0.7319180861763332
             	RE1 dist: 0.1966808153235394		 Val RE1 dist: 1.0897149625031843
             	SED dist: 0.8539373978324558		 Val SED dist: 3.9228084398352583

### Not decreasing ###

Epoch 5077/8000: Training Loss: 0.45758632991624915		 Val Loss: 1.9585450213888418
             	Training MAE: 0.0783400759100914		 Val MAE: 0.06415369361639023
             	Algebraic dist: 0.4171035186104152		 Val Algebraic dist: 0.6718377652375594
             	RE1 dist: 0.19041090426237686		 Val RE1 dist: 1.0158296668011209
             	SED dist: 0.8457654040792714		 Val SED dist: 3.881180472995924

### Not decreasing ###

Epoch 5078/8000: Training Loss: 0.32331358868142834		 Val Loss: 1.470248844312585
             	Training MAE: 0.077367402613163		 Val MAE: 0.06671255081892014
             	Algebraic dist: 0.3515338483064071		 Val Algebraic dist: 0.6400000945381497
             	RE1 dist: 0.1254736444224482		 Val RE1 dist: 0.6670667814171832
             	SED dist: 0.5761978729911472		 Val SED dist: 2.9017768528150474

### Not decreasing ###

Epoch 5079/8000: Training Loss: 0.4708008558853813		 Val Loss: 2.270618438720703
             	Training MAE: 0.07625929266214371		 Val MAE: 0.060200661420822144
             	Algebraic dist: 0.44038805754288385		 Val Algebraic dist: 0.7663265725840693
             	RE1 dist: 0.20486147507377292		 Val RE1 dist: 1.251834952312967
             	SED dist: 0.8742465143618376		 Val SED dist: 4.508513740871264

### Not decreasing ###

Epoch 5080/8000: Training Loss: 0.29363671593044116		 Val Loss: 1.5104428166928499
             	Training MAE: 0.07541315257549286		 Val MAE: 0.06398957222700119
             	Algebraic dist: 0.32419816307399585		 Val Algebraic dist: 0.6125557111657184
             	RE1 dist: 0.11594020802041759		 Val RE1 dist: 0.7067599918531335
             	SED dist: 0.5202765257462211		 Val SED dist: 2.9844967385996943

### Not decreasing ###

Epoch 5081/8000: Training Loss: 0.261846459430197		 Val Loss: 1.3658384240191916
             	Training MAE: 0.07762865722179413		 Val MAE: 0.06367184221744537
             	Algebraic dist: 0.299827472023342		 Val Algebraic dist: 0.5607501734857974
             	RE1 dist: 0.09277807111325471		 Val RE1 dist: 0.6221898949664572
             	SED dist: 0.45418332970660663		 Val SED dist: 2.6964253964631455

### Not decreasing ###

Epoch 5082/8000: Training Loss: 0.3596594851949941		 Val Loss: 1.9882275125254756
             	Training MAE: 0.07814248651266098		 Val MAE: 0.09039933979511261
             	Algebraic dist: 0.3741595641426418		 Val Algebraic dist: 0.8574505681576936
             	RE1 dist: 0.14090595038040823		 Val RE1 dist: 0.9367697342582371
             	SED dist: 0.6483895260354747		 Val SED dist: 3.909533625063689

### Not decreasing ###

Epoch 5083/8000: Training Loss: 0.2974064039147418		 Val Loss: 1.5814835921577786
             	Training MAE: 0.07656718045473099		 Val MAE: 0.06358365714550018
             	Algebraic dist: 0.328692685002866		 Val Algebraic dist: 0.6083601661350416
             	RE1 dist: 0.11061413391776707		 Val RE1 dist: 0.7629739512567935
             	SED dist: 0.5268570029217264		 Val SED dist: 3.129296012546705

### Not decreasing ###

Epoch 5084/8000: Training Loss: 0.384484747181768		 Val Loss: 1.830055568529212
             	Training MAE: 0.07794243097305298		 Val MAE: 0.060108479112386703
             	Algebraic dist: 0.394439116768215		 Val Algebraic dist: 0.6671352801115616
             	RE1 dist: 0.15507278235062308		 Val RE1 dist: 0.8838448731795602
             	SED dist: 0.6992562335470448		 Val SED dist: 3.627754543138587

### Not decreasing ###

Epoch 5085/8000: Training Loss: 0.4627361297607422		 Val Loss: 6.156933328379756
             	Training MAE: 0.07740014046430588		 Val MAE: 0.0836842879652977
             	Algebraic dist: 0.3965912694516389		 Val Algebraic dist: 1.9363008582073709
             	RE1 dist: 0.1822289798570716		 Val RE1 dist: 3.3970131252122964
             	SED dist: 0.8549161993938944		 Val SED dist: 12.258812945822012

### Not decreasing ###

Epoch 5086/8000: Training Loss: 0.6682133881942086		 Val Loss: 2.087422412374745
             	Training MAE: 0.07878626883029938		 Val MAE: 0.05657263845205307
             	Algebraic dist: 0.5279443160347317		 Val Algebraic dist: 0.8113604006559952
             	RE1 dist: 0.33392628379490064		 Val RE1 dist: 1.1272581349248472
             	SED dist: 1.2647899959398352		 Val SED dist: 4.146747091542119

### Not decreasing ###

Epoch 5087/8000: Training Loss: 0.27321680732395337		 Val Loss: 1.5539577318274456
             	Training MAE: 0.07544805109500885		 Val MAE: 0.06280797719955444
             	Algebraic dist: 0.30948274031929346		 Val Algebraic dist: 0.5747597321220066
             	RE1 dist: 0.10392985136612602		 Val RE1 dist: 0.7241853631061056
             	SED dist: 0.47857466987941577		 Val SED dist: 3.072834180748981

### Not decreasing ###

Epoch 5088/8000: Training Loss: 0.37142807504405145		 Val Loss: 1.6735936040463655
             	Training MAE: 0.07808081805706024		 Val MAE: 0.07276525348424911
             	Algebraic dist: 0.36317402383555536		 Val Algebraic dist: 0.6069867092630138
             	RE1 dist: 0.1424884796142578		 Val RE1 dist: 0.7932234225065812
             	SED dist: 0.6717236145682957		 Val SED dist: 3.303400454313859

### Not decreasing ###

Epoch 5089/8000: Training Loss: 0.3773043259330418		 Val Loss: 1.6054485155188518
             	Training MAE: 0.0768420472741127		 Val MAE: 0.07524093240499496
             	Algebraic dist: 0.3881262074346128		 Val Algebraic dist: 0.6150359692780868
             	RE1 dist: 0.1516392127327297		 Val RE1 dist: 0.7566857545272164
             	SED dist: 0.6852138768071714		 Val SED dist: 3.162032749341882

### Not decreasing ###

Epoch 5090/8000: Training Loss: 0.4478572762530783		 Val Loss: 2.8396672787873642
             	Training MAE: 0.07590300589799881		 Val MAE: 0.06975800544023514
             	Algebraic dist: 0.417127567788829		 Val Algebraic dist: 0.8987327243970789
             	RE1 dist: 0.18340726520704187		 Val RE1 dist: 1.537263123885445
             	SED dist: 0.8288380996040676		 Val SED dist: 5.635922639266305

### Not decreasing ###

Epoch 5091/8000: Training Loss: 0.3517241270645805		 Val Loss: 1.6768077352772588
             	Training MAE: 0.07768315821886063		 Val MAE: 0.06393082439899445
             	Algebraic dist: 0.35756529932436737		 Val Algebraic dist: 0.6651648645815642
             	RE1 dist: 0.1397961948228919		 Val RE1 dist: 0.7949411972709324
             	SED dist: 0.6327474842900815		 Val SED dist: 3.318639340608016

### Not decreasing ###

Epoch 5092/8000: Training Loss: 0.2675410353619119		 Val Loss: 1.2597761568815813
             	Training MAE: 0.07555685937404633		 Val MAE: 0.06385773420333862
             	Algebraic dist: 0.305880650230076		 Val Algebraic dist: 0.5920323496279509
             	RE1 dist: 0.10006873503975246		 Val RE1 dist: 0.5677408550096594
             	SED dist: 0.46757892940355383		 Val SED dist: 2.4849151943040932

### Not decreasing ###



## TEST RESULTS: ##
Test Loss: 1.3203807988442666		 Test MAE: 0.0637995071709156
Test Algebraic dist: 0.6025220886734892
Test SED dist: 2.6055977056834325
Test RE1 dist: 0.5983186075510072

Test Algebraic dist truth: 0.005073755733237779
Test SED dist truth: 0.00019875436651805214
Test RE1 dist truth: 2.484488462613634e-05


plots/Flying/SED_0.5__L2_1__huber_1__lr_0.0001__conv__Resnet__use_reconstruction_True/BS_8__ratio_150__frozen_0 no backup to delete after job done

