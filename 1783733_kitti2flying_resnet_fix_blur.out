Sat 07 Dec 2024 20:22:06 IST

SLURM_JOBID:		 1783733
SLURM_JOB_NODELIST:	 cs-4090-03 


/home/alonkay/.conda/envs/alon_env/lib/python3.9/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/home/alonkay/.conda/envs/alon_env/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/cs_storage/alonkay/Thesis/FMatrixRegressor.py:333: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(model_path, map_location='cpu')

###########################################################################################################################################################

__fixed_blur learning rate: 0.0001, mlp_hidden_sizes: [1024, 512], jump_frames: 6, use_reconstruction_layer: True
batch_size: 8, norm: True, train_seqeunces: [0, 2, 3, 5], val_sequences: [6, 7, 8], RL_TEST_NAMES: ['fe2fadf89a84e92a', 'f01e8b6f8e10fdd9', 'f1ee9dc6135e5307', 'a41df4fa06fd391b', 'bc0ebb7482f14795', '9bdd34e784c04e3a', '98ebee1c36ecec55'], dataset: Kitti2Flying,
average embeddings: False, model: microsoft/resnet-152, augmentation: True, random crop: True, part: head, get_old_path: False,
RE1 coeff: 0 SED coeff: 0.5, ALG_COEFF: 0, L2_coeff: 1, huber_coeff: 1, frozen layers: 0, trained vit: None,
crop: 224 resize: 256, use conv: True pretrained: None, train_size: 150, norm_mean: tensor([0.5000, 0.5000, 0.5000], device='cuda:0'), norm_std: tensor([0.5000, 0.5000, 0.5000], device='cuda:0'), sched: None seed: 42, 

train size: 1472, val size: 361, test size: 968

algebraic_truth: 0.004300451149111209		 val_algebraic_truth: 0.005261007858359296
RE1_truth: 1.8894580020771727e-05		 val_RE1_truth: 2.574542051424151e-05
SED_truth: 0.00015111783843325532		 val_SED_truth: 0.00020595079125917476

Epoch 1/8000: Training Loss: 5.961620164954144		 Val Loss: 3.9870592200237773
             	Training MAE: 0.08372374624013901		 Val MAE: 0.07679901272058487
             	Algebraic dist: 1.900632609491763		 Val Algebraic dist: 1.4718523440153704
             	RE1 dist: 3.9232715109120244		 Val RE1 dist: 2.531663977581522
             	SED dist: 11.870500647503397		 Val SED dist: 7.932373046875

Epoch 2/8000: Training Loss: 2.955028368079144		 Val Loss: 2.6203870358674424
             	Training MAE: 0.09484519809484482		 Val MAE: 0.07740095257759094
             	Algebraic dist: 1.1196064327074133		 Val Algebraic dist: 1.0871285977570906
             	RE1 dist: 1.4528442051099695		 Val RE1 dist: 1.4782807723335598
             	SED dist: 5.843886665675951		 Val SED dist: 5.198086614194124

