nohup: ignoring input
/home/alonkay/conda/alon/lib/python3.9/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
Traceback (most recent call last):
  File "/home/alonkay/Thesis/PlayGround.py", line 796, in <module>
    test_trained()
  File "/home/alonkay/Thesis/PlayGround.py", line 780, in test_trained
    train_loader, val_loader, test_loader = get_data_loaders(train_size=10000, part='head', batch_size=1)
  File "/home/alonkay/Thesis/Dataset.py", line 477, in get_data_loaders
    return get_dataloader_flying(train_size, batch_size)
  File "/home/alonkay/Thesis/Dataset.py", line 452, in get_dataloader_flying
    images_1 = {idx: torchvision.io.read_image(os.path.join(right_path, f'{idx:04}.{IMAGE_TYPE}')).to(device) for idx in valid_indices} if INIT_DATA else None
  File "/home/alonkay/Thesis/Dataset.py", line 452, in <dictcomp>
    images_1 = {idx: torchvision.io.read_image(os.path.join(right_path, f'{idx:04}.{IMAGE_TYPE}')).to(device) for idx in valid_indices} if INIT_DATA else None
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 31.50 GiB of which 3.44 MiB is free. Process 856845 has 15.45 GiB memory in use. Including non-PyTorch memory, this process has 9.16 GiB memory in use. Process 857623 has 6.87 GiB memory in use. Of the allocated memory 8.81 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
